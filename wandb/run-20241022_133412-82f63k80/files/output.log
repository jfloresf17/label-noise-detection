LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name            | Type               | Params | Mode
----------------------------------------------------------------
0  | model           | Unet               | 24.4 M | train
1  | loss            | BCEWithLogitsLoss  | 0      | train
2  | train_f1        | BinaryF1Score      | 0      | train
3  | train_iou       | BinaryJaccardIndex | 0      | train
4  | train_precision | BinaryPrecision    | 0      | train
5  | train_recall    | BinaryRecall       | 0      | train
6  | val_f1          | BinaryF1Score      | 0      | train
7  | val_iou         | BinaryJaccardIndex | 0      | train
8  | val_precision   | BinaryPrecision    | 0      | train
9  | val_recall      | BinaryRecall       | 0      | train
10 | test_f1         | BinaryF1Score      | 0      | train
11 | test_iou        | BinaryJaccardIndex | 0      | train
12 | test_precision  | BinaryPrecision    | 0      | train
13 | test_recall     | BinaryRecall       | 0      | train
----------------------------------------------------------------
24.4 M    Trainable params
0         Non-trainable params
24.4 M    Total params
97.745    Total estimated model params size (MB)
201       Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 183, in <module>
    app()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 338, in __call__
    raise e
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 321, in __call__
    return get_command(self)(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 665, in main
    return _main(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 197, in _main
    rv = self.invoke(ctx)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 703, in wrapper
    return callback(**use_params)
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 176, in train
    train_teacher(config)
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 79, in train_teacher
    trainer.fit(teacher_model, clean_dataloader)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 410, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 640, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 633, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/tidop/projects/Noisy-Student/models/teacher_unet.py", line 65, in validation_step
    outputs = self(images)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/projects/Noisy-Student/models/teacher_unet.py", line 42, in forward
    return self.model(x)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py", line 38, in forward
    features = self.encoder(x)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/resnet.py", line 63, in forward
    x = stages[i](x)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.HalfTensor) should be the same
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/tidop/projects/Noisy-Student/trainer.py:176 in train                   │
│                                                                              │
│   173 │                                                                      │
│   174 │   ## Train the model                                                 │
│   175 │   if model == "teacher":                                             │
│ ❱ 176 │   │   train_teacher(config)                                          │
│   177 │   elif model == "student":                                           │
│   178 │   │   train_student(config)                                          │
│   179 │   else:                                                              │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │      config = {                                                          │ │
│ │               │   'device': 'cuda',                                      │ │
│ │               │   'data': {                                              │ │
│ │               │   │   'batch_size': 16,                                  │ │
│ │               │   │   'num_workers': 16,                                 │ │
│ │               │   │   'whu_path':                                        │ │
│ │               '/media/tidop/Datos_4TB/databases/whu',                    │ │
│ │               │   │   'datacentric_image_path':                          │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/training… │ │
│ │               │   │   'label_noisy_path':                                │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/training… │ │
│ │               │   │   'teacher_output_path':                             │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/teacher_… │ │
│ │               │   },                                                     │ │
│ │               │   'Normalize': {                                         │ │
│ │               │   │   'apply': True,                                     │ │
│ │               │   │   'WHU': {                                           │ │
│ │               │   │   │   'mean': [                                      │ │
│ │               │   │   │   │   105.34253814,                              │ │
│ │               │   │   │   │   114.2284708,                               │ │
│ │               │   │   │   │   112.52936415                               │ │
│ │               │   │   │   ],                                             │ │
│ │               │   │   │   'std': [                                       │ │
│ │               │   │   │   │   42.12451161,                               │ │
│ │               │   │   │   │   39.52149692,                               │ │
│ │               │   │   │   │   42.81161886                                │ │
│ │               │   │   │   ]                                              │ │
│ │               │   │   },                                                 │ │
│ │               │   │   'DataCentric': {                                   │ │
│ │               │   │   │   'mean': [                                      │ │
│ │               │   │   │   │   72.74413315,                               │ │
│ │               │   │   │   │   99.76137101,                               │ │
│ │               │   │   │   │   82.70024275                                │ │
│ │               │   │   │   ],                                             │ │
│ │               │   │   │   'std': [                                       │ │
│ │               │   │   │   │   36.28290664,                               │ │
│ │               │   │   │   │   34.82507359,                               │ │
│ │               │   │   │   │   41.48902725                                │ │
│ │               │   │   │   ]                                              │ │
│ │               │   │   }                                                  │ │
│ │               │   },                                                     │ │
│ │               │   'teacher_model': {                                     │ │
│ │               │   │   'encoder_name': 'resnet34',                        │ │
│ │               │   │   'encoder_weights': 'imagenet',                     │ │
│ │               │   │   'in_channels': 3,                                  │ │
│ │               │   │   'out_channels': 1,                                 │ │
│ │               │   │   'learning_rate': '1e-3',                           │ │
│ │               │   │   'checkpoint_dir': 'checkpoints/',                  │ │
│ │               │   │   'checkpoint_name': 'best_teacher'                  │ │
│ │               │   },                                                     │ │
│ │               │   'student_model': {                                     │ │
│ │               │   │   'encoder_name': 'resnet34',                        │ │
│ │               │   │   'encoder_weights': None,                           │ │
│ │               │   │   'in_channels': 3,                                  │ │
│ │               │   │   'out_channels': 1,                                 │ │
│ │               │   │   'learning_rate': '1e-4',                           │ │
│ │               │   │   'checkpoint_dir': 'checkpoints/',                  │ │
│ │               │   │   'checkpoint_name': 'best_student'                  │ │
│ │               │   },                                                     │ │
│ │               │   'knowledge_distillation': {                            │ │
│ │               │   │   'temperature': 3.0,                                │ │
│ │               │   │   'alpha': 0.75,                                     │ │
│ │               │   │   'beta': 0.25                                       │ │
│ │               │   },                                                     │ │
│ │               │   'trainer': {                                           │ │
│ │               │   │   'wandb_project': 'teacher_student',                │ │
│ │               │   │   'experiment_name': 'teacher_model',                │ │
│ │               │   │   'strategy': 'ddp',                                 │ │
│ │               │   │   'accelerator': 'gpu',                              │ │
│ │               │   │   'precision': '16-mixed',                           │ │
│ │               │   │   'max_epochs': 50,                                  │ │
│ │               │   │   'log_every_n_steps': 50,                           │ │
│ │               │   │   'early_stopping': {                                │ │
│ │               │   │   │   'enabled': True,                               │ │
│ │               │   │   │   'patience': 10,                                │ │
│ │               │   │   │   'monitor': 'val_loss',                         │ │
│ │               │   │   │   'mode': 'min'                                  │ │
│ │               │   │   },                                                 │ │
│ │               │   │   'checkpoint_callback': {                           │ │
│ │               │   │   │   'monitor': 'val_loss',                         │ │
│ │               │   │   │   'mode': 'min',                                 │ │
│ │               │   │   │   'save_top_k': 1                                │ │
│ │               │   │   }                                                  │ │
│ │               │   }                                                      │ │
│ │               }                                                          │ │
│ │ config_path = 'config.yaml'                                              │ │
│ │       model = 'teacher'                                                  │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/projects/Noisy-Student/trainer.py:79 in train_teacher            │
│                                                                              │
│    76 │                                                                      │
│    77 │                                                                      │
│    78 │   # Train teacher model                                              │
│ ❱  79 │   trainer.fit(teacher_model, clean_dataloader)                       │
│    80 │                                                                      │
│    81 │   # Test teacher model                                               │
│    82 │   trainer.test(teacher_model, clean_dataloader, ckpt_path="best")    │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │           batch_size = 16                                                │ │
│ │            callbacks = [                                                 │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.early_stopping.Earl… │ │
│ │                        object at 0x7ed89e9a1e10>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.model_checkpoint.Mo… │ │
│ │                        object at 0x7ed89e9a1d50>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.progress.tqdm_progr… │ │
│ │                        object at 0x7ed89e9a0490>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.model_summary.Model… │ │
│ │                        object at 0x7ed89e9a24d0>                         │ │
│ │                        ]                                                 │ │
│ │           checkpoint = <pytorch_lightning.callbacks.model_checkpoint.Mo… │ │
│ │                        object at 0x7ed89e9a1d50>                         │ │
│ │    checkpoint_params = {                                                 │ │
│ │                        │   'monitor': 'val_loss',                        │ │
│ │                        │   'mode': 'min',                                │ │
│ │                        │   'save_top_k': 1                               │ │
│ │                        }                                                 │ │
│ │     clean_dataloader = <dataloader.WHUDataModule object at               │ │
│ │                        0x7ed89e326560>                                   │ │
│ │        CLEAN_DATASET = PosixPath('/media/tidop/Datos_4TB/databases/whu') │ │
│ │               config = {                                                 │ │
│ │                        │   'device': 'cuda',                             │ │
│ │                        │   'data': {                                     │ │
│ │                        │   │   'batch_size': 16,                         │ │
│ │                        │   │   'num_workers': 16,                        │ │
│ │                        │   │   'whu_path':                               │ │
│ │                        '/media/tidop/Datos_4TB/databases/whu',           │ │
│ │                        │   │   'datacentric_image_path':                 │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   │   'label_noisy_path':                       │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   │   'teacher_output_path':                    │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   },                                            │ │
│ │                        │   'Normalize': {                                │ │
│ │                        │   │   'apply': True,                            │ │
│ │                        │   │   'WHU': {                                  │ │
│ │                        │   │   │   'mean': [                             │ │
│ │                        │   │   │   │   105.34253814,                     │ │
│ │                        │   │   │   │   114.2284708,                      │ │
│ │                        │   │   │   │   112.52936415                      │ │
│ │                        │   │   │   ],                                    │ │
│ │                        │   │   │   'std': [                              │ │
│ │                        │   │   │   │   42.12451161,                      │ │
│ │                        │   │   │   │   39.52149692,                      │ │
│ │                        │   │   │   │   42.81161886                       │ │
│ │                        │   │   │   ]                                     │ │
│ │                        │   │   },                                        │ │
│ │                        │   │   'DataCentric': {                          │ │
│ │                        │   │   │   'mean': [                             │ │
│ │                        │   │   │   │   72.74413315,                      │ │
│ │                        │   │   │   │   99.76137101,                      │ │
│ │                        │   │   │   │   82.70024275                       │ │
│ │                        │   │   │   ],                                    │ │
│ │                        │   │   │   'std': [                              │ │
│ │                        │   │   │   │   36.28290664,                      │ │
│ │                        │   │   │   │   34.82507359,                      │ │
│ │                        │   │   │   │   41.48902725                       │ │
│ │                        │   │   │   ]                                     │ │
│ │                        │   │   }                                         │ │
│ │                        │   },                                            │ │
│ │                        │   'teacher_model': {                            │ │
│ │                        │   │   'encoder_name': 'resnet34',               │ │
│ │                        │   │   'encoder_weights': 'imagenet',            │ │
│ │                        │   │   'in_channels': 3,                         │ │
│ │                        │   │   'out_channels': 1,                        │ │
│ │                        │   │   'learning_rate': '1e-3',                  │ │
│ │                        │   │   'checkpoint_dir': 'checkpoints/',         │ │
│ │                        │   │   'checkpoint_name': 'best_teacher'         │ │
│ │                        │   },                                            │ │
│ │                        │   'student_model': {                            │ │
│ │                        │   │   'encoder_name': 'resnet34',               │ │
│ │                        │   │   'encoder_weights': None,                  │ │
│ │                        │   │   'in_channels': 3,                         │ │
│ │                        │   │   'out_channels': 1,                        │ │
│ │                        │   │   'learning_rate': '1e-4',                  │ │
│ │                        │   │   'checkpoint_dir': 'checkpoints/',         │ │
│ │                        │   │   'checkpoint_name': 'best_student'         │ │
│ │                        │   },                                            │ │
│ │                        │   'knowledge_distillation': {                   │ │
│ │                        │   │   'temperature': 3.0,                       │ │
│ │                        │   │   'alpha': 0.75,                            │ │
│ │                        │   │   'beta': 0.25                              │ │
│ │                        │   },                                            │ │
│ │                        │   'trainer': {                                  │ │
│ │                        │   │   'wandb_project': 'teacher_student',       │ │
│ │                        │   │   'experiment_name': 'teacher_model',       │ │
│ │                        │   │   'strategy': 'ddp',                        │ │
│ │                        │   │   'accelerator': 'gpu',                     │ │
│ │                        │   │   'precision': '16-mixed',                  │ │
│ │                        │   │   'max_epochs': 50,                         │ │
│ │                        │   │   'log_every_n_steps': 50,                  │ │
│ │                        │   │   'early_stopping': {                       │ │
│ │                        │   │   │   'enabled': True,                      │ │
│ │                        │   │   │   'patience': 10,                       │ │
│ │                        │   │   │   'monitor': 'val_loss',                │ │
│ │                        │   │   │   'mode': 'min'                         │ │
│ │                        │   │   },                                        │ │
│ │                        │   │   'checkpoint_callback': {                  │ │
│ │                        │   │   │   'monitor': 'val_loss',                │ │
│ │                        │   │   │   'mode': 'min',                        │ │
│ │                        │   │   │   'save_top_k': 1                       │ │
│ │                        │   │   }                                         │ │
│ │                        │   }                                             │ │
│ │                        }                                                 │ │
│ │    early_stop_params = {                                                 │ │
│ │                        │   'enabled': True,                              │ │
│ │                        │   'patience': 10,                               │ │
│ │                        │   'monitor': 'val_loss',                        │ │
│ │                        │   'mode': 'min'                                 │ │
│ │                        }                                                 │ │
│ │       early_stopping = <pytorch_lightning.callbacks.early_stopping.Earl… │ │
│ │                        object at 0x7ed89e9a1e10>                         │ │
│ │      experiment_name = 'teacher_model'                                   │ │
│ │             mean_whu = [105.34253814, 114.2284708, 112.52936415]         │ │
│ │          num_workers = 16                                                │ │
│ │         project_name = 'teacher_student'                                 │ │
│ │              std_whu = [42.12451161, 39.52149692, 42.81161886]           │ │
│ │        teacher_model = TeacherUNetModel(                                 │ │
│ │                          (model): Unet(                                  │ │
│ │                        │   (encoder): ResNetEncoder(                     │ │
│ │                        │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),  │ │
│ │                        stride=(2, 2), padding=(3, 3), bias=False)        │ │
│ │                        │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │     (relu): ReLU(inplace=True)                  │ │
│ │                        │     (maxpool): MaxPool2d(kernel_size=3,         │ │
│ │                        stride=2, padding=1, dilation=1, ceil_mode=False) │ │
│ │                        │     (layer1): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer2): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 128,                │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(64, 128, kernel_size=(1,  │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer3): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(128, 256, kernel_size=(1, │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (4): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (5): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer4): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(256, 512, kernel_size=(1, │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                        │   (decoder): UnetDecoder(                       │ │
│ │                        │     (center): Identity()                        │ │
│ │                        │     (blocks): ModuleList(                       │ │
│ │                        │   │   (0): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(768, 256, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(256, 256, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(384, 128, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(128, 128, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(192, 64, kernel_size=(3,  │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(128, 32, kernel_size=(3,  │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(32, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(32, 32, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(32, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (4): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(32, 16, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(16, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(16, 16, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(16, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                        │   (segmentation_head): SegmentationHead(        │ │
│ │                        │     (0): Conv2d(16, 1, kernel_size=(3, 3),      │ │
│ │                        stride=(1, 1), padding=(1, 1))                    │ │
│ │                        │     (1): Identity()                             │ │
│ │                        │     (2): Activation(                            │ │
│ │                        │   │   (activation): Identity()                  │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                          )                                               │ │
│ │                          (loss): BCEWithLogitsLoss()                     │ │
│ │                          (train_f1): BinaryF1Score()                     │ │
│ │                          (train_iou): BinaryJaccardIndex()               │ │
│ │                          (train_precision): BinaryPrecision()            │ │
│ │                          (train_recall): BinaryRecall()                  │ │
│ │                          (val_f1): BinaryF1Score()                       │ │
│ │                          (val_iou): BinaryJaccardIndex()                 │ │
│ │                          (val_precision): BinaryPrecision()              │ │
│ │                          (val_recall): BinaryRecall()                    │ │
│ │                          (test_f1): BinaryF1Score()                      │ │
│ │                          (test_iou): BinaryJaccardIndex()                │ │
│ │                          (test_precision): BinaryPrecision()             │ │
│ │                          (test_recall): BinaryRecall()                   │ │
│ │                        )                                                 │ │
│ │ teacher_wandb_logger = <pytorch_lightning.loggers.wandb.WandbLogger      │ │
│ │                        object at 0x7ed89e9a0040>                         │ │
│ │              trainer = <pytorch_lightning.trainer.trainer.Trainer object │ │
│ │                        at 0x7ed89e9a0dc0>                                │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:538 in fit                                 │
│                                                                              │
│    535 │   │   self.state.fn = TrainerFn.FITTING                             │
│    536 │   │   self.state.status = TrainerStatus.RUNNING                     │
│    537 │   │   self.training = True                                          │
│ ❱  538 │   │   call._call_and_handle_interrupt(                              │
│    539 │   │   │   self, self._fit_impl, model, train_dataloaders, val_datal │
│    540 │   │   )                                                             │
│    541                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         ckpt_path = None                                                 │ │
│ │        datamodule = None                                                 │ │
│ │             model = TeacherUNetModel(                                    │ │
│ │                       (model): Unet(                                     │ │
│ │                     │   (encoder): ResNetEncoder(                        │ │
│ │                     │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),     │ │
│ │                     stride=(2, 2), padding=(3, 3), bias=False)           │ │
│ │                     │     (bn1): BatchNorm2d(64, eps=1e-05,              │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │     (relu): ReLU(inplace=True)                     │ │
│ │                     │     (maxpool): MaxPool2d(kernel_size=3, stride=2,  │ │
│ │                     padding=1, dilation=1, ceil_mode=False)              │ │
│ │                     │     (layer1): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer2): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 128, kernel_size=(3,   │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), │ │
│ │                     stride=(2, 2), bias=False)                           │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer3): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 256, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(128, 256, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (5): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer4): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 512, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(256, 512, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (decoder): UnetDecoder(                          │ │
│ │                     │     (center): Identity()                           │ │
│ │                     │     (blocks): ModuleList(                          │ │
│ │                     │   │   (0): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(768, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(256, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(384, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (segmentation_head): SegmentationHead(           │ │
│ │                     │     (0): Conv2d(16, 1, kernel_size=(3, 3),         │ │
│ │                     stride=(1, 1), padding=(1, 1))                       │ │
│ │                     │     (1): Identity()                                │ │
│ │                     │     (2): Activation(                               │ │
│ │                     │   │   (activation): Identity()                     │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                       )                                                  │ │
│ │                       (loss): BCEWithLogitsLoss()                        │ │
│ │                       (train_f1): BinaryF1Score()                        │ │
│ │                       (train_iou): BinaryJaccardIndex()                  │ │
│ │                       (train_precision): BinaryPrecision()               │ │
│ │                       (train_recall): BinaryRecall()                     │ │
│ │                       (val_f1): BinaryF1Score()                          │ │
│ │                       (val_iou): BinaryJaccardIndex()                    │ │
│ │                       (val_precision): BinaryPrecision()                 │ │
│ │                       (val_recall): BinaryRecall()                       │ │
│ │                       (test_f1): BinaryF1Score()                         │ │
│ │                       (test_iou): BinaryJaccardIndex()                   │ │
│ │                       (test_precision): BinaryPrecision()                │ │
│ │                       (test_recall): BinaryRecall()                      │ │
│ │                     )                                                    │ │
│ │              self = <pytorch_lightning.trainer.trainer.Trainer object at │ │
│ │                     0x7ed89e9a0dc0>                                      │ │
│ │ train_dataloaders = <dataloader.WHUDataModule object at 0x7ed89e326560>  │ │
│ │   val_dataloaders = None                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/call.py:46 in _call_and_handle_interrupt              │
│                                                                              │
│    43 │   """                                                                │
│    44 │   try:                                                               │
│    45 │   │   if trainer.strategy.launcher is not None:                      │
│ ❱  46 │   │   │   return trainer.strategy.launcher.launch(trainer_fn, *args, │
│    47 │   │   return trainer_fn(*args, **kwargs)                             │
│    48 │                                                                      │
│    49 │   except _TunerExitException:                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │       args = (                                                           │ │
│ │              │   TeacherUNetModel(                                       │ │
│ │                (model): Unet(                                            │ │
│ │              │   (encoder): ResNetEncoder(                               │ │
│ │              │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │              2), padding=(3, 3), bias=False)                             │ │
│ │              │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │     (relu): ReLU(inplace=True)                            │ │
│ │              │     (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │              padding=1, dilation=1, ceil_mode=False)                     │ │
│ │              │     (layer1): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer2): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer3): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (5): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer4): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (decoder): UnetDecoder(                                 │ │
│ │              │     (center): Identity()                                  │ │
│ │              │     (blocks): ModuleList(                                 │ │
│ │              │   │   (0): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (segmentation_head): SegmentationHead(                  │ │
│ │              │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │              padding=(1, 1))                                             │ │
│ │              │     (1): Identity()                                       │ │
│ │              │     (2): Activation(                                      │ │
│ │              │   │   (activation): Identity()                            │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │                )                                                         │ │
│ │                (loss): BCEWithLogitsLoss()                               │ │
│ │                (train_f1): BinaryF1Score()                               │ │
│ │                (train_iou): BinaryJaccardIndex()                         │ │
│ │                (train_precision): BinaryPrecision()                      │ │
│ │                (train_recall): BinaryRecall()                            │ │
│ │                (val_f1): BinaryF1Score()                                 │ │
│ │                (val_iou): BinaryJaccardIndex()                           │ │
│ │                (val_precision): BinaryPrecision()                        │ │
│ │                (val_recall): BinaryRecall()                              │ │
│ │                (test_f1): BinaryF1Score()                                │ │
│ │                (test_iou): BinaryJaccardIndex()                          │ │
│ │                (test_precision): BinaryPrecision()                       │ │
│ │                (test_recall): BinaryRecall()                             │ │
│ │              ),                                                          │ │
│ │              │   <dataloader.WHUDataModule object at 0x7ed89e326560>,    │ │
│ │              │   None,                                                   │ │
│ │              │   None,                                                   │ │
│ │              │   None                                                    │ │
│ │              )                                                           │ │
│ │     kwargs = {}                                                          │ │
│ │    trainer = <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7ed89e9a0dc0>                                             │ │
│ │ trainer_fn = <bound method Trainer._fit_impl of                          │ │
│ │              <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7ed89e9a0dc0>>                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/launchers/subprocess_script.py:105 in launch       │
│                                                                              │
│   102 │   │   │   _launch_process_observer(self.procs)                       │
│   103 │   │                                                                  │
│   104 │   │   _set_num_threads_if_needed(num_processes=self.num_processes)   │
│ ❱ 105 │   │   return function(*args, **kwargs)                               │
│   106 │                                                                      │
│   107 │   @override                                                          │
│   108 │   def kill(self, signum: _SIGNUM) -> None:                           │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │     args = (                                                             │ │
│ │            │   TeacherUNetModel(                                         │ │
│ │              (model): Unet(                                              │ │
│ │            │   (encoder): ResNetEncoder(                                 │ │
│ │            │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │            2), padding=(3, 3), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │            padding=1, dilation=1, ceil_mode=False)                       │ │
│ │            │     (layer1): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer2): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer3): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (4): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (5): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer4): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (decoder): UnetDecoder(                                   │ │
│ │            │     (center): Identity()                                    │ │
│ │            │     (blocks): ModuleList(                                   │ │
│ │            │   │   (0): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (4): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (segmentation_head): SegmentationHead(                    │ │
│ │            │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │            padding=(1, 1))                                               │ │
│ │            │     (1): Identity()                                         │ │
│ │            │     (2): Activation(                                        │ │
│ │            │   │   (activation): Identity()                              │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (loss): BCEWithLogitsLoss()                                 │ │
│ │              (train_f1): BinaryF1Score()                                 │ │
│ │              (train_iou): BinaryJaccardIndex()                           │ │
│ │              (train_precision): BinaryPrecision()                        │ │
│ │              (train_recall): BinaryRecall()                              │ │
│ │              (val_f1): BinaryF1Score()                                   │ │
│ │              (val_iou): BinaryJaccardIndex()                             │ │
│ │              (val_precision): BinaryPrecision()                          │ │
│ │              (val_recall): BinaryRecall()                                │ │
│ │              (test_f1): BinaryF1Score()                                  │ │
│ │              (test_iou): BinaryJaccardIndex()                            │ │
│ │              (test_precision): BinaryPrecision()                         │ │
│ │              (test_recall): BinaryRecall()                               │ │
│ │            ),                                                            │ │
│ │            │   <dataloader.WHUDataModule object at 0x7ed89e326560>,      │ │
│ │            │   None,                                                     │ │
│ │            │   None,                                                     │ │
│ │            │   None                                                      │ │
│ │            )                                                             │ │
│ │ function = <bound method Trainer._fit_impl of                            │ │
│ │            <pytorch_lightning.trainer.trainer.Trainer object at          │ │
│ │            0x7ed89e9a0dc0>>                                              │ │
│ │   kwargs = {}                                                            │ │
│ │     self = <pytorch_lightning.strategies.launchers.subprocess_script._S… │ │
│ │            object at 0x7ed89e9a2a70>                                     │ │
│ │  trainer = <pytorch_lightning.trainer.trainer.Trainer object at          │ │
│ │            0x7ed89e9a0dc0>                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:574 in _fit_impl                           │
│                                                                              │
│    571 │   │   │   model_provided=True,                                      │
│    572 │   │   │   model_connected=self.lightning_module is not None,        │
│    573 │   │   )                                                             │
│ ❱  574 │   │   self._run(model, ckpt_path=ckpt_path)                         │
│    575 │   │                                                                 │
│    576 │   │   assert self.state.stopped                                     │
│    577 │   │   self.training = False                                         │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         ckpt_path = None                                                 │ │
│ │        datamodule = <dataloader.WHUDataModule object at 0x7ed89e326560>  │ │
│ │             model = TeacherUNetModel(                                    │ │
│ │                       (model): Unet(                                     │ │
│ │                     │   (encoder): ResNetEncoder(                        │ │
│ │                     │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),     │ │
│ │                     stride=(2, 2), padding=(3, 3), bias=False)           │ │
│ │                     │     (bn1): BatchNorm2d(64, eps=1e-05,              │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │     (relu): ReLU(inplace=True)                     │ │
│ │                     │     (maxpool): MaxPool2d(kernel_size=3, stride=2,  │ │
│ │                     padding=1, dilation=1, ceil_mode=False)              │ │
│ │                     │     (layer1): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer2): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 128, kernel_size=(3,   │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), │ │
│ │                     stride=(2, 2), bias=False)                           │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer3): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 256, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(128, 256, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (5): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer4): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 512, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(256, 512, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (decoder): UnetDecoder(                          │ │
│ │                     │     (center): Identity()                           │ │
│ │                     │     (blocks): ModuleList(                          │ │
│ │                     │   │   (0): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(768, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(256, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(384, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (segmentation_head): SegmentationHead(           │ │
│ │                     │     (0): Conv2d(16, 1, kernel_size=(3, 3),         │ │
│ │                     stride=(1, 1), padding=(1, 1))                       │ │
│ │                     │     (1): Identity()                                │ │
│ │                     │     (2): Activation(                               │ │
│ │                     │   │   (activation): Identity()                     │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                       )                                                  │ │
│ │                       (loss): BCEWithLogitsLoss()                        │ │
│ │                       (train_f1): BinaryF1Score()                        │ │
│ │                       (train_iou): BinaryJaccardIndex()                  │ │
│ │                       (train_precision): BinaryPrecision()               │ │
│ │                       (train_recall): BinaryRecall()                     │ │
│ │                       (val_f1): BinaryF1Score()                          │ │
│ │                       (val_iou): BinaryJaccardIndex()                    │ │
│ │                       (val_precision): BinaryPrecision()                 │ │
│ │                       (val_recall): BinaryRecall()                       │ │
│ │                       (test_f1): BinaryF1Score()                         │ │
│ │                       (test_iou): BinaryJaccardIndex()                   │ │
│ │                       (test_precision): BinaryPrecision()                │ │
│ │                       (test_recall): BinaryRecall()                      │ │
│ │                     )                                                    │ │
│ │              self = <pytorch_lightning.trainer.trainer.Trainer object at │ │
│ │                     0x7ed89e9a0dc0>                                      │ │
│ │ train_dataloaders = None                                                 │ │
│ │   val_dataloaders = None                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:981 in _run                                │
│                                                                              │
│    978 │   │   # ----------------------------                                │
│    979 │   │   # RUN THE TRAINER                                             │
│    980 │   │   # ----------------------------                                │
│ ❱  981 │   │   results = self._run_stage()                                   │
│    982 │   │                                                                 │
│    983 │   │   # ----------------------------                                │
│    984 │   │   # POST-Training CLEAN UP                                      │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │  ckpt_path = None                                                        │ │
│ │ max_epochs = 50                                                          │ │
│ │ min_epochs = 0                                                           │ │
│ │      model = TeacherUNetModel(                                           │ │
│ │                (model): Unet(                                            │ │
│ │              │   (encoder): ResNetEncoder(                               │ │
│ │              │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │              2), padding=(3, 3), bias=False)                             │ │
│ │              │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │     (relu): ReLU(inplace=True)                            │ │
│ │              │     (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │              padding=1, dilation=1, ceil_mode=False)                     │ │
│ │              │     (layer1): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer2): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer3): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (5): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer4): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (decoder): UnetDecoder(                                 │ │
│ │              │     (center): Identity()                                  │ │
│ │              │     (blocks): ModuleList(                                 │ │
│ │              │   │   (0): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (segmentation_head): SegmentationHead(                  │ │
│ │              │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │              padding=(1, 1))                                             │ │
│ │              │     (1): Identity()                                       │ │
│ │              │     (2): Activation(                                      │ │
│ │              │   │   (activation): Identity()                            │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │                )                                                         │ │
│ │                (loss): BCEWithLogitsLoss()                               │ │
│ │                (train_f1): BinaryF1Score()                               │ │
│ │                (train_iou): BinaryJaccardIndex()                         │ │
│ │                (train_precision): BinaryPrecision()                      │ │
│ │                (train_recall): BinaryRecall()                            │ │
│ │                (val_f1): BinaryF1Score()                                 │ │
│ │                (val_iou): BinaryJaccardIndex()                           │ │
│ │                (val_precision): BinaryPrecision()                        │ │
│ │                (val_recall): BinaryRecall()                              │ │
│ │                (test_f1): BinaryF1Score()                                │ │
│ │                (test_iou): BinaryJaccardIndex()                          │ │
│ │                (test_precision): BinaryPrecision()                       │ │
│ │                (test_recall): BinaryRecall()                             │ │
│ │              )                                                           │ │
│ │       self = <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7ed89e9a0dc0>                                             │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:1023 in _run_stage                         │
│                                                                              │
│   1020 │   │   │   return self.predict_loop.run()                            │
│   1021 │   │   if self.training:                                             │
│   1022 │   │   │   with isolate_rng():                                       │
│ ❱ 1023 │   │   │   │   self._run_sanity_check()                              │
│   1024 │   │   │   with torch.autograd.set_detect_anomaly(self._detect_anoma │
│   1025 │   │   │   │   self.fit_loop.run()                                   │
│   1026 │   │   │   return None                                               │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ self = <pytorch_lightning.trainer.trainer.Trainer object at              │ │
│ │        0x7ed89e9a0dc0>                                                   │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:1052 in _run_sanity_check                  │
│                                                                              │
│   1049 │   │   │   call._call_callback_hooks(self, "on_sanity_check_start")  │
│   1050 │   │   │                                                             │
│   1051 │   │   │   # run eval step                                           │
│ ❱ 1052 │   │   │   val_loop.run()                                            │
│   1053 │   │   │                                                             │
│   1054 │   │   │   call._call_callback_hooks(self, "on_sanity_check_end")    │
│   1055                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                self = <pytorch_lightning.trainer.trainer.Trainer object  │ │
│ │                       at 0x7ed89e9a0dc0>                                 │ │
│ │ should_sanity_check = True                                               │ │
│ │               stage = <RunningStage.TRAINING: 'train'>                   │ │
│ │            val_loop = <pytorch_lightning.loops.evaluation_loop._Evaluat… │ │
│ │                       object at 0x7ed89e9a16c0>                          │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/utilities.py:178 in _decorator                          │
│                                                                              │
│   175 │   │   else:                                                          │
│   176 │   │   │   context_manager = torch.no_grad                            │
│   177 │   │   with context_manager():                                        │
│ ❱ 178 │   │   │   return loop_run(self, *args, **kwargs)                     │
│   179 │                                                                      │
│   180 │   return _decorator                                                  │
│   181                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │            args = ()                                                     │ │
│ │ context_manager = <class 'torch.autograd.grad_mode.no_grad'>             │ │
│ │          kwargs = {}                                                     │ │
│ │        loop_run = <function _EvaluationLoop.run at 0x7ed8ba913e20>       │ │
│ │            self = <pytorch_lightning.loops.evaluation_loop._EvaluationL… │ │
│ │                   object at 0x7ed89e9a16c0>                              │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/evaluation_loop.py:135 in run                           │
│                                                                              │
│   132 │   │   │   │   previous_dataloader_idx = dataloader_idx               │
│   133 │   │   │   │   self.batch_progress.is_last_batch = data_fetcher.done  │
│   134 │   │   │   │   # run step hooks                                       │
│ ❱ 135 │   │   │   │   self._evaluation_step(batch, batch_idx, dataloader_idx │
│   136 │   │   │   except StopIteration:                                      │
│   137 │   │   │   │   # this needs to wrap the `*_step` call too (not just ` │
│   138 │   │   │   │   break                                                  │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                   batch = [                                              │ │
│ │                           │   tensor([[[[ 2.3164,  2.3446,  2.3149,      │ │
│ │                           ..., -0.6058, -0.6181, -0.7150],               │ │
│ │                           │   │     [ 1.4268,  1.3023,  1.1477,  ...,    │ │
│ │                           -0.3876, -0.7470, -1.0972],                    │ │
│ │                           │   │     [ 0.0779, -0.0593,  0.0045,  ...,    │ │
│ │                           -0.7834, -1.3672, -1.4232],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.6139, -0.5378, -0.6376,  ...,    │ │
│ │                           0.7786,  0.8201,  0.9101],                     │ │
│ │                           │   │     [-0.5613, -0.4577, -0.6747,  ...,    │ │
│ │                           0.7601,  0.7934,  0.8617],                     │ │
│ │                           │   │     [-0.3507, -0.2922, -0.4185,  ...,    │ │
│ │                           0.7168,  0.8312,  0.9036]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 2.0406,  2.0645,  2.0510,  ...,    │ │
│ │                           -0.4332, -0.3903, -0.5082],                    │ │
│ │                           │   │     [ 1.1315,  1.0024,  0.8545,  ...,    │ │
│ │                           -0.1651, -0.5269, -0.9126],                    │ │
│ │                           │   │     [ 0.0182, -0.1264,  0.0231,  ...,    │ │
│ │                           -0.6886, -1.3571, -1.3879],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2281, -0.1932, -0.2900,  ...,    │ │
│ │                           0.4864,  0.5149,  0.6028],                     │ │
│ │                           │   │     [-0.1770, -0.0489, -0.2525,  ...,    │ │
│ │                           0.4758,  0.5133,  0.5956],                     │ │
│ │                           │   │     [ 0.0319,  0.1804,  0.0335,  ...,    │ │
│ │                           0.4438,  0.5766,  0.6924]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.8773,  1.9022,  1.8847,  ...,    │ │
│ │                           -0.4057, -0.4887, -0.5277],                    │ │
│ │                           │   │     [ 0.9649,  0.8121,  0.6603,  ...,    │ │
│ │                           -0.1638, -0.5726, -0.8895],                    │ │
│ │                           │   │     [ 0.0210, -0.0865,  0.0234,  ...,    │ │
│ │                           -0.5850, -1.2241, -1.2979],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.4361, -0.4343, -0.5230,  ...,    │ │
│ │                           0.4143,  0.4844,  0.5816],                     │ │
│ │                           │   │     [-0.2906, -0.2463, -0.5730,  ...,    │ │
│ │                           0.4011,  0.4917,  0.5691],                     │ │
│ │                           │   │     [ 0.0091,  0.0706, -0.2163,  ...,    │ │
│ │                           0.3680,  0.5424,  0.6669]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,    │ │
│ │                           -0.2612, -0.4125, -0.2770],                    │ │
│ │                           │   │     [ 0.6888,  0.5887,  0.5071,  ...,    │ │
│ │                           -0.1710, -0.2637, -0.5444],                    │ │
│ │                           │   │     [ 1.1148,  0.1169, -0.1676,  ...,    │ │
│ │                           0.1911,  0.3721, -0.2837],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.4486, -0.5441, -0.9948,  ...,    │ │
│ │                           1.4529,  1.5731,  1.6655],                     │ │
│ │                           │   │     [-0.8471, -0.8097, -0.5052,  ...,    │ │
│ │                           1.6699,  1.6633,  1.5620],                     │ │
│ │                           │   │     [-1.2547, -0.6262, -0.1167,  ...,    │ │
│ │                           2.0572,  1.8766,  1.8721]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 0.3655,  0.4483,  0.3462,  ...,    │ │
│ │                           0.0064, -0.0699,  0.0557],                     │ │
│ │                           │   │     [ 0.4605,  0.3635,  0.2722,  ...,    │ │
│ │                           0.0618,  0.0547, -0.1675],                     │ │
│ │                           │   │     [ 0.9666,  0.1626, -0.0085,  ...,    │ │
│ │                           0.3880,  0.6220,  0.0236],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2760, -0.2201, -0.7969,  ...,    │ │
│ │                           1.5642,  1.7006,  1.7636],                     │ │
│ │                           │   │     [-0.9533, -0.6040, -0.2027,  ...,    │ │
│ │                           1.7120,  1.7452,  1.6086],                     │ │
│ │                           │   │     [-1.4558, -0.4432,  0.2369,  ...,    │ │
│ │                           1.9949,  1.9005,  1.8320]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 0.2965,  0.3601,  0.3009,  ...,    │ │
│ │                           0.0602, -0.1504, -0.0534],                     │ │
│ │                           │   │     [ 0.4160,  0.2953,  0.2230,  ...,    │ │
│ │                           0.1778, -0.0084, -0.3465],                     │ │
│ │                           │   │     [ 0.9099,  0.0840, -0.1021,  ...,    │ │
│ │                           0.5869,  0.6836, -0.0941],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.3519, -0.4613, -0.9606,  ...,    │ │
│ │                           1.4837,  1.5997,  1.6536],                     │ │
│ │                           │   │     [-0.8312, -0.7609, -0.3011,  ...,    │ │
│ │                           1.6274,  1.6373,  1.4997],                     │ │
│ │                           │   │     [-1.3824, -0.5392,  0.2546,  ...,    │ │
│ │                           1.8659,  1.7704,  1.7204]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,    │ │
│ │                           0.5743,  0.6527,  0.1973],                     │ │
│ │                           │   │     [-0.1900,  0.1981,  0.3613,  ...,    │ │
│ │                           -0.4840, -0.7741, -0.6588],                    │ │
│ │                           │   │     [-0.4079, -0.5727, -0.7945,  ...,    │ │
│ │                           -0.9792, -0.8624, -0.8335],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5236, -1.5460, -1.5493,  ...,    │ │
│ │                           0.8791,  1.3495,  1.2763],                     │ │
│ │                           │   │     [-1.5478, -1.5571, -0.9722,  ...,    │ │
│ │                           1.0991,  1.2270,  1.1958],                     │ │
│ │                           │   │     [-1.5594, -1.5262, -1.3078,  ...,    │ │
│ │                           1.2170,  1.2479,  1.2777]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.2511,  2.0410,  2.2335,  ...,    │ │
│ │                           0.4876,  0.6290,  0.2545],                     │ │
│ │                           │   │     [-0.3203,  0.2990,  0.5133,  ...,    │ │
│ │                           -0.1165, -0.2367, -0.0257],                    │ │
│ │                           │   │     [-0.1477, -0.1331, -0.3114,  ...,    │ │
│ │                           -0.7581, -0.6202, -0.5923],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.8475, -1.8564, -1.9051,  ...,    │ │
│ │                           1.0213,  1.5171,  1.4460],                     │ │
│ │                           │   │     [-1.8560, -1.8576, -1.2073,  ...,    │ │
│ │                           1.4468,  1.5998,  1.5811],                     │ │
│ │                           │   │     [-1.9128, -1.8755, -1.5804,  ...,    │ │
│ │                           1.6565,  1.6719,  1.6993]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.3119,  1.9435,  2.1157,  ...,    │ │
│ │                           0.4802,  0.4811,  0.0363],                     │ │
│ │                           │   │     [-0.1179,  0.2318,  0.3654,  ...,    │ │
│ │                           -0.1602, -0.5587, -0.5162],                    │ │
│ │                           │   │     [-0.1421, -0.2981, -0.5722,  ...,    │ │
│ │                           -0.8887, -0.8376, -0.8337],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.7000, -1.7201, -1.7387,  ...,    │ │
│ │                           1.3972,  1.9169,  1.9397],                     │ │
│ │                           │   │     [-1.7279, -1.7529, -1.1157,  ...,    │ │
│ │                           2.0661,  2.2213,  2.2087],                     │ │
│ │                           │   │     [-1.7323, -1.6954, -1.4618,  ...,    │ │
│ │                           2.2354,  2.2530,  2.2691]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   ...,                                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-1.0599, -1.0722, -0.8373,  ...,    │ │
│ │                           -0.8042, -0.7623, -0.7780],                    │ │
│ │                           │   │     [-1.0798, -0.9996, -1.0004,  ...,    │ │
│ │                           -0.8416, -0.7748, -0.8144],                    │ │
│ │                           │   │     [-0.8928, -0.8869, -0.8661,  ...,    │ │
│ │                           -0.7878, -0.9039, -0.9166],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.8657, -0.9139, -0.9354,  ...,    │ │
│ │                           -0.7860, -0.6917, -0.2532],                    │ │
│ │                           │   │     [-0.9836, -1.0682, -1.0412,  ...,    │ │
│ │                           -0.5871, -0.4002, -0.4672],                    │ │
│ │                           │   │     [-0.9863, -1.0090, -1.0853,  ...,    │ │
│ │                           -0.6160, -0.5219, -0.7189]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.6332, -0.7097, -0.4215,  ...,    │ │
│ │                           -0.1901, -0.1644, -0.2325],                    │ │
│ │                           │   │     [-0.6487, -0.6316, -0.5818,  ...,    │ │
│ │                           -0.2829, -0.2394, -0.3049],                    │ │
│ │                           │   │     [-0.3767, -0.4395, -0.4375,  ...,    │ │
│ │                           -0.2110, -0.4470, -0.5231],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2565, -0.2205, -0.2220,  ...,    │ │
│ │                           -0.3818, -0.3438,  0.1731],                    │ │
│ │                           │   │     [-0.4657, -0.5518, -0.5182,  ...,    │ │
│ │                           -0.2438, -0.0176, -0.0727],                    │ │
│ │                           │   │     [-0.3987, -0.4983, -0.6036,  ...,    │ │
│ │                           -0.3505, -0.2082, -0.3332]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.0878, -1.1527, -0.9100,  ...,    │ │
│ │                           -0.7169, -0.7085, -0.7336],                    │ │
│ │                           │   │     [-1.1135, -1.0810, -1.0489,  ...,    │ │
│ │                           -0.7306, -0.6846, -0.7594],                    │ │
│ │                           │   │     [-0.9125, -0.9624, -0.9069,  ...,    │ │
│ │                           -0.6095, -0.7978, -0.8245],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.7285, -0.7857, -0.7854,  ...,    │ │
│ │                           -0.7182, -0.6215,  0.1228],                    │ │
│ │                           │   │     [-0.9004, -1.0222, -0.9365,  ...,    │ │
│ │                           -0.4408, -0.2605, -0.2418],                    │ │
│ │                           │   │     [-0.8313, -0.9434, -0.9788,  ...,    │ │
│ │                           -0.4678, -0.4024, -0.5858]]],                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-0.7077, -0.4473, -0.6266,  ...,    │ │
│ │                           -0.7038, -0.6567, -0.7818],                    │ │
│ │                           │   │     [-0.8280, -0.4161, -0.5953,  ...,    │ │
│ │                           -0.8468, -0.4521, -0.5808],                    │ │
│ │                           │   │     [-0.5753, -0.5170, -0.6090,  ...,    │ │
│ │                           -0.7919, -0.5200, -0.4384],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.1959, -0.6135, -0.5363,  ...,    │ │
│ │                           -1.3624, -0.8494, -0.1735],                    │ │
│ │                           │   │     [-0.4295, -0.6888, -0.4310,  ...,    │ │
│ │                           -0.3587, -0.2537, -0.3986],                    │ │
│ │                           │   │     [-0.5943, -0.6783, -0.7139,  ...,    │ │
│ │                           -0.3507, -0.4791, -0.6006]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.2072,  0.0127, -0.1702,  ...,    │ │
│ │                           -0.3419, -0.2687, -0.4003],                    │ │
│ │                           │   │     [-0.3858,  0.0282, -0.1687,  ...,    │ │
│ │                           -0.4790, -0.0354, -0.1698],                    │ │
│ │                           │   │     [-0.2005, -0.1149, -0.1699,  ...,    │ │
│ │                           -0.3153,  0.0203,  0.0299],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [ 0.1754, -0.2889, -0.1054,  ...,    │ │
│ │                           -1.4425, -0.7123,  0.3566],                    │ │
│ │                           │   │     [-0.1350, -0.4375, -0.0643,  ...,    │ │
│ │                           0.0931,  0.2030,  0.0399],                     │ │
│ │                           │   │     [-0.3228, -0.4490, -0.4441,  ...,    │ │
│ │                           0.1140, -0.0388, -0.1875]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.6597, -0.3586, -0.4449,  ...,    │ │
│ │                           -0.6856, -0.6522, -0.7503],                    │ │
│ │                           │   │     [-0.7248, -0.2678, -0.3945,  ...,    │ │
│ │                           -0.8226, -0.4105, -0.5004],                    │ │
│ │                           │   │     [-0.2626, -0.1671, -0.3766,  ...,    │ │
│ │                           -0.6941, -0.3854, -0.3569],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [ 0.2934, -0.4135, -0.2755,  ...,    │ │
│ │                           -1.2591, -0.5653,  0.2921],                    │ │
│ │                           │   │     [-0.1146, -0.5248, -0.1897,  ...,    │ │
│ │                           0.0059,  0.1336, -0.1004],                     │ │
│ │                           │   │     [-0.4185, -0.6055, -0.5559,  ...,    │ │
│ │                           -0.0995, -0.2689, -0.3513]]],                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-1.3826, -1.5758, -1.3897,  ...,    │ │
│ │                           1.1593,  1.1517,  1.0863],                     │ │
│ │                           │   │     [-1.4554, -1.4403, -1.1914,  ...,    │ │
│ │                           1.1762,  1.1228,  1.1525],                     │ │
│ │                           │   │     [-1.4418, -1.2993, -1.0208,  ...,    │ │
│ │                           1.3535,  1.1681,  1.1589],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5414, -0.6903, -0.7511,  ...,    │ │
│ │                           -0.5200, -0.5756, -0.5779],                    │ │
│ │                           │   │     [-1.5643, -0.7541, -0.6268,  ...,    │ │
│ │                           -0.5044, -0.6458, -0.6436],                    │ │
│ │                           │   │     [-1.4533, -0.6317, -0.1612,  ...,    │ │
│ │                           -0.3613, -0.7063, -0.7261]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.3448, -1.5791, -1.2935,  ...,    │ │
│ │                           0.5572,  0.5726,  0.5173],                     │ │
│ │                           │   │     [-1.4295, -1.4998, -1.0167,  ...,    │ │
│ │                           0.5924,  0.5592,  0.5988],                     │ │
│ │                           │   │     [-1.3550, -1.2938, -1.0301,  ...,    │ │
│ │                           0.7972,  0.6153,  0.6056],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.7982, -0.8752, -0.6012,  ...,    │ │
│ │                           -0.0912, -0.1196, -0.1621],                    │ │
│ │                           │   │     [-1.8009, -0.8427, -0.3782,  ...,    │ │
│ │                           -0.0841, -0.1920, -0.2276],                    │ │
│ │                           │   │     [-1.6954, -0.7387, -0.0568,  ...,    │ │
│ │                           0.0218, -0.2507, -0.3032]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.4091, -1.6641, -1.4289,  ...,    │ │
│ │                           0.2938,  0.2579,  0.1735],                     │ │
│ │                           │   │     [-1.4810, -1.5788, -1.2095,  ...,    │ │
│ │                           0.2887,  0.2026,  0.2187],                     │ │
│ │                           │   │     [-1.4501, -1.4066, -1.1120,  ...,    │ │
│ │                           0.4428,  0.2340,  0.2250],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5457, -0.7003, -0.6430,  ...,    │ │
│ │                           -0.3908, -0.4467, -0.4766],                    │ │
│ │                           │   │     [-1.6041, -0.7394, -0.4135,  ...,    │ │
│ │                           -0.3832, -0.5244, -0.5442],                    │ │
│ │                           │   │     [-1.5440, -0.6222, -0.0975,  ...,    │ │
│ │                           -0.2572, -0.5930, -0.6154]]]],                 │ │
│ │                           │      dtype=torch.float64),                   │ │
│ │                           │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,  │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.]]]],                                │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.]]]],                                │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   ...,                                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]]])                                 │ │
│ │                           ]                                              │ │
│ │               batch_idx = 0                                              │ │
│ │            data_fetcher = <pytorch_lightning.loops.fetchers._PrefetchDa… │ │
│ │                           object at 0x7ed89c51e0b0>                      │ │
│ │          dataloader_idx = 0                                              │ │
│ │         dataloader_iter = None                                           │ │
│ │ previous_dataloader_idx = 0                                              │ │
│ │                    self = <pytorch_lightning.loops.evaluation_loop._Eva… │ │
│ │                           object at 0x7ed89e9a16c0>                      │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/evaluation_loop.py:396 in _evaluation_step              │
│                                                                              │
│   393 │   │   │   if not using_dataloader_iter                               │
│   394 │   │   │   else (dataloader_iter,)                                    │
│   395 │   │   )                                                              │
│ ❱ 396 │   │   output = call._call_strategy_hook(trainer, hook_name, *step_ar │
│   397 │   │                                                                  │
│   398 │   │   self.batch_progress.increment_processed()                      │
│   399                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                 batch = [                                                │ │
│ │                         │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,  │ │
│ │                         -0.6058, -0.6181, -0.7150],                      │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0', dtype=torch.float64),    │ │
│ │                         │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,    │ │
│ │                         0.,   0.],                                       │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')                        │ │
│ │                         ]                                                │ │
│ │             batch_idx = 0                                                │ │
│ │          data_fetcher = <pytorch_lightning.loops.fetchers._PrefetchData… │ │
│ │                         object at 0x7ed89c51e0b0>                        │ │
│ │        dataloader_idx = 0                                                │ │
│ │       dataloader_iter = None                                             │ │
│ │           hook_kwargs = OrderedDict([('batch', [tensor([[[[ 2.3164,      │ │
│ │                         2.3446,  2.3149,  ..., -0.6058, -0.6181,         │ │
│ │                         -0.7150],                                        │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0', dtype=torch.float64),    │ │
│ │                         tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')]), ('batch_idx', 0)])  │ │
│ │             hook_name = 'validation_step'                                │ │
│ │                  self = <pytorch_lightning.loops.evaluation_loop._Evalu… │ │
│ │                         object at 0x7ed89e9a16c0>                        │ │
│ │             step_args = (                                                │ │
│ │                         │   [                                            │ │
│ │                         │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,    │ │
│ │                         ..., -0.6058, -0.6181, -0.7150],                 │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0', dtype=torch.float64),    │ │
│ │                         │   │   tensor([[[[[  0.,   0.,   0.,  ...,      │ │
│ │                         0.,   0.,   0.],                                 │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')                        │ │
│ │                         │   ],                                           │ │
│ │                         │   0                                            │ │
│ │                         )                                                │ │
│ │               trainer = <pytorch_lightning.trainer.trainer.Trainer       │ │
│ │                         object at 0x7ed89e9a0dc0>                        │ │
│ │ using_dataloader_iter = False                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/call.py:319 in _call_strategy_hook                    │
│                                                                              │
│   316 │   │   return None                                                    │
│   317 │                                                                      │
│   318 │   with trainer.profiler.profile(f"[Strategy]{trainer.strategy.__clas │
│ ❱ 319 │   │   output = fn(*args, **kwargs)                                   │
│   320 │                                                                      │
│   321 │   # restore current_fx when nested context                           │
│   322 │   pl_module._current_fx_name = prev_fx_name                          │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │           fn = <bound method Strategy.validation_step of                 │ │
│ │                <pytorch_lightning.strategies.ddp.DDPStrategy object at   │ │
│ │                0x7ed89e9a03d0>>                                          │ │
│ │    hook_name = 'validation_step'                                         │ │
│ │       kwargs = {}                                                        │ │
│ │    pl_module = TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )                                                         │ │
│ │ prev_fx_name = None                                                      │ │
│ │      trainer = <pytorch_lightning.trainer.trainer.Trainer object at      │ │
│ │                0x7ed89e9a0dc0>                                           │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:410 in validation_step                 │
│                                                                              │
│   407 │   │   assert self.model is not None                                  │
│   408 │   │   with self.precision_plugin.val_step_context():                 │
│   409 │   │   │   if self.model != self.lightning_module:                    │
│ ❱ 410 │   │   │   │   return self._forward_redirection(self.model, self.ligh │
│   411 │   │   │   return self.lightning_module.validation_step(*args, **kwar │
│   412 │                                                                      │
│   413 │   def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:     │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = <pytorch_lightning.strategies.ddp.DDPStrategy object at         │ │
│ │          0x7ed89e9a03d0>                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:640 in __call__                        │
│                                                                              │
│   637 │   │   # Patch the original_module's forward so we can redirect the a │
│   638 │   │   original_module.forward = wrapped_forward  # type: ignore[meth │
│   639 │   │                                                                  │
│ ❱ 640 │   │   wrapper_output = wrapper_module(*args, **kwargs)               │
│   641 │   │   self.on_after_outer_forward(wrapper_module, original_module)   │
│   642 │   │   return wrapper_output                                          │
│   643                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │             args = (                                                     │ │
│ │                    │   [                                                 │ │
│ │                    │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,   │ │
│ │                    -0.6058, -0.6181, -0.7150],                           │ │
│ │                    │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,  │ │
│ │                    -0.7470, -1.0972],                                    │ │
│ │                    │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,  │ │
│ │                    -1.3672, -1.4232],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  │ │
│ │                    0.8201,  0.9101],                                     │ │
│ │                    │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  │ │
│ │                    0.7934,  0.8617],                                     │ │
│ │                    │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  │ │
│ │                    0.8312,  0.9036]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,  │ │
│ │                    -0.3903, -0.5082],                                    │ │
│ │                    │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,  │ │
│ │                    -0.5269, -0.9126],                                    │ │
│ │                    │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,  │ │
│ │                    -1.3571, -1.3879],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  │ │
│ │                    0.5149,  0.6028],                                     │ │
│ │                    │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  │ │
│ │                    0.5133,  0.5956],                                     │ │
│ │                    │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  │ │
│ │                    0.5766,  0.6924]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,  │ │
│ │                    -0.4887, -0.5277],                                    │ │
│ │                    │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,  │ │
│ │                    -0.5726, -0.8895],                                    │ │
│ │                    │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,  │ │
│ │                    -1.2241, -1.2979],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  │ │
│ │                    0.4844,  0.5816],                                     │ │
│ │                    │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  │ │
│ │                    0.4917,  0.5691],                                     │ │
│ │                    │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  │ │
│ │                    0.5424,  0.6669]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,  │ │
│ │                    -0.4125, -0.2770],                                    │ │
│ │                    │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,  │ │
│ │                    -0.2637, -0.5444],                                    │ │
│ │                    │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  │ │
│ │                    0.3721, -0.2837],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  │ │
│ │                    1.5731,  1.6655],                                     │ │
│ │                    │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  │ │
│ │                    1.6633,  1.5620],                                     │ │
│ │                    │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  │ │
│ │                    1.8766,  1.8721]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,  │ │
│ │                    -0.0699,  0.0557],                                    │ │
│ │                    │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  │ │
│ │                    0.0547, -0.1675],                                     │ │
│ │                    │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  │ │
│ │                    0.6220,  0.0236],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  │ │
│ │                    1.7006,  1.7636],                                     │ │
│ │                    │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  │ │
│ │                    1.7452,  1.6086],                                     │ │
│ │                    │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  │ │
│ │                    1.9005,  1.8320]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,  │ │
│ │                    -0.1504, -0.0534],                                    │ │
│ │                    │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,  │ │
│ │                    -0.0084, -0.3465],                                    │ │
│ │                    │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  │ │
│ │                    0.6836, -0.0941],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  │ │
│ │                    1.5997,  1.6536],                                     │ │
│ │                    │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  │ │
│ │                    1.6373,  1.4997],                                     │ │
│ │                    │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  │ │
│ │                    1.7704,  1.7204]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  │ │
│ │                    0.6527,  0.1973],                                     │ │
│ │                    │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,  │ │
│ │                    -0.7741, -0.6588],                                    │ │
│ │                    │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,  │ │
│ │                    -0.8624, -0.8335],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  │ │
│ │                    1.3495,  1.2763],                                     │ │
│ │                    │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  │ │
│ │                    1.2270,  1.1958],                                     │ │
│ │                    │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  │ │
│ │                    1.2479,  1.2777]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  │ │
│ │                    0.6290,  0.2545],                                     │ │
│ │                    │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,  │ │
│ │                    -0.2367, -0.0257],                                    │ │
│ │                    │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,  │ │
│ │                    -0.6202, -0.5923],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  │ │
│ │                    1.5171,  1.4460],                                     │ │
│ │                    │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  │ │
│ │                    1.5998,  1.5811],                                     │ │
│ │                    │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  │ │
│ │                    1.6719,  1.6993]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  │ │
│ │                    0.4811,  0.0363],                                     │ │
│ │                    │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,  │ │
│ │                    -0.5587, -0.5162],                                    │ │
│ │                    │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,  │ │
│ │                    -0.8376, -0.8337],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  │ │
│ │                    1.9169,  1.9397],                                     │ │
│ │                    │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  │ │
│ │                    2.2213,  2.2087],                                     │ │
│ │                    │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  │ │
│ │                    2.2530,  2.2691]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,  │ │
│ │                    -0.7623, -0.7780],                                    │ │
│ │                    │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,  │ │
│ │                    -0.7748, -0.8144],                                    │ │
│ │                    │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,  │ │
│ │                    -0.9039, -0.9166],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,  │ │
│ │                    -0.6917, -0.2532],                                    │ │
│ │                    │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,  │ │
│ │                    -0.4002, -0.4672],                                    │ │
│ │                    │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,  │ │
│ │                    -0.5219, -0.7189]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,  │ │
│ │                    -0.1644, -0.2325],                                    │ │
│ │                    │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,  │ │
│ │                    -0.2394, -0.3049],                                    │ │
│ │                    │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,  │ │
│ │                    -0.4470, -0.5231],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,  │ │
│ │                    -0.3438,  0.1731],                                    │ │
│ │                    │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,  │ │
│ │                    -0.0176, -0.0727],                                    │ │
│ │                    │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,  │ │
│ │                    -0.2082, -0.3332]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,  │ │
│ │                    -0.7085, -0.7336],                                    │ │
│ │                    │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,  │ │
│ │                    -0.6846, -0.7594],                                    │ │
│ │                    │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,  │ │
│ │                    -0.7978, -0.8245],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,  │ │
│ │                    -0.6215,  0.1228],                                    │ │
│ │                    │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,  │ │
│ │                    -0.2605, -0.2418],                                    │ │
│ │                    │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,  │ │
│ │                    -0.4024, -0.5858]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,  │ │
│ │                    -0.6567, -0.7818],                                    │ │
│ │                    │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,  │ │
│ │                    -0.4521, -0.5808],                                    │ │
│ │                    │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,  │ │
│ │                    -0.5200, -0.4384],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,  │ │
│ │                    -0.8494, -0.1735],                                    │ │
│ │                    │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,  │ │
│ │                    -0.2537, -0.3986],                                    │ │
│ │                    │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,  │ │
│ │                    -0.4791, -0.6006]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,  │ │
│ │                    -0.2687, -0.4003],                                    │ │
│ │                    │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,  │ │
│ │                    -0.0354, -0.1698],                                    │ │
│ │                    │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  │ │
│ │                    0.0203,  0.0299],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,  │ │
│ │                    -0.7123,  0.3566],                                    │ │
│ │                    │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  │ │
│ │                    0.2030,  0.0399],                                     │ │
│ │                    │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,  │ │
│ │                    -0.0388, -0.1875]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,  │ │
│ │                    -0.6522, -0.7503],                                    │ │
│ │                    │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,  │ │
│ │                    -0.4105, -0.5004],                                    │ │
│ │                    │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,  │ │
│ │                    -0.3854, -0.3569],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,  │ │
│ │                    -0.5653,  0.2921],                                    │ │
│ │                    │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  │ │
│ │                    0.1336, -0.1004],                                     │ │
│ │                    │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,  │ │
│ │                    -0.2689, -0.3513]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  │ │
│ │                    1.1517,  1.0863],                                     │ │
│ │                    │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  │ │
│ │                    1.1228,  1.1525],                                     │ │
│ │                    │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  │ │
│ │                    1.1681,  1.1589],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,  │ │
│ │                    -0.5756, -0.5779],                                    │ │
│ │                    │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,  │ │
│ │                    -0.6458, -0.6436],                                    │ │
│ │                    │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,  │ │
│ │                    -0.7063, -0.7261]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  │ │
│ │                    0.5726,  0.5173],                                     │ │
│ │                    │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  │ │
│ │                    0.5592,  0.5988],                                     │ │
│ │                    │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  │ │
│ │                    0.6153,  0.6056],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,  │ │
│ │                    -0.1196, -0.1621],                                    │ │
│ │                    │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,  │ │
│ │                    -0.1920, -0.2276],                                    │ │
│ │                    │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,  │ │
│ │                    -0.2507, -0.3032]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  │ │
│ │                    0.2579,  0.1735],                                     │ │
│ │                    │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  │ │
│ │                    0.2026,  0.2187],                                     │ │
│ │                    │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  │ │
│ │                    0.2340,  0.2250],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,  │ │
│ │                    -0.4467, -0.4766],                                    │ │
│ │                    │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,  │ │
│ │                    -0.5244, -0.5442],                                    │ │
│ │                    │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,  │ │
│ │                    -0.5930, -0.6154]]]],                                 │ │
│ │                    │      device='cuda:0', dtype=torch.float64),         │ │
│ │                    │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,     │ │
│ │                    0.,   0.],                                            │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]]], device='cuda:0')                             │ │
│ │                    │   ],                                                │ │
│ │                    │   0                                                 │ │
│ │                    )                                                     │ │
│ │           kwargs = {}                                                    │ │
│ │      method_name = 'validation_step'                                     │ │
│ │ original_forward = <bound method TeacherUNetModel.forward of             │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │  original_module = TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )                                                     │ │
│ │             self = <pytorch_lightning.strategies.ddp._DDPForwardRedirec… │ │
│ │                    object at 0x7ed89e9a06a0>                             │ │
│ │  wrapped_forward = <function                                             │ │
│ │                    _ForwardRedirection.__call__.<locals>.wrapped_forward │ │
│ │                    at 0x7ed89c58edd0>                                    │ │
│ │   wrapper_module = DistributedDataParallel(                              │ │
│ │                      (module): TeacherUNetModel(                         │ │
│ │                    │   (model): Unet(                                    │ │
│ │                    │     (encoder): ResNetEncoder(                       │ │
│ │                    │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),    │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   (relu): ReLU(inplace=True)                    │ │
│ │                    │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2, │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │   │   (layer1): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer2): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3,  │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(64, 128, kernel_size=(1,    │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer3): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(128, 256, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (5): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer4): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(256, 512, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (decoder): UnetDecoder(                         │ │
│ │                    │   │   (center): Identity()                          │ │
│ │                    │   │   (blocks): ModuleList(                         │ │
│ │                    │   │     (0): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(768, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(384, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(192, 64, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 32, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (segmentation_head): SegmentationHead(          │ │
│ │                    │   │   (0): Conv2d(16, 1, kernel_size=(3, 3),        │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │   │   (1): Identity()                               │ │
│ │                    │   │   (2): Activation(                              │ │
│ │                    │   │     (activation): Identity()                    │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (loss): BCEWithLogitsLoss()                       │ │
│ │                    │   (train_f1): BinaryF1Score()                       │ │
│ │                    │   (train_iou): BinaryJaccardIndex()                 │ │
│ │                    │   (train_precision): BinaryPrecision()              │ │
│ │                    │   (train_recall): BinaryRecall()                    │ │
│ │                    │   (val_f1): BinaryF1Score()                         │ │
│ │                    │   (val_iou): BinaryJaccardIndex()                   │ │
│ │                    │   (val_precision): BinaryPrecision()                │ │
│ │                    │   (val_recall): BinaryRecall()                      │ │
│ │                    │   (test_f1): BinaryF1Score()                        │ │
│ │                    │   (test_iou): BinaryJaccardIndex()                  │ │
│ │                    │   (test_precision): BinaryPrecision()               │ │
│ │                    │   (test_recall): BinaryRecall()                     │ │
│ │                      )                                                   │ │
│ │                    )                                                     │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method DistributedDataParallel.forward of          │ │
│ │                DistributedDataParallel(                                  │ │
│ │                  (module): TeacherUNetModel(                             │ │
│ │                │   (model): Unet(                                        │ │
│ │                │     (encoder): ResNetEncoder(                           │ │
│ │                │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),        │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,     │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   │   (layer1): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer2): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),  │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),    │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer3): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (5): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer4): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (decoder): UnetDecoder(                             │ │
│ │                │   │   (center): Identity()                              │ │
│ │                │   │   (blocks): ModuleList(                             │ │
│ │                │   │     (0): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (segmentation_head): SegmentationHead(              │ │
│ │                │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │   │   (1): Identity()                                   │ │
│ │                │   │   (2): Activation(                                  │ │
│ │                │   │     (activation): Identity()                        │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (loss): BCEWithLogitsLoss()                           │ │
│ │                │   (train_f1): BinaryF1Score()                           │ │
│ │                │   (train_iou): BinaryJaccardIndex()                     │ │
│ │                │   (train_precision): BinaryPrecision()                  │ │
│ │                │   (train_recall): BinaryRecall()                        │ │
│ │                │   (val_f1): BinaryF1Score()                             │ │
│ │                │   (val_iou): BinaryJaccardIndex()                       │ │
│ │                │   (val_precision): BinaryPrecision()                    │ │
│ │                │   (val_recall): BinaryRecall()                          │ │
│ │                │   (test_f1): BinaryF1Score()                            │ │
│ │                │   (test_iou): BinaryJaccardIndex()                      │ │
│ │                │   (test_precision): BinaryPrecision()                   │ │
│ │                │   (test_recall): BinaryRecall()                         │ │
│ │                  )                                                       │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = DistributedDataParallel(                                  │ │
│ │                  (module): TeacherUNetModel(                             │ │
│ │                │   (model): Unet(                                        │ │
│ │                │     (encoder): ResNetEncoder(                           │ │
│ │                │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),        │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,     │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   │   (layer1): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer2): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),  │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),    │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer3): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (5): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer4): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (decoder): UnetDecoder(                             │ │
│ │                │   │   (center): Identity()                              │ │
│ │                │   │   (blocks): ModuleList(                             │ │
│ │                │   │     (0): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (segmentation_head): SegmentationHead(              │ │
│ │                │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │   │   (1): Identity()                                   │ │
│ │                │   │   (2): Activation(                                  │ │
│ │                │   │     (activation): Identity()                        │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (loss): BCEWithLogitsLoss()                           │ │
│ │                │   (train_f1): BinaryF1Score()                           │ │
│ │                │   (train_iou): BinaryJaccardIndex()                     │ │
│ │                │   (train_precision): BinaryPrecision()                  │ │
│ │                │   (train_recall): BinaryRecall()                        │ │
│ │                │   (val_f1): BinaryF1Score()                             │ │
│ │                │   (val_iou): BinaryJaccardIndex()                       │ │
│ │                │   (val_precision): BinaryPrecision()                    │ │
│ │                │   (val_recall): BinaryRecall()                          │ │
│ │                │   (test_f1): BinaryF1Score()                            │ │
│ │                │   (test_iou): BinaryJaccardIndex()                      │ │
│ │                │   (test_precision): BinaryPrecision()                   │ │
│ │                │   (test_recall): BinaryRecall()                         │ │
│ │                  )                                                       │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/parallel/distributed.py:1523 in forward                                │
│                                                                              │
│   1520 │   │   │   output = (                                                │
│   1521 │   │   │   │   self.module.forward(*inputs, **kwargs)                │
│   1522 │   │   │   │   if self._delay_all_reduce_all_params                  │
│ ❱ 1523 │   │   │   │   else self._run_ddp_forward(*inputs, **kwargs)         │
│   1524 │   │   │   )                                                         │
│   1525 │   │   │   return self._post_forward(output)                         │
│   1526                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ inputs = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/parallel/distributed.py:1359 in _run_ddp_forward                       │
│                                                                              │
│   1356 │                                                                     │
│   1357 │   def _run_ddp_forward(self, *inputs, **kwargs):                    │
│   1358 │   │   with self._inside_ddp_forward():                              │
│ ❱ 1359 │   │   │   return self.module(*inputs, **kwargs)  # type: ignore[ind │
│   1360 │                                                                     │
│   1361 │   def _clear_grad_buffer(self):                                     │
│   1362 │   │   # Making param.grad points to the grad buffers before backwar │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ inputs = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = TeacherUNetModel(                                               │ │
│ │            (model): Unet(                                                │ │
│ │          │   (encoder): ResNetEncoder(                                   │ │
│ │          │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,  │ │
│ │          dilation=1, ceil_mode=False)                                    │ │
│ │          │     (layer1): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer2): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),          │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer3): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (5): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer4): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (decoder): UnetDecoder(                                     │ │
│ │          │     (center): Identity()                                      │ │
│ │          │     (blocks): ModuleList(                                     │ │
│ │          │   │   (0): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (segmentation_head): SegmentationHead(                      │ │
│ │          │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),     │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │     (1): Identity()                                           │ │
│ │          │     (2): Activation(                                          │ │
│ │          │   │   (activation): Identity()                                │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (loss): BCEWithLogitsLoss()                                   │ │
│ │            (train_f1): BinaryF1Score()                                   │ │
│ │            (train_iou): BinaryJaccardIndex()                             │ │
│ │            (train_precision): BinaryPrecision()                          │ │
│ │            (train_recall): BinaryRecall()                                │ │
│ │            (val_f1): BinaryF1Score()                                     │ │
│ │            (val_iou): BinaryJaccardIndex()                               │ │
│ │            (val_precision): BinaryPrecision()                            │ │
│ │            (val_recall): BinaryRecall()                                  │ │
│ │            (test_f1): BinaryF1Score()                                    │ │
│ │            (test_iou): BinaryJaccardIndex()                              │ │
│ │            (test_precision): BinaryPrecision()                           │ │
│ │            (test_recall): BinaryRecall()                                 │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │ forward_call = <function                                                 │ │
│ │                _ForwardRedirection.__call__.<locals>.wrapped_forward at  │ │
│ │                0x7ed89c58edd0>                                           │ │
│ │       kwargs = {}                                                        │ │
│ │         self = TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:633 in wrapped_forward                 │
│                                                                              │
│   630 │   │   │   original_module.forward = original_forward  # type: ignore │
│   631 │   │   │   # Call the actual method e.g. `.training_step(...)`        │
│   632 │   │   │   method = getattr(original_module, method_name)             │
│ ❱ 633 │   │   │   out = method(*_args, **_kwargs)                            │
│   634 │   │   │   self.on_after_inner_forward(wrapper_module, original_modul │
│   635 │   │   │   return out                                                 │
│   636                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │            _args = (                                                     │ │
│ │                    │   [                                                 │ │
│ │                    │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,   │ │
│ │                    -0.6058, -0.6181, -0.7150],                           │ │
│ │                    │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,  │ │
│ │                    -0.7470, -1.0972],                                    │ │
│ │                    │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,  │ │
│ │                    -1.3672, -1.4232],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  │ │
│ │                    0.8201,  0.9101],                                     │ │
│ │                    │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  │ │
│ │                    0.7934,  0.8617],                                     │ │
│ │                    │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  │ │
│ │                    0.8312,  0.9036]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,  │ │
│ │                    -0.3903, -0.5082],                                    │ │
│ │                    │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,  │ │
│ │                    -0.5269, -0.9126],                                    │ │
│ │                    │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,  │ │
│ │                    -1.3571, -1.3879],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  │ │
│ │                    0.5149,  0.6028],                                     │ │
│ │                    │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  │ │
│ │                    0.5133,  0.5956],                                     │ │
│ │                    │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  │ │
│ │                    0.5766,  0.6924]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,  │ │
│ │                    -0.4887, -0.5277],                                    │ │
│ │                    │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,  │ │
│ │                    -0.5726, -0.8895],                                    │ │
│ │                    │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,  │ │
│ │                    -1.2241, -1.2979],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  │ │
│ │                    0.4844,  0.5816],                                     │ │
│ │                    │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  │ │
│ │                    0.4917,  0.5691],                                     │ │
│ │                    │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  │ │
│ │                    0.5424,  0.6669]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,  │ │
│ │                    -0.4125, -0.2770],                                    │ │
│ │                    │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,  │ │
│ │                    -0.2637, -0.5444],                                    │ │
│ │                    │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  │ │
│ │                    0.3721, -0.2837],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  │ │
│ │                    1.5731,  1.6655],                                     │ │
│ │                    │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  │ │
│ │                    1.6633,  1.5620],                                     │ │
│ │                    │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  │ │
│ │                    1.8766,  1.8721]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,  │ │
│ │                    -0.0699,  0.0557],                                    │ │
│ │                    │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  │ │
│ │                    0.0547, -0.1675],                                     │ │
│ │                    │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  │ │
│ │                    0.6220,  0.0236],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  │ │
│ │                    1.7006,  1.7636],                                     │ │
│ │                    │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  │ │
│ │                    1.7452,  1.6086],                                     │ │
│ │                    │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  │ │
│ │                    1.9005,  1.8320]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,  │ │
│ │                    -0.1504, -0.0534],                                    │ │
│ │                    │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,  │ │
│ │                    -0.0084, -0.3465],                                    │ │
│ │                    │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  │ │
│ │                    0.6836, -0.0941],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  │ │
│ │                    1.5997,  1.6536],                                     │ │
│ │                    │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  │ │
│ │                    1.6373,  1.4997],                                     │ │
│ │                    │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  │ │
│ │                    1.7704,  1.7204]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  │ │
│ │                    0.6527,  0.1973],                                     │ │
│ │                    │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,  │ │
│ │                    -0.7741, -0.6588],                                    │ │
│ │                    │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,  │ │
│ │                    -0.8624, -0.8335],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  │ │
│ │                    1.3495,  1.2763],                                     │ │
│ │                    │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  │ │
│ │                    1.2270,  1.1958],                                     │ │
│ │                    │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  │ │
│ │                    1.2479,  1.2777]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  │ │
│ │                    0.6290,  0.2545],                                     │ │
│ │                    │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,  │ │
│ │                    -0.2367, -0.0257],                                    │ │
│ │                    │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,  │ │
│ │                    -0.6202, -0.5923],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  │ │
│ │                    1.5171,  1.4460],                                     │ │
│ │                    │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  │ │
│ │                    1.5998,  1.5811],                                     │ │
│ │                    │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  │ │
│ │                    1.6719,  1.6993]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  │ │
│ │                    0.4811,  0.0363],                                     │ │
│ │                    │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,  │ │
│ │                    -0.5587, -0.5162],                                    │ │
│ │                    │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,  │ │
│ │                    -0.8376, -0.8337],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  │ │
│ │                    1.9169,  1.9397],                                     │ │
│ │                    │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  │ │
│ │                    2.2213,  2.2087],                                     │ │
│ │                    │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  │ │
│ │                    2.2530,  2.2691]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,  │ │
│ │                    -0.7623, -0.7780],                                    │ │
│ │                    │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,  │ │
│ │                    -0.7748, -0.8144],                                    │ │
│ │                    │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,  │ │
│ │                    -0.9039, -0.9166],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,  │ │
│ │                    -0.6917, -0.2532],                                    │ │
│ │                    │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,  │ │
│ │                    -0.4002, -0.4672],                                    │ │
│ │                    │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,  │ │
│ │                    -0.5219, -0.7189]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,  │ │
│ │                    -0.1644, -0.2325],                                    │ │
│ │                    │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,  │ │
│ │                    -0.2394, -0.3049],                                    │ │
│ │                    │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,  │ │
│ │                    -0.4470, -0.5231],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,  │ │
│ │                    -0.3438,  0.1731],                                    │ │
│ │                    │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,  │ │
│ │                    -0.0176, -0.0727],                                    │ │
│ │                    │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,  │ │
│ │                    -0.2082, -0.3332]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,  │ │
│ │                    -0.7085, -0.7336],                                    │ │
│ │                    │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,  │ │
│ │                    -0.6846, -0.7594],                                    │ │
│ │                    │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,  │ │
│ │                    -0.7978, -0.8245],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,  │ │
│ │                    -0.6215,  0.1228],                                    │ │
│ │                    │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,  │ │
│ │                    -0.2605, -0.2418],                                    │ │
│ │                    │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,  │ │
│ │                    -0.4024, -0.5858]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,  │ │
│ │                    -0.6567, -0.7818],                                    │ │
│ │                    │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,  │ │
│ │                    -0.4521, -0.5808],                                    │ │
│ │                    │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,  │ │
│ │                    -0.5200, -0.4384],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,  │ │
│ │                    -0.8494, -0.1735],                                    │ │
│ │                    │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,  │ │
│ │                    -0.2537, -0.3986],                                    │ │
│ │                    │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,  │ │
│ │                    -0.4791, -0.6006]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,  │ │
│ │                    -0.2687, -0.4003],                                    │ │
│ │                    │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,  │ │
│ │                    -0.0354, -0.1698],                                    │ │
│ │                    │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  │ │
│ │                    0.0203,  0.0299],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,  │ │
│ │                    -0.7123,  0.3566],                                    │ │
│ │                    │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  │ │
│ │                    0.2030,  0.0399],                                     │ │
│ │                    │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,  │ │
│ │                    -0.0388, -0.1875]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,  │ │
│ │                    -0.6522, -0.7503],                                    │ │
│ │                    │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,  │ │
│ │                    -0.4105, -0.5004],                                    │ │
│ │                    │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,  │ │
│ │                    -0.3854, -0.3569],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,  │ │
│ │                    -0.5653,  0.2921],                                    │ │
│ │                    │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  │ │
│ │                    0.1336, -0.1004],                                     │ │
│ │                    │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,  │ │
│ │                    -0.2689, -0.3513]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  │ │
│ │                    1.1517,  1.0863],                                     │ │
│ │                    │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  │ │
│ │                    1.1228,  1.1525],                                     │ │
│ │                    │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  │ │
│ │                    1.1681,  1.1589],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,  │ │
│ │                    -0.5756, -0.5779],                                    │ │
│ │                    │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,  │ │
│ │                    -0.6458, -0.6436],                                    │ │
│ │                    │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,  │ │
│ │                    -0.7063, -0.7261]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  │ │
│ │                    0.5726,  0.5173],                                     │ │
│ │                    │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  │ │
│ │                    0.5592,  0.5988],                                     │ │
│ │                    │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  │ │
│ │                    0.6153,  0.6056],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,  │ │
│ │                    -0.1196, -0.1621],                                    │ │
│ │                    │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,  │ │
│ │                    -0.1920, -0.2276],                                    │ │
│ │                    │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,  │ │
│ │                    -0.2507, -0.3032]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  │ │
│ │                    0.2579,  0.1735],                                     │ │
│ │                    │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  │ │
│ │                    0.2026,  0.2187],                                     │ │
│ │                    │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  │ │
│ │                    0.2340,  0.2250],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,  │ │
│ │                    -0.4467, -0.4766],                                    │ │
│ │                    │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,  │ │
│ │                    -0.5244, -0.5442],                                    │ │
│ │                    │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,  │ │
│ │                    -0.5930, -0.6154]]]],                                 │ │
│ │                    │      device='cuda:0', dtype=torch.float64),         │ │
│ │                    │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,     │ │
│ │                    0.,   0.],                                            │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]]], device='cuda:0')                             │ │
│ │                    │   ],                                                │ │
│ │                    │   0                                                 │ │
│ │                    )                                                     │ │
│ │          _kwargs = {}                                                    │ │
│ │           method = <bound method TeacherUNetModel.validation_step of     │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │      method_name = 'validation_step'                                     │ │
│ │ original_forward = <bound method TeacherUNetModel.forward of             │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │  original_module = TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )                                                     │ │
│ │             self = <pytorch_lightning.strategies.ddp._DDPForwardRedirec… │ │
│ │                    object at 0x7ed89e9a06a0>                             │ │
│ │   wrapper_module = DistributedDataParallel(                              │ │
│ │                      (module): TeacherUNetModel(                         │ │
│ │                    │   (model): Unet(                                    │ │
│ │                    │     (encoder): ResNetEncoder(                       │ │
│ │                    │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),    │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   (relu): ReLU(inplace=True)                    │ │
│ │                    │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2, │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │   │   (layer1): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer2): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3,  │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(64, 128, kernel_size=(1,    │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer3): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(128, 256, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (5): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer4): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(256, 512, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (decoder): UnetDecoder(                         │ │
│ │                    │   │   (center): Identity()                          │ │
│ │                    │   │   (blocks): ModuleList(                         │ │
│ │                    │   │     (0): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(768, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(384, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(192, 64, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 32, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (segmentation_head): SegmentationHead(          │ │
│ │                    │   │   (0): Conv2d(16, 1, kernel_size=(3, 3),        │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │   │   (1): Identity()                               │ │
│ │                    │   │   (2): Activation(                              │ │
│ │                    │   │     (activation): Identity()                    │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (loss): BCEWithLogitsLoss()                       │ │
│ │                    │   (train_f1): BinaryF1Score()                       │ │
│ │                    │   (train_iou): BinaryJaccardIndex()                 │ │
│ │                    │   (train_precision): BinaryPrecision()              │ │
│ │                    │   (train_recall): BinaryRecall()                    │ │
│ │                    │   (val_f1): BinaryF1Score()                         │ │
│ │                    │   (val_iou): BinaryJaccardIndex()                   │ │
│ │                    │   (val_precision): BinaryPrecision()                │ │
│ │                    │   (val_recall): BinaryRecall()                      │ │
│ │                    │   (test_f1): BinaryF1Score()                        │ │
│ │                    │   (test_iou): BinaryJaccardIndex()                  │ │
│ │                    │   (test_precision): BinaryPrecision()               │ │
│ │                    │   (test_recall): BinaryRecall()                     │ │
│ │                      )                                                   │ │
│ │                    )                                                     │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/projects/Noisy-Student/models/teacher_unet.py:65 in              │
│ validation_step                                                              │
│                                                                              │
│    62 │                                                                      │
│    63 │   def validation_step(self, batch, batch_idx):                       │
│    64 │   │   images, labels = batch                                         │
│ ❱  65 │   │   outputs = self(images)                                         │
│    66 │   │                                                                  │
│    67 │   │   # Update the metrics                                           │
│    68 │   │   ce_loss = self.loss(outputs, labels)                           │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │     batch = [                                                            │ │
│ │             │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,     │ │
│ │             -0.6181, -0.7150],                                           │ │
│ │             │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,         │ │
│ │             -0.7470, -1.0972],                                           │ │
│ │             │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,         │ │
│ │             -1.3672, -1.4232],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,         │ │
│ │             0.8201,  0.9101],                                            │ │
│ │             │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,         │ │
│ │             0.7934,  0.8617],                                            │ │
│ │             │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,         │ │
│ │             0.8312,  0.9036]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,         │ │
│ │             -0.3903, -0.5082],                                           │ │
│ │             │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,         │ │
│ │             -0.5269, -0.9126],                                           │ │
│ │             │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,         │ │
│ │             -1.3571, -1.3879],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,         │ │
│ │             0.5149,  0.6028],                                            │ │
│ │             │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,         │ │
│ │             0.5133,  0.5956],                                            │ │
│ │             │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,         │ │
│ │             0.5766,  0.6924]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,         │ │
│ │             -0.4887, -0.5277],                                           │ │
│ │             │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,         │ │
│ │             -0.5726, -0.8895],                                           │ │
│ │             │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,         │ │
│ │             -1.2241, -1.2979],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,         │ │
│ │             0.4844,  0.5816],                                            │ │
│ │             │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,         │ │
│ │             0.4917,  0.5691],                                            │ │
│ │             │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,         │ │
│ │             0.5424,  0.6669]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,         │ │
│ │             -0.4125, -0.2770],                                           │ │
│ │             │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,         │ │
│ │             -0.2637, -0.5444],                                           │ │
│ │             │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,         │ │
│ │             0.3721, -0.2837],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,         │ │
│ │             1.5731,  1.6655],                                            │ │
│ │             │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,         │ │
│ │             1.6633,  1.5620],                                            │ │
│ │             │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,         │ │
│ │             1.8766,  1.8721]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,         │ │
│ │             -0.0699,  0.0557],                                           │ │
│ │             │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,         │ │
│ │             0.0547, -0.1675],                                            │ │
│ │             │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,         │ │
│ │             0.6220,  0.0236],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,         │ │
│ │             1.7006,  1.7636],                                            │ │
│ │             │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,         │ │
│ │             1.7452,  1.6086],                                            │ │
│ │             │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,         │ │
│ │             1.9005,  1.8320]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,         │ │
│ │             -0.1504, -0.0534],                                           │ │
│ │             │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,         │ │
│ │             -0.0084, -0.3465],                                           │ │
│ │             │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,         │ │
│ │             0.6836, -0.0941],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,         │ │
│ │             1.5997,  1.6536],                                            │ │
│ │             │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,         │ │
│ │             1.6373,  1.4997],                                            │ │
│ │             │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,         │ │
│ │             1.7704,  1.7204]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,         │ │
│ │             0.6527,  0.1973],                                            │ │
│ │             │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,         │ │
│ │             -0.7741, -0.6588],                                           │ │
│ │             │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,         │ │
│ │             -0.8624, -0.8335],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,         │ │
│ │             1.3495,  1.2763],                                            │ │
│ │             │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,         │ │
│ │             1.2270,  1.1958],                                            │ │
│ │             │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,         │ │
│ │             1.2479,  1.2777]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,         │ │
│ │             0.6290,  0.2545],                                            │ │
│ │             │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,         │ │
│ │             -0.2367, -0.0257],                                           │ │
│ │             │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,         │ │
│ │             -0.6202, -0.5923],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,         │ │
│ │             1.5171,  1.4460],                                            │ │
│ │             │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,         │ │
│ │             1.5998,  1.5811],                                            │ │
│ │             │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,         │ │
│ │             1.6719,  1.6993]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,         │ │
│ │             0.4811,  0.0363],                                            │ │
│ │             │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,         │ │
│ │             -0.5587, -0.5162],                                           │ │
│ │             │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,         │ │
│ │             -0.8376, -0.8337],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,         │ │
│ │             1.9169,  1.9397],                                            │ │
│ │             │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,         │ │
│ │             2.2213,  2.2087],                                            │ │
│ │             │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,         │ │
│ │             2.2530,  2.2691]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,         │ │
│ │             -0.7623, -0.7780],                                           │ │
│ │             │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,         │ │
│ │             -0.7748, -0.8144],                                           │ │
│ │             │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,         │ │
│ │             -0.9039, -0.9166],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,         │ │
│ │             -0.6917, -0.2532],                                           │ │
│ │             │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,         │ │
│ │             -0.4002, -0.4672],                                           │ │
│ │             │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,         │ │
│ │             -0.5219, -0.7189]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,         │ │
│ │             -0.1644, -0.2325],                                           │ │
│ │             │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,         │ │
│ │             -0.2394, -0.3049],                                           │ │
│ │             │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,         │ │
│ │             -0.4470, -0.5231],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,         │ │
│ │             -0.3438,  0.1731],                                           │ │
│ │             │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,         │ │
│ │             -0.0176, -0.0727],                                           │ │
│ │             │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,         │ │
│ │             -0.2082, -0.3332]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,         │ │
│ │             -0.7085, -0.7336],                                           │ │
│ │             │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,         │ │
│ │             -0.6846, -0.7594],                                           │ │
│ │             │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,         │ │
│ │             -0.7978, -0.8245],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,         │ │
│ │             -0.6215,  0.1228],                                           │ │
│ │             │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,         │ │
│ │             -0.2605, -0.2418],                                           │ │
│ │             │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,         │ │
│ │             -0.4024, -0.5858]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,         │ │
│ │             -0.6567, -0.7818],                                           │ │
│ │             │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,         │ │
│ │             -0.4521, -0.5808],                                           │ │
│ │             │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,         │ │
│ │             -0.5200, -0.4384],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,         │ │
│ │             -0.8494, -0.1735],                                           │ │
│ │             │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,         │ │
│ │             -0.2537, -0.3986],                                           │ │
│ │             │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,         │ │
│ │             -0.4791, -0.6006]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,         │ │
│ │             -0.2687, -0.4003],                                           │ │
│ │             │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,         │ │
│ │             -0.0354, -0.1698],                                           │ │
│ │             │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,         │ │
│ │             0.0203,  0.0299],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,         │ │
│ │             -0.7123,  0.3566],                                           │ │
│ │             │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,         │ │
│ │             0.2030,  0.0399],                                            │ │
│ │             │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,         │ │
│ │             -0.0388, -0.1875]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,         │ │
│ │             -0.6522, -0.7503],                                           │ │
│ │             │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,         │ │
│ │             -0.4105, -0.5004],                                           │ │
│ │             │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,         │ │
│ │             -0.3854, -0.3569],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,         │ │
│ │             -0.5653,  0.2921],                                           │ │
│ │             │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,         │ │
│ │             0.1336, -0.1004],                                            │ │
│ │             │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,         │ │
│ │             -0.2689, -0.3513]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,         │ │
│ │             1.1517,  1.0863],                                            │ │
│ │             │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,         │ │
│ │             1.1228,  1.1525],                                            │ │
│ │             │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,         │ │
│ │             1.1681,  1.1589],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,         │ │
│ │             -0.5756, -0.5779],                                           │ │
│ │             │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,         │ │
│ │             -0.6458, -0.6436],                                           │ │
│ │             │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,         │ │
│ │             -0.7063, -0.7261]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,         │ │
│ │             0.5726,  0.5173],                                            │ │
│ │             │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,         │ │
│ │             0.5592,  0.5988],                                            │ │
│ │             │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,         │ │
│ │             0.6153,  0.6056],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,         │ │
│ │             -0.1196, -0.1621],                                           │ │
│ │             │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,         │ │
│ │             -0.1920, -0.2276],                                           │ │
│ │             │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,         │ │
│ │             -0.2507, -0.3032]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,         │ │
│ │             0.2579,  0.1735],                                            │ │
│ │             │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,         │ │
│ │             0.2026,  0.2187],                                            │ │
│ │             │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,         │ │
│ │             0.2340,  0.2250],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,         │ │
│ │             -0.4467, -0.4766],                                           │ │
│ │             │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,         │ │
│ │             -0.5244, -0.5442],                                           │ │
│ │             │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,         │ │
│ │             -0.5930, -0.6154]]]],                                        │ │
│ │             │      device='cuda:0', dtype=torch.float64),                │ │
│ │             │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],   │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],   │ │
│ │             device='cuda:0')                                             │ │
│ │             ]                                                            │ │
│ │ batch_idx = 0                                                            │ │
│ │    images = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,         │ │
│ │             -0.6181, -0.7150],                                           │ │
│ │             │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,         │ │
│ │             -0.7470, -1.0972],                                           │ │
│ │             │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,         │ │
│ │             -1.3672, -1.4232],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,         │ │
│ │             0.8201,  0.9101],                                            │ │
│ │             │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,         │ │
│ │             0.7934,  0.8617],                                            │ │
│ │             │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,         │ │
│ │             0.8312,  0.9036]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,         │ │
│ │             -0.3903, -0.5082],                                           │ │
│ │             │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,         │ │
│ │             -0.5269, -0.9126],                                           │ │
│ │             │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,         │ │
│ │             -1.3571, -1.3879],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,         │ │
│ │             0.5149,  0.6028],                                            │ │
│ │             │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,         │ │
│ │             0.5133,  0.5956],                                            │ │
│ │             │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,         │ │
│ │             0.5766,  0.6924]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,         │ │
│ │             -0.4887, -0.5277],                                           │ │
│ │             │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,         │ │
│ │             -0.5726, -0.8895],                                           │ │
│ │             │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,         │ │
│ │             -1.2241, -1.2979],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,         │ │
│ │             0.4844,  0.5816],                                            │ │
│ │             │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,         │ │
│ │             0.4917,  0.5691],                                            │ │
│ │             │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,         │ │
│ │             0.5424,  0.6669]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,         │ │
│ │             -0.4125, -0.2770],                                           │ │
│ │             │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,         │ │
│ │             -0.2637, -0.5444],                                           │ │
│ │             │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,         │ │
│ │             0.3721, -0.2837],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,         │ │
│ │             1.5731,  1.6655],                                            │ │
│ │             │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,         │ │
│ │             1.6633,  1.5620],                                            │ │
│ │             │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,         │ │
│ │             1.8766,  1.8721]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,         │ │
│ │             -0.0699,  0.0557],                                           │ │
│ │             │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,         │ │
│ │             0.0547, -0.1675],                                            │ │
│ │             │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,         │ │
│ │             0.6220,  0.0236],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,         │ │
│ │             1.7006,  1.7636],                                            │ │
│ │             │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,         │ │
│ │             1.7452,  1.6086],                                            │ │
│ │             │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,         │ │
│ │             1.9005,  1.8320]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,         │ │
│ │             -0.1504, -0.0534],                                           │ │
│ │             │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,         │ │
│ │             -0.0084, -0.3465],                                           │ │
│ │             │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,         │ │
│ │             0.6836, -0.0941],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,         │ │
│ │             1.5997,  1.6536],                                            │ │
│ │             │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,         │ │
│ │             1.6373,  1.4997],                                            │ │
│ │             │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,         │ │
│ │             1.7704,  1.7204]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,         │ │
│ │             0.6527,  0.1973],                                            │ │
│ │             │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,         │ │
│ │             -0.7741, -0.6588],                                           │ │
│ │             │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,         │ │
│ │             -0.8624, -0.8335],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,         │ │
│ │             1.3495,  1.2763],                                            │ │
│ │             │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,         │ │
│ │             1.2270,  1.1958],                                            │ │
│ │             │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,         │ │
│ │             1.2479,  1.2777]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,         │ │
│ │             0.6290,  0.2545],                                            │ │
│ │             │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,         │ │
│ │             -0.2367, -0.0257],                                           │ │
│ │             │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,         │ │
│ │             -0.6202, -0.5923],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,         │ │
│ │             1.5171,  1.4460],                                            │ │
│ │             │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,         │ │
│ │             1.5998,  1.5811],                                            │ │
│ │             │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,         │ │
│ │             1.6719,  1.6993]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,         │ │
│ │             0.4811,  0.0363],                                            │ │
│ │             │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,         │ │
│ │             -0.5587, -0.5162],                                           │ │
│ │             │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,         │ │
│ │             -0.8376, -0.8337],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,         │ │
│ │             1.9169,  1.9397],                                            │ │
│ │             │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,         │ │
│ │             2.2213,  2.2087],                                            │ │
│ │             │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,         │ │
│ │             2.2530,  2.2691]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,         │ │
│ │             -0.7623, -0.7780],                                           │ │
│ │             │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,         │ │
│ │             -0.7748, -0.8144],                                           │ │
│ │             │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,         │ │
│ │             -0.9039, -0.9166],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,         │ │
│ │             -0.6917, -0.2532],                                           │ │
│ │             │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,         │ │
│ │             -0.4002, -0.4672],                                           │ │
│ │             │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,         │ │
│ │             -0.5219, -0.7189]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,         │ │
│ │             -0.1644, -0.2325],                                           │ │
│ │             │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,         │ │
│ │             -0.2394, -0.3049],                                           │ │
│ │             │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,         │ │
│ │             -0.4470, -0.5231],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,         │ │
│ │             -0.3438,  0.1731],                                           │ │
│ │             │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,         │ │
│ │             -0.0176, -0.0727],                                           │ │
│ │             │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,         │ │
│ │             -0.2082, -0.3332]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,         │ │
│ │             -0.7085, -0.7336],                                           │ │
│ │             │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,         │ │
│ │             -0.6846, -0.7594],                                           │ │
│ │             │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,         │ │
│ │             -0.7978, -0.8245],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,         │ │
│ │             -0.6215,  0.1228],                                           │ │
│ │             │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,         │ │
│ │             -0.2605, -0.2418],                                           │ │
│ │             │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,         │ │
│ │             -0.4024, -0.5858]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,         │ │
│ │             -0.6567, -0.7818],                                           │ │
│ │             │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,         │ │
│ │             -0.4521, -0.5808],                                           │ │
│ │             │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,         │ │
│ │             -0.5200, -0.4384],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,         │ │
│ │             -0.8494, -0.1735],                                           │ │
│ │             │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,         │ │
│ │             -0.2537, -0.3986],                                           │ │
│ │             │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,         │ │
│ │             -0.4791, -0.6006]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,         │ │
│ │             -0.2687, -0.4003],                                           │ │
│ │             │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,         │ │
│ │             -0.0354, -0.1698],                                           │ │
│ │             │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,         │ │
│ │             0.0203,  0.0299],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,         │ │
│ │             -0.7123,  0.3566],                                           │ │
│ │             │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,         │ │
│ │             0.2030,  0.0399],                                            │ │
│ │             │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,         │ │
│ │             -0.0388, -0.1875]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,         │ │
│ │             -0.6522, -0.7503],                                           │ │
│ │             │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,         │ │
│ │             -0.4105, -0.5004],                                           │ │
│ │             │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,         │ │
│ │             -0.3854, -0.3569],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,         │ │
│ │             -0.5653,  0.2921],                                           │ │
│ │             │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,         │ │
│ │             0.1336, -0.1004],                                            │ │
│ │             │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,         │ │
│ │             -0.2689, -0.3513]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,         │ │
│ │             1.1517,  1.0863],                                            │ │
│ │             │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,         │ │
│ │             1.1228,  1.1525],                                            │ │
│ │             │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,         │ │
│ │             1.1681,  1.1589],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,         │ │
│ │             -0.5756, -0.5779],                                           │ │
│ │             │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,         │ │
│ │             -0.6458, -0.6436],                                           │ │
│ │             │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,         │ │
│ │             -0.7063, -0.7261]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,         │ │
│ │             0.5726,  0.5173],                                            │ │
│ │             │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,         │ │
│ │             0.5592,  0.5988],                                            │ │
│ │             │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,         │ │
│ │             0.6153,  0.6056],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,         │ │
│ │             -0.1196, -0.1621],                                           │ │
│ │             │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,         │ │
│ │             -0.1920, -0.2276],                                           │ │
│ │             │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,         │ │
│ │             -0.2507, -0.3032]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,         │ │
│ │             0.2579,  0.1735],                                            │ │
│ │             │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,         │ │
│ │             0.2026,  0.2187],                                            │ │
│ │             │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,         │ │
│ │             0.2340,  0.2250],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,         │ │
│ │             -0.4467, -0.4766],                                           │ │
│ │             │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,         │ │
│ │             -0.5244, -0.5442],                                           │ │
│ │             │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,         │ │
│ │             -0.5930, -0.6154]]]],                                        │ │
│ │             │      device='cuda:0', dtype=torch.float64)                 │ │
│ │    labels = tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],   │ │
│ │             device='cuda:0')                                             │ │
│ │      self = TeacherUNetModel(                                            │ │
│ │               (model): Unet(                                             │ │
│ │             │   (encoder): ResNetEncoder(                                │ │
│ │             │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,  │ │
│ │             2), padding=(3, 3), bias=False)                              │ │
│ │             │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,        │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │     (relu): ReLU(inplace=True)                             │ │
│ │             │     (maxpool): MaxPool2d(kernel_size=3, stride=2,          │ │
│ │             padding=1, dilation=1, ceil_mode=False)                      │ │
│ │             │     (layer1): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer2): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),       │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),         │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer3): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),      │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),        │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (4): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (5): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer4): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),      │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),        │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │             │   (decoder): UnetDecoder(                                  │ │
│ │             │     (center): Identity()                                   │ │
│ │             │     (blocks): ModuleList(                                  │ │
│ │             │   │   (0): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),         │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),         │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (4): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │             │   (segmentation_head): SegmentationHead(                   │ │
│ │             │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │             padding=(1, 1))                                              │ │
│ │             │     (1): Identity()                                        │ │
│ │             │     (2): Activation(                                       │ │
│ │             │   │   (activation): Identity()                             │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │               )                                                          │ │
│ │               (loss): BCEWithLogitsLoss()                                │ │
│ │               (train_f1): BinaryF1Score()                                │ │
│ │               (train_iou): BinaryJaccardIndex()                          │ │
│ │               (train_precision): BinaryPrecision()                       │ │
│ │               (train_recall): BinaryRecall()                             │ │
│ │               (val_f1): BinaryF1Score()                                  │ │
│ │               (val_iou): BinaryJaccardIndex()                            │ │
│ │               (val_precision): BinaryPrecision()                         │ │
│ │               (val_recall): BinaryRecall()                               │ │
│ │               (test_f1): BinaryF1Score()                                 │ │
│ │               (test_iou): BinaryJaccardIndex()                           │ │
│ │               (test_precision): BinaryPrecision()                        │ │
│ │               (test_recall): BinaryRecall()                              │ │
│ │             )                                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,        │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = TeacherUNetModel(                                               │ │
│ │            (model): Unet(                                                │ │
│ │          │   (encoder): ResNetEncoder(                                   │ │
│ │          │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,  │ │
│ │          dilation=1, ceil_mode=False)                                    │ │
│ │          │     (layer1): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer2): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),          │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer3): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (5): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer4): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (decoder): UnetDecoder(                                     │ │
│ │          │     (center): Identity()                                      │ │
│ │          │     (blocks): ModuleList(                                     │ │
│ │          │   │   (0): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (segmentation_head): SegmentationHead(                      │ │
│ │          │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),     │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │     (1): Identity()                                           │ │
│ │          │     (2): Activation(                                          │ │
│ │          │   │   (activation): Identity()                                │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (loss): BCEWithLogitsLoss()                                   │ │
│ │            (train_f1): BinaryF1Score()                                   │ │
│ │            (train_iou): BinaryJaccardIndex()                             │ │
│ │            (train_precision): BinaryPrecision()                          │ │
│ │            (train_recall): BinaryRecall()                                │ │
│ │            (val_f1): BinaryF1Score()                                     │ │
│ │            (val_iou): BinaryJaccardIndex()                               │ │
│ │            (val_precision): BinaryPrecision()                            │ │
│ │            (val_recall): BinaryRecall()                                  │ │
│ │            (test_f1): BinaryF1Score()                                    │ │
│ │            (test_iou): BinaryJaccardIndex()                              │ │
│ │            (test_precision): BinaryPrecision()                           │ │
│ │            (test_recall): BinaryRecall()                                 │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,  │ │
│ │                -0.6181, -0.7150],                                        │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method TeacherUNetModel.forward of                 │ │
│ │                TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/projects/Noisy-Student/models/teacher_unet.py:42 in forward      │
│                                                                              │
│    39 │   │   self.test_recall = torchmetrics.Recall(task="binary")          │
│    40 │                                                                      │
│    41 │   def forward(self, x):                                              │
│ ❱  42 │   │   return self.model(x)                                           │
│    43 │                                                                      │
│    44 │   def training_step(self, batch, batch_idx):                         │
│    45 │   │   images, labels = batch                                         │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ self = TeacherUNetModel(                                                 │ │
│ │          (model): Unet(                                                  │ │
│ │        │   (encoder): ResNetEncoder(                                     │ │
│ │        │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),   │ │
│ │        padding=(3, 3), bias=False)                                       │ │
│ │        │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,             │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     (relu): ReLU(inplace=True)                                  │ │
│ │        │     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,    │ │
│ │        dilation=1, ceil_mode=False)                                      │ │
│ │        │     (layer1): Sequential(                                       │ │
│ │        │   │   (0): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (1): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (2): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (layer2): Sequential(                                       │ │
│ │        │   │   (0): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, │ │
│ │        2), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (downsample): Sequential(                               │ │
│ │        │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2,   │ │
│ │        2), bias=False)                                                   │ │
│ │        │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (1): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (2): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (3): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (layer3): Sequential(                                       │ │
│ │        │   │   (0): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),           │ │
│ │        stride=(2, 2), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (downsample): Sequential(                               │ │
│ │        │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,  │ │
│ │        2), bias=False)                                                   │ │
│ │        │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (1): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (2): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (3): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (4): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (5): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (layer4): Sequential(                                       │ │
│ │        │   │   (0): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),           │ │
│ │        stride=(2, 2), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (downsample): Sequential(                               │ │
│ │        │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,  │ │
│ │        2), bias=False)                                                   │ │
│ │        │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (1): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (2): BasicBlock(                                          │ │
│ │        │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (relu): ReLU(inplace=True)                              │ │
│ │        │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │        stride=(1, 1), padding=(1, 1), bias=False)                        │ │
│ │        │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │        │   (decoder): UnetDecoder(                                       │ │
│ │        │     (center): Identity()                                        │ │
│ │        │     (blocks): ModuleList(                                       │ │
│ │        │   │   (0): DecoderBlock(                                        │ │
│ │        │   │     (conv1): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention1): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (conv2): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention2): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (1): DecoderBlock(                                        │ │
│ │        │   │     (conv1): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention1): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (conv2): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention2): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (2): DecoderBlock(                                        │ │
│ │        │   │     (conv1): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1,   │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention1): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (conv2): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention2): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (3): DecoderBlock(                                        │ │
│ │        │   │     (conv1): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1,   │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention1): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (conv2): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention2): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (4): DecoderBlock(                                        │ │
│ │        │   │     (conv1): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention1): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (conv2): Conv2dReLU(                                    │ │
│ │        │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,         │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   │   (2): ReLU(inplace=True)                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │     (attention2): Attention(                                │ │
│ │        │   │   │   (attention): Identity()                               │ │
│ │        │   │     )                                                       │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │        │   (segmentation_head): SegmentationHead(                        │ │
│ │        │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),       │ │
│ │        padding=(1, 1))                                                   │ │
│ │        │     (1): Identity()                                             │ │
│ │        │     (2): Activation(                                            │ │
│ │        │   │   (activation): Identity()                                  │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │          )                                                               │ │
│ │          (loss): BCEWithLogitsLoss()                                     │ │
│ │          (train_f1): BinaryF1Score()                                     │ │
│ │          (train_iou): BinaryJaccardIndex()                               │ │
│ │          (train_precision): BinaryPrecision()                            │ │
│ │          (train_recall): BinaryRecall()                                  │ │
│ │          (val_f1): BinaryF1Score()                                       │ │
│ │          (val_iou): BinaryJaccardIndex()                                 │ │
│ │          (val_precision): BinaryPrecision()                              │ │
│ │          (val_recall): BinaryRecall()                                    │ │
│ │          (test_f1): BinaryF1Score()                                      │ │
│ │          (test_iou): BinaryJaccardIndex()                                │ │
│ │          (test_precision): BinaryPrecision()                             │ │
│ │          (test_recall): BinaryRecall()                                   │ │
│ │        )                                                                 │ │
│ │    x = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181,     │ │
│ │        -0.7150],                                                         │ │
│ │        │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,     │ │
│ │        -1.0972],                                                         │ │
│ │        │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,     │ │
│ │        -1.4232],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,     │ │
│ │        0.9101],                                                          │ │
│ │        │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,     │ │
│ │        0.8617],                                                          │ │
│ │        │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,     │ │
│ │        0.9036]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,     │ │
│ │        -0.5082],                                                         │ │
│ │        │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,     │ │
│ │        -0.9126],                                                         │ │
│ │        │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,     │ │
│ │        -1.3879],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,     │ │
│ │        0.6028],                                                          │ │
│ │        │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,     │ │
│ │        0.5956],                                                          │ │
│ │        │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,     │ │
│ │        0.6924]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,     │ │
│ │        -0.5277],                                                         │ │
│ │        │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,     │ │
│ │        -0.8895],                                                         │ │
│ │        │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,     │ │
│ │        -1.2979],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,     │ │
│ │        0.5816],                                                          │ │
│ │        │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,     │ │
│ │        0.5691],                                                          │ │
│ │        │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,     │ │
│ │        0.6669]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,     │ │
│ │        -0.2770],                                                         │ │
│ │        │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,     │ │
│ │        -0.5444],                                                         │ │
│ │        │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,     │ │
│ │        -0.2837],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,     │ │
│ │        1.6655],                                                          │ │
│ │        │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,     │ │
│ │        1.5620],                                                          │ │
│ │        │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,     │ │
│ │        1.8721]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,     │ │
│ │        0.0557],                                                          │ │
│ │        │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,     │ │
│ │        -0.1675],                                                         │ │
│ │        │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,     │ │
│ │        0.0236],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,     │ │
│ │        1.7636],                                                          │ │
│ │        │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,     │ │
│ │        1.6086],                                                          │ │
│ │        │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,     │ │
│ │        1.8320]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,     │ │
│ │        -0.0534],                                                         │ │
│ │        │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,     │ │
│ │        -0.3465],                                                         │ │
│ │        │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,     │ │
│ │        -0.0941],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,     │ │
│ │        1.6536],                                                          │ │
│ │        │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,     │ │
│ │        1.4997],                                                          │ │
│ │        │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,     │ │
│ │        1.7204]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,     │ │
│ │        0.1973],                                                          │ │
│ │        │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,     │ │
│ │        -0.6588],                                                         │ │
│ │        │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,     │ │
│ │        -0.8335],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,     │ │
│ │        1.2763],                                                          │ │
│ │        │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,     │ │
│ │        1.1958],                                                          │ │
│ │        │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,     │ │
│ │        1.2777]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,     │ │
│ │        0.2545],                                                          │ │
│ │        │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,     │ │
│ │        -0.0257],                                                         │ │
│ │        │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,     │ │
│ │        -0.5923],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,     │ │
│ │        1.4460],                                                          │ │
│ │        │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,     │ │
│ │        1.5811],                                                          │ │
│ │        │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,     │ │
│ │        1.6993]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,     │ │
│ │        0.0363],                                                          │ │
│ │        │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,     │ │
│ │        -0.5162],                                                         │ │
│ │        │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,     │ │
│ │        -0.8337],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,     │ │
│ │        1.9397],                                                          │ │
│ │        │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,     │ │
│ │        2.2087],                                                          │ │
│ │        │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,     │ │
│ │        2.2691]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   ...,                                                      │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,     │ │
│ │        -0.7780],                                                         │ │
│ │        │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,     │ │
│ │        -0.8144],                                                         │ │
│ │        │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,     │ │
│ │        -0.9166],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,     │ │
│ │        -0.2532],                                                         │ │
│ │        │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,     │ │
│ │        -0.4672],                                                         │ │
│ │        │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,     │ │
│ │        -0.7189]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,     │ │
│ │        -0.2325],                                                         │ │
│ │        │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,     │ │
│ │        -0.3049],                                                         │ │
│ │        │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,     │ │
│ │        -0.5231],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,     │ │
│ │        0.1731],                                                          │ │
│ │        │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,     │ │
│ │        -0.0727],                                                         │ │
│ │        │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,     │ │
│ │        -0.3332]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,     │ │
│ │        -0.7336],                                                         │ │
│ │        │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,     │ │
│ │        -0.7594],                                                         │ │
│ │        │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,     │ │
│ │        -0.8245],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,     │ │
│ │        0.1228],                                                          │ │
│ │        │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,     │ │
│ │        -0.2418],                                                         │ │
│ │        │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,     │ │
│ │        -0.5858]]],                                                       │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,     │ │
│ │        -0.7818],                                                         │ │
│ │        │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,     │ │
│ │        -0.5808],                                                         │ │
│ │        │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,     │ │
│ │        -0.4384],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,     │ │
│ │        -0.1735],                                                         │ │
│ │        │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,     │ │
│ │        -0.3986],                                                         │ │
│ │        │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,     │ │
│ │        -0.6006]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,     │ │
│ │        -0.4003],                                                         │ │
│ │        │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,     │ │
│ │        -0.1698],                                                         │ │
│ │        │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,     │ │
│ │        0.0299],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,     │ │
│ │        0.3566],                                                          │ │
│ │        │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,     │ │
│ │        0.0399],                                                          │ │
│ │        │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,     │ │
│ │        -0.1875]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,     │ │
│ │        -0.7503],                                                         │ │
│ │        │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,     │ │
│ │        -0.5004],                                                         │ │
│ │        │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,     │ │
│ │        -0.3569],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,     │ │
│ │        0.2921],                                                          │ │
│ │        │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,     │ │
│ │        -0.1004],                                                         │ │
│ │        │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,     │ │
│ │        -0.3513]]],                                                       │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,     │ │
│ │        1.0863],                                                          │ │
│ │        │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,     │ │
│ │        1.1525],                                                          │ │
│ │        │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,     │ │
│ │        1.1589],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,     │ │
│ │        -0.5779],                                                         │ │
│ │        │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,     │ │
│ │        -0.6436],                                                         │ │
│ │        │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,     │ │
│ │        -0.7261]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,     │ │
│ │        0.5173],                                                          │ │
│ │        │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,     │ │
│ │        0.5988],                                                          │ │
│ │        │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,     │ │
│ │        0.6056],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,     │ │
│ │        -0.1621],                                                         │ │
│ │        │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,     │ │
│ │        -0.2276],                                                         │ │
│ │        │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,     │ │
│ │        -0.3032]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,     │ │
│ │        0.1735],                                                          │ │
│ │        │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,     │ │
│ │        0.2187],                                                          │ │
│ │        │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,     │ │
│ │        0.2250],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,     │ │
│ │        -0.4766],                                                         │ │
│ │        │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,     │ │
│ │        -0.5442],                                                         │ │
│ │        │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,     │ │
│ │        -0.6154]]]],                                                      │ │
│ │        │      device='cuda:0', dtype=torch.float64)                      │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,        │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = Unet(                                                           │ │
│ │            (encoder): ResNetEncoder(                                     │ │
│ │          │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),   │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │          │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,             │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   (relu): ReLU(inplace=True)                                  │ │
│ │          │   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,    │ │
│ │          dilation=1, ceil_mode=False)                                    │ │
│ │          │   (layer1): Sequential(                                       │ │
│ │          │     (0): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (1): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (2): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (layer2): Sequential(                                       │ │
│ │          │     (0): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, │ │
│ │          2), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (downsample): Sequential(                               │ │
│ │          │   │     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2,   │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (1): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (2): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (3): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (layer3): Sequential(                                       │ │
│ │          │     (0): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),           │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (downsample): Sequential(                               │ │
│ │          │   │     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,  │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (1): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (2): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (3): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (4): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (5): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (layer4): Sequential(                                       │ │
│ │          │     (0): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),           │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (downsample): Sequential(                               │ │
│ │          │   │     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,  │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (1): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │     (2): BasicBlock(                                          │ │
│ │          │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (decoder): UnetDecoder(                                       │ │
│ │          │   (center): Identity()                                        │ │
│ │          │   (blocks): ModuleList(                                       │ │
│ │          │     (0): DecoderBlock(                                        │ │
│ │          │   │   (conv1): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention1): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (conv2): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention2): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (1): DecoderBlock(                                        │ │
│ │          │   │   (conv1): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention1): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (conv2): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention2): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (2): DecoderBlock(                                        │ │
│ │          │   │   (conv1): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1,   │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention1): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (conv2): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention2): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (3): DecoderBlock(                                        │ │
│ │          │   │   (conv1): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1,   │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention1): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (conv2): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention2): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (4): DecoderBlock(                                        │ │
│ │          │   │   (conv1): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention1): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (conv2): Conv2dReLU(                                    │ │
│ │          │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (2): ReLU(inplace=True)                               │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (attention2): Attention(                                │ │
│ │          │   │     (attention): Identity()                               │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (segmentation_head): SegmentationHead(                        │ │
│ │          │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),       │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   (1): Identity()                                             │ │
│ │          │   (2): Activation(                                            │ │
│ │          │     (activation): Identity()                                  │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,  │ │
│ │                -0.6181, -0.7150],                                        │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method SegmentationModel.forward of Unet(          │ │
│ │                  (encoder): ResNetEncoder(                               │ │
│ │                │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │                2), padding=(3, 3), bias=False)                           │ │
│ │                │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   (relu): ReLU(inplace=True)                            │ │
│ │                │   (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   (layer1): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer2): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (3): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer3): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (3): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (4): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (5): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer4): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (decoder): UnetDecoder(                                 │ │
│ │                │   (center): Identity()                                  │ │
│ │                │   (blocks): ModuleList(                                 │ │
│ │                │     (0): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (2): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (3): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (4): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (segmentation_head): SegmentationHead(                  │ │
│ │                │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │                padding=(1, 1))                                           │ │
│ │                │   (1): Identity()                                       │ │
│ │                │   (2): Activation(                                      │ │
│ │                │     (activation): Identity()                            │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = Unet(                                                     │ │
│ │                  (encoder): ResNetEncoder(                               │ │
│ │                │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │                2), padding=(3, 3), bias=False)                           │ │
│ │                │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   (relu): ReLU(inplace=True)                            │ │
│ │                │   (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   (layer1): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer2): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (3): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer3): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (3): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (4): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (5): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (layer4): Sequential(                                 │ │
│ │                │     (0): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (downsample): Sequential(                         │ │
│ │                │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │     (2): BasicBlock(                                    │ │
│ │                │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (decoder): UnetDecoder(                                 │ │
│ │                │   (center): Identity()                                  │ │
│ │                │   (blocks): ModuleList(                                 │ │
│ │                │     (0): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (1): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (2): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (3): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (4): DecoderBlock(                                  │ │
│ │                │   │   (conv1): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention1): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (conv2): Conv2dReLU(                              │ │
│ │                │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (2): ReLU(inplace=True)                         │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (attention2): Attention(                          │ │
│ │                │   │     (attention): Identity()                         │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (segmentation_head): SegmentationHead(                  │ │
│ │                │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │                padding=(1, 1))                                           │ │
│ │                │   (1): Identity()                                       │ │
│ │                │   (2): Activation(                                      │ │
│ │                │     (activation): Identity()                            │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/seg │
│ mentation_models_pytorch/base/model.py:38 in forward                         │
│                                                                              │
│   35 │   │                                                                   │
│   36 │   │   self.check_input_shape(x)                                       │
│   37 │   │                                                                   │
│ ❱ 38 │   │   features = self.encoder(x)                                      │
│   39 │   │   decoder_output = self.decoder(*features)                        │
│   40 │   │                                                                   │
│   41 │   │   masks = self.segmentation_head(decoder_output)                  │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ self = Unet(                                                             │ │
│ │          (encoder): ResNetEncoder(                                       │ │
│ │        │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),     │ │
│ │        padding=(3, 3), bias=False)                                       │ │
│ │        │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,  │ │
│ │        track_running_stats=True)                                         │ │
│ │        │   (relu): ReLU(inplace=True)                                    │ │
│ │        │   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,      │ │
│ │        dilation=1, ceil_mode=False)                                      │ │
│ │        │   (layer1): Sequential(                                         │ │
│ │        │     (0): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (1): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (2): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │        │   (layer2): Sequential(                                         │ │
│ │        │     (0): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2,   │ │
│ │        2), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (downsample): Sequential(                                 │ │
│ │        │   │     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), │ │
│ │        bias=False)                                                       │ │
│ │        │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (1): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (2): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (3): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │        │   (layer3): Sequential(                                         │ │
│ │        │     (0): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2,  │ │
│ │        2), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (downsample): Sequential(                                 │ │
│ │        │   │     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,    │ │
│ │        2), bias=False)                                                   │ │
│ │        │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (1): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (2): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (3): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (4): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (5): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │        │   (layer4): Sequential(                                         │ │
│ │        │     (0): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2,  │ │
│ │        2), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (downsample): Sequential(                                 │ │
│ │        │   │     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,    │ │
│ │        2), bias=False)                                                   │ │
│ │        │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (1): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │     (2): BasicBlock(                                            │ │
│ │        │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │   (relu): ReLU(inplace=True)                                │ │
│ │        │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │          )                                                               │ │
│ │          (decoder): UnetDecoder(                                         │ │
│ │        │   (center): Identity()                                          │ │
│ │        │   (blocks): ModuleList(                                         │ │
│ │        │     (0): DecoderBlock(                                          │ │
│ │        │   │   (conv1): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention1): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (conv2): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention2): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (1): DecoderBlock(                                          │ │
│ │        │   │   (conv1): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention1): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (conv2): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,    │ │
│ │        1), padding=(1, 1), bias=False)                                   │ │
│ │        │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention2): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (2): DecoderBlock(                                          │ │
│ │        │   │   (conv1): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention1): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (conv2): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention2): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (3): DecoderBlock(                                          │ │
│ │        │   │   (conv1): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention1): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (conv2): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention2): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │     (4): DecoderBlock(                                          │ │
│ │        │   │   (conv1): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention1): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (conv2): Conv2dReLU(                                      │ │
│ │        │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │        padding=(1, 1), bias=False)                                       │ │
│ │        │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,           │ │
│ │        affine=True, track_running_stats=True)                            │ │
│ │        │   │     (2): ReLU(inplace=True)                                 │ │
│ │        │   │   )                                                         │ │
│ │        │   │   (attention2): Attention(                                  │ │
│ │        │   │     (attention): Identity()                                 │ │
│ │        │   │   )                                                         │ │
│ │        │     )                                                           │ │
│ │        │   )                                                             │ │
│ │          )                                                               │ │
│ │          (segmentation_head): SegmentationHead(                          │ │
│ │        │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),         │ │
│ │        padding=(1, 1))                                                   │ │
│ │        │   (1): Identity()                                               │ │
│ │        │   (2): Activation(                                              │ │
│ │        │     (activation): Identity()                                    │ │
│ │        │   )                                                             │ │
│ │          )                                                               │ │
│ │        )                                                                 │ │
│ │    x = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181,     │ │
│ │        -0.7150],                                                         │ │
│ │        │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,     │ │
│ │        -1.0972],                                                         │ │
│ │        │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,     │ │
│ │        -1.4232],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,     │ │
│ │        0.9101],                                                          │ │
│ │        │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,     │ │
│ │        0.8617],                                                          │ │
│ │        │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,     │ │
│ │        0.9036]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,     │ │
│ │        -0.5082],                                                         │ │
│ │        │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,     │ │
│ │        -0.9126],                                                         │ │
│ │        │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,     │ │
│ │        -1.3879],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,     │ │
│ │        0.6028],                                                          │ │
│ │        │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,     │ │
│ │        0.5956],                                                          │ │
│ │        │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,     │ │
│ │        0.6924]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,     │ │
│ │        -0.5277],                                                         │ │
│ │        │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,     │ │
│ │        -0.8895],                                                         │ │
│ │        │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,     │ │
│ │        -1.2979],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,     │ │
│ │        0.5816],                                                          │ │
│ │        │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,     │ │
│ │        0.5691],                                                          │ │
│ │        │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,     │ │
│ │        0.6669]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,     │ │
│ │        -0.2770],                                                         │ │
│ │        │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,     │ │
│ │        -0.5444],                                                         │ │
│ │        │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,     │ │
│ │        -0.2837],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,     │ │
│ │        1.6655],                                                          │ │
│ │        │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,     │ │
│ │        1.5620],                                                          │ │
│ │        │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,     │ │
│ │        1.8721]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,     │ │
│ │        0.0557],                                                          │ │
│ │        │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,     │ │
│ │        -0.1675],                                                         │ │
│ │        │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,     │ │
│ │        0.0236],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,     │ │
│ │        1.7636],                                                          │ │
│ │        │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,     │ │
│ │        1.6086],                                                          │ │
│ │        │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,     │ │
│ │        1.8320]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,     │ │
│ │        -0.0534],                                                         │ │
│ │        │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,     │ │
│ │        -0.3465],                                                         │ │
│ │        │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,     │ │
│ │        -0.0941],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,     │ │
│ │        1.6536],                                                          │ │
│ │        │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,     │ │
│ │        1.4997],                                                          │ │
│ │        │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,     │ │
│ │        1.7204]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,     │ │
│ │        0.1973],                                                          │ │
│ │        │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,     │ │
│ │        -0.6588],                                                         │ │
│ │        │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,     │ │
│ │        -0.8335],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,     │ │
│ │        1.2763],                                                          │ │
│ │        │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,     │ │
│ │        1.1958],                                                          │ │
│ │        │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,     │ │
│ │        1.2777]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,     │ │
│ │        0.2545],                                                          │ │
│ │        │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,     │ │
│ │        -0.0257],                                                         │ │
│ │        │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,     │ │
│ │        -0.5923],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,     │ │
│ │        1.4460],                                                          │ │
│ │        │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,     │ │
│ │        1.5811],                                                          │ │
│ │        │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,     │ │
│ │        1.6993]],                                                         │ │
│ │        │   │                                                             │ │
│ │        │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,     │ │
│ │        0.0363],                                                          │ │
│ │        │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,     │ │
│ │        -0.5162],                                                         │ │
│ │        │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,     │ │
│ │        -0.8337],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,     │ │
│ │        1.9397],                                                          │ │
│ │        │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,     │ │
│ │        2.2087],                                                          │ │
│ │        │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,     │ │
│ │        2.2691]]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   ...,                                                      │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,     │ │
│ │        -0.7780],                                                         │ │
│ │        │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,     │ │
│ │        -0.8144],                                                         │ │
│ │        │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,     │ │
│ │        -0.9166],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,     │ │
│ │        -0.2532],                                                         │ │
│ │        │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,     │ │
│ │        -0.4672],                                                         │ │
│ │        │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,     │ │
│ │        -0.7189]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,     │ │
│ │        -0.2325],                                                         │ │
│ │        │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,     │ │
│ │        -0.3049],                                                         │ │
│ │        │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,     │ │
│ │        -0.5231],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,     │ │
│ │        0.1731],                                                          │ │
│ │        │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,     │ │
│ │        -0.0727],                                                         │ │
│ │        │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,     │ │
│ │        -0.3332]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,     │ │
│ │        -0.7336],                                                         │ │
│ │        │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,     │ │
│ │        -0.7594],                                                         │ │
│ │        │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,     │ │
│ │        -0.8245],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,     │ │
│ │        0.1228],                                                          │ │
│ │        │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,     │ │
│ │        -0.2418],                                                         │ │
│ │        │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,     │ │
│ │        -0.5858]]],                                                       │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,     │ │
│ │        -0.7818],                                                         │ │
│ │        │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,     │ │
│ │        -0.5808],                                                         │ │
│ │        │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,     │ │
│ │        -0.4384],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,     │ │
│ │        -0.1735],                                                         │ │
│ │        │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,     │ │
│ │        -0.3986],                                                         │ │
│ │        │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,     │ │
│ │        -0.6006]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,     │ │
│ │        -0.4003],                                                         │ │
│ │        │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,     │ │
│ │        -0.1698],                                                         │ │
│ │        │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,     │ │
│ │        0.0299],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,     │ │
│ │        0.3566],                                                          │ │
│ │        │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,     │ │
│ │        0.0399],                                                          │ │
│ │        │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,     │ │
│ │        -0.1875]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,     │ │
│ │        -0.7503],                                                         │ │
│ │        │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,     │ │
│ │        -0.5004],                                                         │ │
│ │        │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,     │ │
│ │        -0.3569],                                                         │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,     │ │
│ │        0.2921],                                                          │ │
│ │        │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,     │ │
│ │        -0.1004],                                                         │ │
│ │        │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,     │ │
│ │        -0.3513]]],                                                       │ │
│ │        │   │                                                             │ │
│ │        │   │                                                             │ │
│ │        │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,     │ │
│ │        1.0863],                                                          │ │
│ │        │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,     │ │
│ │        1.1525],                                                          │ │
│ │        │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,     │ │
│ │        1.1589],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,     │ │
│ │        -0.5779],                                                         │ │
│ │        │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,     │ │
│ │        -0.6436],                                                         │ │
│ │        │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,     │ │
│ │        -0.7261]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,     │ │
│ │        0.5173],                                                          │ │
│ │        │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,     │ │
│ │        0.5988],                                                          │ │
│ │        │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,     │ │
│ │        0.6056],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,     │ │
│ │        -0.1621],                                                         │ │
│ │        │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,     │ │
│ │        -0.2276],                                                         │ │
│ │        │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,     │ │
│ │        -0.3032]],                                                        │ │
│ │        │   │                                                             │ │
│ │        │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,     │ │
│ │        0.1735],                                                          │ │
│ │        │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,     │ │
│ │        0.2187],                                                          │ │
│ │        │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,     │ │
│ │        0.2250],                                                          │ │
│ │        │   │     ...,                                                    │ │
│ │        │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,     │ │
│ │        -0.4766],                                                         │ │
│ │        │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,     │ │
│ │        -0.5442],                                                         │ │
│ │        │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,     │ │
│ │        -0.6154]]]],                                                      │ │
│ │        │      device='cuda:0', dtype=torch.float64)                      │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,        │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = ResNetEncoder(                                                  │ │
│ │            (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),     │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,  │ │
│ │          track_running_stats=True)                                       │ │
│ │            (relu): ReLU(inplace=True)                                    │ │
│ │            (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,      │ │
│ │          dilation=1, ceil_mode=False)                                    │ │
│ │            (layer1): Sequential(                                         │ │
│ │          │   (0): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (1): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (2): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,    │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (layer2): Sequential(                                         │ │
│ │          │   (0): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2,   │ │
│ │          2), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (downsample): Sequential(                                 │ │
│ │          │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), │ │
│ │          bias=False)                                                     │ │
│ │          │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (1): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (2): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (3): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (layer3): Sequential(                                         │ │
│ │          │   (0): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2,  │ │
│ │          2), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (downsample): Sequential(                                 │ │
│ │          │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,    │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (1): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (2): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (3): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (4): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (5): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (layer4): Sequential(                                         │ │
│ │          │   (0): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2,  │ │
│ │          2), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (downsample): Sequential(                                 │ │
│ │          │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,    │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (1): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │          │   (2): BasicBlock(                                            │ │
│ │          │     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,  │ │
│ │                -0.6181, -0.7150],                                        │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method ResNetEncoder.forward of ResNetEncoder(     │ │
│ │                  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │                2), padding=(3, 3), bias=False)                           │ │
│ │                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                  (relu): ReLU(inplace=True)                              │ │
│ │                  (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                  (layer1): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer2): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (3): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer3): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (3): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (4): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (5): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer4): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = ResNetEncoder(                                            │ │
│ │                  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │                2), padding=(3, 3), bias=False)                           │ │
│ │                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                  (relu): ReLU(inplace=True)                              │ │
│ │                  (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                  (layer1): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer2): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (3): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer3): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (3): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (4): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (5): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (layer4): Sequential(                                   │ │
│ │                │   (0): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (downsample): Sequential(                           │ │
│ │                │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (1): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                │   (2): BasicBlock(                                      │ │
│ │                │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/seg │
│ mentation_models_pytorch/encoders/resnet.py:63 in forward                    │
│                                                                              │
│    60 │   │                                                                  │
│    61 │   │   features = []                                                  │
│    62 │   │   for i in range(self._depth + 1):                               │
│ ❱  63 │   │   │   x = stages[i](x)                                           │
│    64 │   │   │   features.append(x)                                         │
│    65 │   │                                                                  │
│    66 │   │   return features                                                │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ features = [                                                             │ │
│ │            │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,      │ │
│ │            -0.6181, -0.7150],                                            │ │
│ │            │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470, │ │
│ │            -1.0972],                                                     │ │
│ │            │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672, │ │
│ │            -1.4232],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201, │ │
│ │            0.9101],                                                      │ │
│ │            │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934, │ │
│ │            0.8617],                                                      │ │
│ │            │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312, │ │
│ │            0.9036]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903, │ │
│ │            -0.5082],                                                     │ │
│ │            │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269, │ │
│ │            -0.9126],                                                     │ │
│ │            │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571, │ │
│ │            -1.3879],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149, │ │
│ │            0.6028],                                                      │ │
│ │            │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133, │ │
│ │            0.5956],                                                      │ │
│ │            │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766, │ │
│ │            0.6924]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887, │ │
│ │            -0.5277],                                                     │ │
│ │            │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726, │ │
│ │            -0.8895],                                                     │ │
│ │            │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241, │ │
│ │            -1.2979],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844, │ │
│ │            0.5816],                                                      │ │
│ │            │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917, │ │
│ │            0.5691],                                                      │ │
│ │            │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424, │ │
│ │            0.6669]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125, │ │
│ │            -0.2770],                                                     │ │
│ │            │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637, │ │
│ │            -0.5444],                                                     │ │
│ │            │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721, │ │
│ │            -0.2837],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731, │ │
│ │            1.6655],                                                      │ │
│ │            │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633, │ │
│ │            1.5620],                                                      │ │
│ │            │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766, │ │
│ │            1.8721]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699, │ │
│ │            0.0557],                                                      │ │
│ │            │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547, │ │
│ │            -0.1675],                                                     │ │
│ │            │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220, │ │
│ │            0.0236],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006, │ │
│ │            1.7636],                                                      │ │
│ │            │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452, │ │
│ │            1.6086],                                                      │ │
│ │            │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005, │ │
│ │            1.8320]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504, │ │
│ │            -0.0534],                                                     │ │
│ │            │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084, │ │
│ │            -0.3465],                                                     │ │
│ │            │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836, │ │
│ │            -0.0941],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997, │ │
│ │            1.6536],                                                      │ │
│ │            │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373, │ │
│ │            1.4997],                                                      │ │
│ │            │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704, │ │
│ │            1.7204]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527, │ │
│ │            0.1973],                                                      │ │
│ │            │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741, │ │
│ │            -0.6588],                                                     │ │
│ │            │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624, │ │
│ │            -0.8335],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495, │ │
│ │            1.2763],                                                      │ │
│ │            │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270, │ │
│ │            1.1958],                                                      │ │
│ │            │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479, │ │
│ │            1.2777]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290, │ │
│ │            0.2545],                                                      │ │
│ │            │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367, │ │
│ │            -0.0257],                                                     │ │
│ │            │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202, │ │
│ │            -0.5923],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171, │ │
│ │            1.4460],                                                      │ │
│ │            │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998, │ │
│ │            1.5811],                                                      │ │
│ │            │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719, │ │
│ │            1.6993]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811, │ │
│ │            0.0363],                                                      │ │
│ │            │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587, │ │
│ │            -0.5162],                                                     │ │
│ │            │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376, │ │
│ │            -0.8337],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169, │ │
│ │            1.9397],                                                      │ │
│ │            │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213, │ │
│ │            2.2087],                                                      │ │
│ │            │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530, │ │
│ │            2.2691]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   ...,                                                  │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623, │ │
│ │            -0.7780],                                                     │ │
│ │            │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748, │ │
│ │            -0.8144],                                                     │ │
│ │            │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039, │ │
│ │            -0.9166],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917, │ │
│ │            -0.2532],                                                     │ │
│ │            │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002, │ │
│ │            -0.4672],                                                     │ │
│ │            │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219, │ │
│ │            -0.7189]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644, │ │
│ │            -0.2325],                                                     │ │
│ │            │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394, │ │
│ │            -0.3049],                                                     │ │
│ │            │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470, │ │
│ │            -0.5231],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438, │ │
│ │            0.1731],                                                      │ │
│ │            │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176, │ │
│ │            -0.0727],                                                     │ │
│ │            │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082, │ │
│ │            -0.3332]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085, │ │
│ │            -0.7336],                                                     │ │
│ │            │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846, │ │
│ │            -0.7594],                                                     │ │
│ │            │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978, │ │
│ │            -0.8245],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215, │ │
│ │            0.1228],                                                      │ │
│ │            │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605, │ │
│ │            -0.2418],                                                     │ │
│ │            │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024, │ │
│ │            -0.5858]]],                                                   │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567, │ │
│ │            -0.7818],                                                     │ │
│ │            │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521, │ │
│ │            -0.5808],                                                     │ │
│ │            │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200, │ │
│ │            -0.4384],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494, │ │
│ │            -0.1735],                                                     │ │
│ │            │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537, │ │
│ │            -0.3986],                                                     │ │
│ │            │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791, │ │
│ │            -0.6006]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687, │ │
│ │            -0.4003],                                                     │ │
│ │            │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354, │ │
│ │            -0.1698],                                                     │ │
│ │            │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203, │ │
│ │            0.0299],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123, │ │
│ │            0.3566],                                                      │ │
│ │            │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030, │ │
│ │            0.0399],                                                      │ │
│ │            │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388, │ │
│ │            -0.1875]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522, │ │
│ │            -0.7503],                                                     │ │
│ │            │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105, │ │
│ │            -0.5004],                                                     │ │
│ │            │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854, │ │
│ │            -0.3569],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653, │ │
│ │            0.2921],                                                      │ │
│ │            │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336, │ │
│ │            -0.1004],                                                     │ │
│ │            │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689, │ │
│ │            -0.3513]]],                                                   │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517, │ │
│ │            1.0863],                                                      │ │
│ │            │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228, │ │
│ │            1.1525],                                                      │ │
│ │            │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681, │ │
│ │            1.1589],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756, │ │
│ │            -0.5779],                                                     │ │
│ │            │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458, │ │
│ │            -0.6436],                                                     │ │
│ │            │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063, │ │
│ │            -0.7261]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726, │ │
│ │            0.5173],                                                      │ │
│ │            │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592, │ │
│ │            0.5988],                                                      │ │
│ │            │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153, │ │
│ │            0.6056],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196, │ │
│ │            -0.1621],                                                     │ │
│ │            │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920, │ │
│ │            -0.2276],                                                     │ │
│ │            │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507, │ │
│ │            -0.3032]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579, │ │
│ │            0.1735],                                                      │ │
│ │            │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026, │ │
│ │            0.2187],                                                      │ │
│ │            │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340, │ │
│ │            0.2250],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467, │ │
│ │            -0.4766],                                                     │ │
│ │            │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244, │ │
│ │            -0.5442],                                                     │ │
│ │            │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930, │ │
│ │            -0.6154]]]],                                                  │ │
│ │            │      device='cuda:0', dtype=torch.float64)                  │ │
│ │            ]                                                             │ │
│ │        i = 1                                                             │ │
│ │     self = ResNetEncoder(                                                │ │
│ │              (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),   │ │
│ │            padding=(3, 3), bias=False)                                   │ │
│ │              (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,             │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              (relu): ReLU(inplace=True)                                  │ │
│ │              (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,    │ │
│ │            dilation=1, ceil_mode=False)                                  │ │
│ │              (layer1): Sequential(                                       │ │
│ │            │   (0): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (1): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (2): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (layer2): Sequential(                                       │ │
│ │            │   (0): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, │ │
│ │            2), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (downsample): Sequential(                               │ │
│ │            │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2,   │ │
│ │            2), bias=False)                                               │ │
│ │            │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (1): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (2): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (3): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (layer3): Sequential(                                       │ │
│ │            │   (0): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),           │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (downsample): Sequential(                               │ │
│ │            │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,  │ │
│ │            2), bias=False)                                               │ │
│ │            │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (1): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (2): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (3): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (4): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (5): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (layer4): Sequential(                                       │ │
│ │            │   (0): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),           │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (downsample): Sequential(                               │ │
│ │            │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,  │ │
│ │            2), bias=False)                                               │ │
│ │            │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (1): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (2): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,        │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │            )                                                             │ │
│ │   stages = [                                                             │ │
│ │            │   Identity(),                                               │ │
│ │            │   Sequential(                                               │ │
│ │              (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),       │ │
│ │            padding=(3, 3), bias=False)                                   │ │
│ │              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,  │ │
│ │            track_running_stats=True)                                     │ │
│ │              (2): ReLU(inplace=True)                                     │ │
│ │            ),                                                            │ │
│ │            │   Sequential(                                               │ │
│ │              (0): MaxPool2d(kernel_size=3, stride=2, padding=1,          │ │
│ │            dilation=1, ceil_mode=False)                                  │ │
│ │              (1): Sequential(                                            │ │
│ │            │   (0): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (1): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │            │   (2): BasicBlock(                                          │ │
│ │            │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │            ),                                                            │ │
│ │            │   Sequential(                                               │ │
│ │              (0): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2,   │ │
│ │            2), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (downsample): Sequential(                                 │ │
│ │            │     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), │ │
│ │            bias=False)                                                   │ │
│ │            │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (1): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (2): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (3): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │            ),                                                            │ │
│ │            │   Sequential(                                               │ │
│ │              (0): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2,  │ │
│ │            2), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (downsample): Sequential(                                 │ │
│ │            │     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2,    │ │
│ │            2), bias=False)                                               │ │
│ │            │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (1): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (2): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (3): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (4): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (5): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │            ),                                                            │ │
│ │            │   Sequential(                                               │ │
│ │              (0): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2,  │ │
│ │            2), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (downsample): Sequential(                                 │ │
│ │            │     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2,    │ │
│ │            2), bias=False)                                               │ │
│ │            │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (1): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │              (2): BasicBlock(                                            │ │
│ │            │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   (relu): ReLU(inplace=True)                                │ │
│ │            │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1,  │ │
│ │            1), padding=(1, 1), bias=False)                               │ │
│ │            │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,          │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │              )                                                           │ │
│ │            )                                                             │ │
│ │            ]                                                             │ │
│ │        x = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181, │ │
│ │            -0.7150],                                                     │ │
│ │            │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470, │ │
│ │            -1.0972],                                                     │ │
│ │            │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672, │ │
│ │            -1.4232],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201, │ │
│ │            0.9101],                                                      │ │
│ │            │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934, │ │
│ │            0.8617],                                                      │ │
│ │            │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312, │ │
│ │            0.9036]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903, │ │
│ │            -0.5082],                                                     │ │
│ │            │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269, │ │
│ │            -0.9126],                                                     │ │
│ │            │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571, │ │
│ │            -1.3879],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149, │ │
│ │            0.6028],                                                      │ │
│ │            │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133, │ │
│ │            0.5956],                                                      │ │
│ │            │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766, │ │
│ │            0.6924]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887, │ │
│ │            -0.5277],                                                     │ │
│ │            │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726, │ │
│ │            -0.8895],                                                     │ │
│ │            │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241, │ │
│ │            -1.2979],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844, │ │
│ │            0.5816],                                                      │ │
│ │            │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917, │ │
│ │            0.5691],                                                      │ │
│ │            │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424, │ │
│ │            0.6669]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125, │ │
│ │            -0.2770],                                                     │ │
│ │            │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637, │ │
│ │            -0.5444],                                                     │ │
│ │            │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721, │ │
│ │            -0.2837],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731, │ │
│ │            1.6655],                                                      │ │
│ │            │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633, │ │
│ │            1.5620],                                                      │ │
│ │            │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766, │ │
│ │            1.8721]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699, │ │
│ │            0.0557],                                                      │ │
│ │            │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547, │ │
│ │            -0.1675],                                                     │ │
│ │            │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220, │ │
│ │            0.0236],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006, │ │
│ │            1.7636],                                                      │ │
│ │            │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452, │ │
│ │            1.6086],                                                      │ │
│ │            │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005, │ │
│ │            1.8320]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504, │ │
│ │            -0.0534],                                                     │ │
│ │            │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084, │ │
│ │            -0.3465],                                                     │ │
│ │            │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836, │ │
│ │            -0.0941],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997, │ │
│ │            1.6536],                                                      │ │
│ │            │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373, │ │
│ │            1.4997],                                                      │ │
│ │            │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704, │ │
│ │            1.7204]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527, │ │
│ │            0.1973],                                                      │ │
│ │            │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741, │ │
│ │            -0.6588],                                                     │ │
│ │            │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624, │ │
│ │            -0.8335],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495, │ │
│ │            1.2763],                                                      │ │
│ │            │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270, │ │
│ │            1.1958],                                                      │ │
│ │            │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479, │ │
│ │            1.2777]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290, │ │
│ │            0.2545],                                                      │ │
│ │            │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367, │ │
│ │            -0.0257],                                                     │ │
│ │            │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202, │ │
│ │            -0.5923],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171, │ │
│ │            1.4460],                                                      │ │
│ │            │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998, │ │
│ │            1.5811],                                                      │ │
│ │            │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719, │ │
│ │            1.6993]],                                                     │ │
│ │            │   │                                                         │ │
│ │            │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811, │ │
│ │            0.0363],                                                      │ │
│ │            │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587, │ │
│ │            -0.5162],                                                     │ │
│ │            │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376, │ │
│ │            -0.8337],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169, │ │
│ │            1.9397],                                                      │ │
│ │            │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213, │ │
│ │            2.2087],                                                      │ │
│ │            │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530, │ │
│ │            2.2691]]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   ...,                                                  │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623, │ │
│ │            -0.7780],                                                     │ │
│ │            │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748, │ │
│ │            -0.8144],                                                     │ │
│ │            │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039, │ │
│ │            -0.9166],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917, │ │
│ │            -0.2532],                                                     │ │
│ │            │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002, │ │
│ │            -0.4672],                                                     │ │
│ │            │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219, │ │
│ │            -0.7189]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644, │ │
│ │            -0.2325],                                                     │ │
│ │            │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394, │ │
│ │            -0.3049],                                                     │ │
│ │            │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470, │ │
│ │            -0.5231],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438, │ │
│ │            0.1731],                                                      │ │
│ │            │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176, │ │
│ │            -0.0727],                                                     │ │
│ │            │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082, │ │
│ │            -0.3332]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085, │ │
│ │            -0.7336],                                                     │ │
│ │            │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846, │ │
│ │            -0.7594],                                                     │ │
│ │            │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978, │ │
│ │            -0.8245],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215, │ │
│ │            0.1228],                                                      │ │
│ │            │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605, │ │
│ │            -0.2418],                                                     │ │
│ │            │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024, │ │
│ │            -0.5858]]],                                                   │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567, │ │
│ │            -0.7818],                                                     │ │
│ │            │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521, │ │
│ │            -0.5808],                                                     │ │
│ │            │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200, │ │
│ │            -0.4384],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494, │ │
│ │            -0.1735],                                                     │ │
│ │            │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537, │ │
│ │            -0.3986],                                                     │ │
│ │            │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791, │ │
│ │            -0.6006]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687, │ │
│ │            -0.4003],                                                     │ │
│ │            │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354, │ │
│ │            -0.1698],                                                     │ │
│ │            │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203, │ │
│ │            0.0299],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123, │ │
│ │            0.3566],                                                      │ │
│ │            │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030, │ │
│ │            0.0399],                                                      │ │
│ │            │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388, │ │
│ │            -0.1875]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522, │ │
│ │            -0.7503],                                                     │ │
│ │            │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105, │ │
│ │            -0.5004],                                                     │ │
│ │            │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854, │ │
│ │            -0.3569],                                                     │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653, │ │
│ │            0.2921],                                                      │ │
│ │            │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336, │ │
│ │            -0.1004],                                                     │ │
│ │            │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689, │ │
│ │            -0.3513]]],                                                   │ │
│ │            │   │                                                         │ │
│ │            │   │                                                         │ │
│ │            │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517, │ │
│ │            1.0863],                                                      │ │
│ │            │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228, │ │
│ │            1.1525],                                                      │ │
│ │            │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681, │ │
│ │            1.1589],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756, │ │
│ │            -0.5779],                                                     │ │
│ │            │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458, │ │
│ │            -0.6436],                                                     │ │
│ │            │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063, │ │
│ │            -0.7261]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726, │ │
│ │            0.5173],                                                      │ │
│ │            │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592, │ │
│ │            0.5988],                                                      │ │
│ │            │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153, │ │
│ │            0.6056],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196, │ │
│ │            -0.1621],                                                     │ │
│ │            │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920, │ │
│ │            -0.2276],                                                     │ │
│ │            │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507, │ │
│ │            -0.3032]],                                                    │ │
│ │            │   │                                                         │ │
│ │            │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579, │ │
│ │            0.1735],                                                      │ │
│ │            │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026, │ │
│ │            0.2187],                                                      │ │
│ │            │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340, │ │
│ │            0.2250],                                                      │ │
│ │            │   │     ...,                                                │ │
│ │            │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467, │ │
│ │            -0.4766],                                                     │ │
│ │            │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244, │ │
│ │            -0.5442],                                                     │ │
│ │            │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930, │ │
│ │            -0.6154]]]],                                                  │ │
│ │            │      device='cuda:0', dtype=torch.float64)                  │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,        │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = Sequential(                                                     │ │
│ │            (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),         │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,    │ │
│ │          track_running_stats=True)                                       │ │
│ │            (2): ReLU(inplace=True)                                       │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,  │ │
│ │                -0.6181, -0.7150],                                        │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method Sequential.forward of Sequential(           │ │
│ │                  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),   │ │
│ │                padding=(3, 3), bias=False)                               │ │
│ │                  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                  (2): ReLU(inplace=True)                                 │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = Sequential(                                               │ │
│ │                  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),   │ │
│ │                padding=(3, 3), bias=False)                               │ │
│ │                  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                  (2): ReLU(inplace=True)                                 │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/container.py:217 in forward                                    │
│                                                                              │
│   214 │   # with Any as TorchScript expects a more precise type              │
│   215 │   def forward(self, input):                                          │
│   216 │   │   for module in self:                                            │
│ ❱ 217 │   │   │   input = module(input)                                      │
│   218 │   │   return input                                                   │
│   219 │                                                                      │
│   220 │   def append(self, module: Module) -> 'Sequential':                  │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │  input = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181,   │ │
│ │          -0.7150],                                                       │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64)                    │ │
│ │ module = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3,    │ │
│ │          3), bias=False)                                                 │ │
│ │   self = Sequential(                                                     │ │
│ │            (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),         │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True,    │ │
│ │          track_running_stats=True)                                       │ │
│ │            (2): ReLU(inplace=True)                                       │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,        │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64),                   │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3,    │ │
│ │          3), bias=False)                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,  │ │
│ │                -0.6181, -0.7150],                                        │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0', dtype=torch.float64),             │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method Conv2d.forward of Conv2d(3, 64,             │ │
│ │                kernel_size=(7, 7), stride=(2, 2), padding=(3, 3),        │ │
│ │                bias=False)>                                              │ │
│ │       kwargs = {}                                                        │ │
│ │         self = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2),          │ │
│ │                padding=(3, 3), bias=False)                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/conv.py:460 in forward                                         │
│                                                                              │
│    457 │   │   │   │   │   │   self.padding, self.dilation, self.groups)     │
│    458 │                                                                     │
│    459 │   def forward(self, input: Tensor) -> Tensor:                       │
│ ❱  460 │   │   return self._conv_forward(input, self.weight, self.bias)      │
│    461                                                                       │
│    462 class Conv3d(_ConvNd):                                                │
│    463 │   __doc__ = r"""Applies a 3D convolution over an input signal compo │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ input = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181,    │ │
│ │         -0.7150],                                                        │ │
│ │         │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,    │ │
│ │         -1.0972],                                                        │ │
│ │         │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,    │ │
│ │         -1.4232],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,    │ │
│ │         0.9101],                                                         │ │
│ │         │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,    │ │
│ │         0.8617],                                                         │ │
│ │         │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,    │ │
│ │         0.9036]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,    │ │
│ │         -0.5082],                                                        │ │
│ │         │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,    │ │
│ │         -0.9126],                                                        │ │
│ │         │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,    │ │
│ │         -1.3879],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,    │ │
│ │         0.6028],                                                         │ │
│ │         │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,    │ │
│ │         0.5956],                                                         │ │
│ │         │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,    │ │
│ │         0.6924]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,    │ │
│ │         -0.5277],                                                        │ │
│ │         │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,    │ │
│ │         -0.8895],                                                        │ │
│ │         │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,    │ │
│ │         -1.2979],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,    │ │
│ │         0.5816],                                                         │ │
│ │         │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,    │ │
│ │         0.5691],                                                         │ │
│ │         │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,    │ │
│ │         0.6669]]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,    │ │
│ │         -0.2770],                                                        │ │
│ │         │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,    │ │
│ │         -0.5444],                                                        │ │
│ │         │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,    │ │
│ │         -0.2837],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,    │ │
│ │         1.6655],                                                         │ │
│ │         │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,    │ │
│ │         1.5620],                                                         │ │
│ │         │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,    │ │
│ │         1.8721]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,    │ │
│ │         0.0557],                                                         │ │
│ │         │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,    │ │
│ │         -0.1675],                                                        │ │
│ │         │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,    │ │
│ │         0.0236],                                                         │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,    │ │
│ │         1.7636],                                                         │ │
│ │         │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,    │ │
│ │         1.6086],                                                         │ │
│ │         │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,    │ │
│ │         1.8320]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,    │ │
│ │         -0.0534],                                                        │ │
│ │         │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,    │ │
│ │         -0.3465],                                                        │ │
│ │         │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,    │ │
│ │         -0.0941],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,    │ │
│ │         1.6536],                                                         │ │
│ │         │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,    │ │
│ │         1.4997],                                                         │ │
│ │         │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,    │ │
│ │         1.7204]]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,    │ │
│ │         0.1973],                                                         │ │
│ │         │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,    │ │
│ │         -0.6588],                                                        │ │
│ │         │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,    │ │
│ │         -0.8335],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,    │ │
│ │         1.2763],                                                         │ │
│ │         │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,    │ │
│ │         1.1958],                                                         │ │
│ │         │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,    │ │
│ │         1.2777]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,    │ │
│ │         0.2545],                                                         │ │
│ │         │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,    │ │
│ │         -0.0257],                                                        │ │
│ │         │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,    │ │
│ │         -0.5923],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,    │ │
│ │         1.4460],                                                         │ │
│ │         │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,    │ │
│ │         1.5811],                                                         │ │
│ │         │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,    │ │
│ │         1.6993]],                                                        │ │
│ │         │   │                                                            │ │
│ │         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,    │ │
│ │         0.0363],                                                         │ │
│ │         │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,    │ │
│ │         -0.5162],                                                        │ │
│ │         │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,    │ │
│ │         -0.8337],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,    │ │
│ │         1.9397],                                                         │ │
│ │         │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,    │ │
│ │         2.2087],                                                         │ │
│ │         │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,    │ │
│ │         2.2691]]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   ...,                                                     │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,    │ │
│ │         -0.7780],                                                        │ │
│ │         │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,    │ │
│ │         -0.8144],                                                        │ │
│ │         │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,    │ │
│ │         -0.9166],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,    │ │
│ │         -0.2532],                                                        │ │
│ │         │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,    │ │
│ │         -0.4672],                                                        │ │
│ │         │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,    │ │
│ │         -0.7189]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,    │ │
│ │         -0.2325],                                                        │ │
│ │         │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,    │ │
│ │         -0.3049],                                                        │ │
│ │         │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,    │ │
│ │         -0.5231],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,    │ │
│ │         0.1731],                                                         │ │
│ │         │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,    │ │
│ │         -0.0727],                                                        │ │
│ │         │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,    │ │
│ │         -0.3332]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,    │ │
│ │         -0.7336],                                                        │ │
│ │         │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,    │ │
│ │         -0.7594],                                                        │ │
│ │         │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,    │ │
│ │         -0.8245],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,    │ │
│ │         0.1228],                                                         │ │
│ │         │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,    │ │
│ │         -0.2418],                                                        │ │
│ │         │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,    │ │
│ │         -0.5858]]],                                                      │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,    │ │
│ │         -0.7818],                                                        │ │
│ │         │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,    │ │
│ │         -0.5808],                                                        │ │
│ │         │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,    │ │
│ │         -0.4384],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,    │ │
│ │         -0.1735],                                                        │ │
│ │         │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,    │ │
│ │         -0.3986],                                                        │ │
│ │         │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,    │ │
│ │         -0.6006]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,    │ │
│ │         -0.4003],                                                        │ │
│ │         │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,    │ │
│ │         -0.1698],                                                        │ │
│ │         │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,    │ │
│ │         0.0299],                                                         │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,    │ │
│ │         0.3566],                                                         │ │
│ │         │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,    │ │
│ │         0.0399],                                                         │ │
│ │         │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,    │ │
│ │         -0.1875]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,    │ │
│ │         -0.7503],                                                        │ │
│ │         │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,    │ │
│ │         -0.5004],                                                        │ │
│ │         │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,    │ │
│ │         -0.3569],                                                        │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,    │ │
│ │         0.2921],                                                         │ │
│ │         │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,    │ │
│ │         -0.1004],                                                        │ │
│ │         │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,    │ │
│ │         -0.3513]]],                                                      │ │
│ │         │   │                                                            │ │
│ │         │   │                                                            │ │
│ │         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,    │ │
│ │         1.0863],                                                         │ │
│ │         │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,    │ │
│ │         1.1525],                                                         │ │
│ │         │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,    │ │
│ │         1.1589],                                                         │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,    │ │
│ │         -0.5779],                                                        │ │
│ │         │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,    │ │
│ │         -0.6436],                                                        │ │
│ │         │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,    │ │
│ │         -0.7261]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,    │ │
│ │         0.5173],                                                         │ │
│ │         │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,    │ │
│ │         0.5988],                                                         │ │
│ │         │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,    │ │
│ │         0.6056],                                                         │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,    │ │
│ │         -0.1621],                                                        │ │
│ │         │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,    │ │
│ │         -0.2276],                                                        │ │
│ │         │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,    │ │
│ │         -0.3032]],                                                       │ │
│ │         │   │                                                            │ │
│ │         │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,    │ │
│ │         0.1735],                                                         │ │
│ │         │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,    │ │
│ │         0.2187],                                                         │ │
│ │         │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,    │ │
│ │         0.2250],                                                         │ │
│ │         │   │     ...,                                                   │ │
│ │         │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,    │ │
│ │         -0.4766],                                                        │ │
│ │         │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,    │ │
│ │         -0.5442],                                                        │ │
│ │         │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,    │ │
│ │         -0.6154]]]],                                                     │ │
│ │         │      device='cuda:0', dtype=torch.float64)                     │ │
│ │  self = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), │ │
│ │         bias=False)                                                      │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/conv.py:456 in _conv_forward                                   │
│                                                                              │
│    453 │   │   │   return F.conv2d(F.pad(input, self._reversed_padding_repea │
│    454 │   │   │   │   │   │   │   weight, bias, self.stride,                │
│    455 │   │   │   │   │   │   │   _pair(0), self.dilation, self.groups)     │
│ ❱  456 │   │   return F.conv2d(input, weight, bias, self.stride,             │
│    457 │   │   │   │   │   │   self.padding, self.dilation, self.groups)     │
│    458 │                                                                     │
│    459 │   def forward(self, input: Tensor) -> Tensor:                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   bias = None                                                            │ │
│ │  input = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058, -0.6181,   │ │
│ │          -0.7150],                                                       │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0', dtype=torch.float64)                    │ │
│ │   self = Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3,    │ │
│ │          3), bias=False)                                                 │ │
│ │ weight = Parameter containing:                                           │ │
│ │          tensor([[[[ 5.4109e-03, -6.9092e-03,  7.8839e-03,  ...,         │ │
│ │          4.9072e-02,                                                     │ │
│ │          │   │   │   3.0660e-02,  2.5398e-02],                           │ │
│ │          │   │     [ 4.1081e-02,  3.1296e-02,  3.2265e-02,  ...,         │ │
│ │          3.3145e-02,                                                     │ │
│ │          │   │   │   2.9754e-02,  4.1735e-02],                           │ │
│ │          │   │     [ 4.9519e-03, -3.1705e-02, -6.1310e-02,  ...,         │ │
│ │          -9.7493e-02,                                                    │ │
│ │          │   │      -1.1601e-01, -1.2191e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.2287e-02, -2.4841e-02, -9.3052e-03,  ...,         │ │
│ │          1.7113e-02,                                                     │ │
│ │          │   │   │   2.4631e-03,  1.6726e-02],                           │ │
│ │          │   │     [ 3.9117e-03,  4.4537e-03,  3.6315e-02,  ...,         │ │
│ │          1.0371e-01,                                                     │ │
│ │          │   │   │   7.3973e-02,  5.9085e-02],                           │ │
│ │          │   │     [ 1.6784e-02,  8.8902e-03,  3.1312e-02,  ...,         │ │
│ │          9.6964e-02,                                                     │ │
│ │          │   │   │   8.3749e-02,  9.6970e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-7.7192e-03, -8.7711e-03,  1.4143e-02,  ...,         │ │
│ │          3.3901e-02,                                                     │ │
│ │          │   │   │   2.5483e-02,  2.4275e-02],                           │ │
│ │          │   │     [ 5.3961e-02,  4.4677e-02,  3.4326e-02,  ...,         │ │
│ │          1.3392e-02,                                                     │ │
│ │          │   │   │   1.9135e-02,  3.7995e-02],                           │ │
│ │          │   │     [ 1.0251e-03, -5.4513e-02, -1.0225e-01,  ...,         │ │
│ │          -1.9231e-01,                                                    │ │
│ │          │   │      -1.9994e-01, -1.8192e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.6878e-02, -2.8386e-02, -4.4255e-03,  ...,         │ │
│ │          -6.8456e-03,                                                    │ │
│ │          │   │      -3.6264e-02, -1.1390e-02],                           │ │
│ │          │   │     [ 2.0045e-02,  3.0008e-02,  8.2949e-02,  ...,         │ │
│ │          1.6182e-01,                                                     │ │
│ │          │   │   │   1.1763e-01,  8.3941e-02],                           │ │
│ │          │   │     [ 4.1894e-02,  4.6071e-02,  8.0600e-02,  ...,         │ │
│ │          1.7516e-01,                                                     │ │
│ │          │   │   │   1.4343e-01,  1.3443e-01]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-7.7148e-03, -1.7918e-02, -2.0221e-02,  ...,         │ │
│ │          -1.3486e-02,                                                    │ │
│ │          │   │      -2.1028e-03,  7.2784e-03],                           │ │
│ │          │   │     [ 5.8849e-02,  3.8925e-02,  3.1777e-02,  ...,         │ │
│ │          2.3909e-02,                                                     │ │
│ │          │   │   │   3.5335e-02,  5.6446e-02],                           │ │
│ │          │   │     [ 2.5604e-02, -1.2546e-02, -3.2496e-02,  ...,         │ │
│ │          -8.2224e-02,                                                    │ │
│ │          │   │      -8.6249e-02, -8.8526e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 9.6982e-03,  5.0040e-04,  1.6232e-02,  ...,         │ │
│ │          1.2168e-02,                                                     │ │
│ │          │   │      -9.0300e-03,  1.3157e-02],                           │ │
│ │          │   │     [ 1.5182e-02,  1.7193e-02,  5.0388e-02,  ...,         │ │
│ │          9.9608e-02,                                                     │ │
│ │          │   │   │   6.4494e-02,  3.7811e-02],                           │ │
│ │          │   │     [ 2.2578e-02,  1.1820e-02,  3.9056e-02,  ...,         │ │
│ │          1.0658e-01,                                                     │ │
│ │          │   │   │   8.2158e-02,  6.7253e-02]]],                         │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 5.2890e-03, -1.8514e-02,  4.8604e-02,  ...,         │ │
│ │          -1.1673e-01,                                                    │ │
│ │          │   │      -7.7231e-03,  4.3190e-02],                           │ │
│ │          │   │     [ 9.9169e-03, -7.5485e-02,  8.5592e-02,  ...,         │ │
│ │          -2.5069e-01,                                                    │ │
│ │          │   │   │   3.3187e-02,  8.0061e-02],                           │ │
│ │          │   │     [ 1.0924e-02, -1.0414e-01,  9.8119e-02,  ...,         │ │
│ │          -4.6019e-01,                                                    │ │
│ │          │   │   │   1.0599e-01,  8.8966e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.3708e-02, -4.6085e-02,  4.9725e-02,  ...,         │ │
│ │          -4.9645e-01,                                                    │ │
│ │          │   │   │   1.9887e-01,  8.5659e-04],                           │ │
│ │          │   │     [-1.6414e-02, -3.3005e-02,  1.1675e-02,  ...,         │ │
│ │          -2.7291e-01,                                                    │ │
│ │          │   │   │   1.0565e-01, -2.9263e-03],                           │ │
│ │          │   │     [ 2.9204e-02, -2.3626e-02,  2.7544e-02,  ...,         │ │
│ │          -1.4070e-01,                                                    │ │
│ │          │   │   │   8.1618e-03,  7.4697e-03]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.7239e-02, -1.9221e-02,  7.1091e-02,  ...,         │ │
│ │          -1.1989e-01,                                                    │ │
│ │          │   │      -5.4927e-02,  4.1394e-02],                           │ │
│ │          │   │     [-9.3741e-04, -8.9751e-02,  1.4261e-01,  ...,         │ │
│ │          -3.2899e-01,                                                    │ │
│ │          │   │      -3.1064e-02,  1.2781e-01],                           │ │
│ │          │   │     [ 9.9263e-04, -1.1431e-01,  1.9636e-01,  ...,         │ │
│ │          -6.4508e-01,                                                    │ │
│ │          │   │   │   5.0416e-02,  1.7501e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.6489e-02, -5.0040e-02,  1.0794e-01,  ...,         │ │
│ │          -6.5474e-01,                                                    │ │
│ │          │   │   │   1.9261e-01,  8.3400e-02],                           │ │
│ │          │   │     [ 6.2673e-03, -2.0505e-02,  3.9209e-02,  ...,         │ │
│ │          -3.4147e-01,                                                    │ │
│ │          │   │   │   1.1782e-01,  4.7919e-02],                           │ │
│ │          │   │     [ 1.4163e-02, -3.0627e-02,  1.8890e-02,  ...,         │ │
│ │          -1.4547e-01,                                                    │ │
│ │          │   │   │   1.7282e-03,  2.6207e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 3.5155e-03, -1.7897e-02,  2.4880e-02,  ...,         │ │
│ │          -4.3334e-02,                                                    │ │
│ │          │   │      -5.1756e-03, -9.3145e-03],                           │ │
│ │          │   │     [ 9.4920e-05, -5.5241e-02,  2.5778e-02,  ...,         │ │
│ │          -1.2653e-01,                                                    │ │
│ │          │   │   │   3.9181e-02, -6.1278e-03],                           │ │
│ │          │   │     [ 1.4390e-02, -5.6854e-02,  9.4218e-03,  ...,         │ │
│ │          -2.8153e-01,                                                    │ │
│ │          │   │   │   1.1694e-01, -7.1436e-03],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.9954e-03, -1.0464e-02, -4.1483e-02,  ...,         │ │
│ │          -3.3736e-01,                                                    │ │
│ │          │   │   │   2.0680e-01, -4.8699e-02],                           │ │
│ │          │   │     [ 4.6892e-03,  1.4869e-04, -4.1309e-02,  ...,         │ │
│ │          -1.8820e-01,                                                    │ │
│ │          │   │   │   1.1659e-01, -3.1936e-02],                           │ │
│ │          │   │     [ 8.7192e-03, -7.4809e-03, -6.6958e-03,  ...,         │ │
│ │          -8.1208e-02,                                                    │ │
│ │          │   │   │   3.2353e-02, -3.3910e-03]]],                         │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-5.9959e-03, -1.9090e-02, -4.3520e-02,  ...,         │ │
│ │          2.0887e-02,                                                     │ │
│ │          │   │   │   1.3546e-01, -5.8227e-02],                           │ │
│ │          │   │     [ 1.5565e-03,  3.3861e-02,  1.0249e-01,  ...,         │ │
│ │          -3.1755e-01,                                                    │ │
│ │          │   │      -1.4153e-01,  1.9178e-01],                           │ │
│ │          │   │     [-2.2202e-04, -2.8745e-02, -1.4681e-01,  ...,         │ │
│ │          4.9141e-01,                                                     │ │
│ │          │   │      -2.6786e-01, -1.8531e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 1.2001e-02, -5.6779e-02,  1.8373e-01,  ...,         │ │
│ │          -5.2318e-01,                                                    │ │
│ │          │   │      -1.7220e-01,  1.5940e-01],                           │ │
│ │          │   │     [ 2.6243e-03,  1.2970e-02, -1.3902e-01,  ...,         │ │
│ │          2.3513e-01,                                                     │ │
│ │          │   │      -1.3287e-01, -1.0518e-01],                           │ │
│ │          │   │     [-1.1640e-02, -3.8260e-03,  2.4871e-02,  ...,         │ │
│ │          1.4452e-03,                                                     │ │
│ │          │   │   │   8.0324e-02, -2.1633e-03]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 3.1390e-02,  2.3407e-02, -9.0118e-03,  ...,         │ │
│ │          -1.5045e-02,                                                    │ │
│ │          │   │   │   1.1747e-01, -5.4097e-02],                           │ │
│ │          │   │     [-7.1051e-03,  4.0835e-02,  1.5637e-01,  ...,         │ │
│ │          -3.3902e-01,                                                    │ │
│ │          │   │      -2.3148e-01,  1.3631e-01],                           │ │
│ │          │   │     [-4.1105e-02, -6.9036e-02, -1.8226e-01,  ...,         │ │
│ │          7.3000e-01,                                                     │ │
│ │          │   │      -2.1829e-01, -2.5407e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 4.7438e-02, -3.9516e-02,  1.9419e-01,  ...,         │ │
│ │          -6.8339e-01,                                                    │ │
│ │          │   │      -2.0557e-01,  2.2746e-01],                           │ │
│ │          │   │     [ 2.4876e-02,  4.0771e-02, -1.2085e-01,  ...,         │ │
│ │          2.1713e-01,                                                     │ │
│ │          │   │      -1.8653e-01, -9.7477e-02],                           │ │
│ │          │   │     [-4.4771e-03,  2.9979e-02,  5.8641e-02,  ...,         │ │
│ │          2.7419e-03,                                                     │ │
│ │          │   │   │   6.6834e-02, -1.2358e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.9978e-02, -6.0826e-03, -3.6583e-02,  ...,         │ │
│ │          2.5929e-03,                                                     │ │
│ │          │   │   │   9.7848e-02, -6.6162e-02],                           │ │
│ │          │   │     [ 1.7332e-02,  3.7463e-02,  1.0402e-01,  ...,         │ │
│ │          -3.0002e-01,                                                    │ │
│ │          │   │      -1.0622e-01,  1.8765e-01],                           │ │
│ │          │   │     [-5.9565e-03, -1.0599e-02, -1.1531e-01,  ...,         │ │
│ │          4.0172e-01,                                                     │ │
│ │          │   │      -2.8638e-01, -1.6430e-01],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 1.0877e-02, -8.4373e-02,  1.2378e-01,  ...,         │ │
│ │          -3.6782e-01,                                                    │ │
│ │          │   │      -1.1202e-01,  1.5838e-01],                           │ │
│ │          │   │     [ 1.1257e-02,  1.4023e-02, -1.6207e-01,  ...,         │ │
│ │          2.2055e-01,                                                     │ │
│ │          │   │      -8.4523e-02, -1.3719e-02],                           │ │
│ │          │   │     [-6.8506e-03,  9.2005e-03,  3.7370e-02,  ...,         │ │
│ │          -5.3645e-02,                                                    │ │
│ │          │   │   │   3.9750e-02, -1.7585e-03]]],                         │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 4.8939e-04,  2.2258e-02, -5.8092e-03,  ...,         │ │
│ │          2.4769e-02,                                                     │ │
│ │          │   │      -1.5008e-03, -2.7763e-03],                           │ │
│ │          │   │     [-1.0835e-02,  3.3958e-02, -5.4082e-02,  ...,         │ │
│ │          1.6750e-01,                                                     │ │
│ │          │   │      -6.2745e-03, -1.4581e-02],                           │ │
│ │          │   │     [-2.7653e-02,  1.0989e-01,  1.3244e-01,  ...,         │ │
│ │          -5.6184e-02,                                                    │ │
│ │          │   │   │   2.2555e-01, -2.4275e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 7.6819e-02, -2.3372e-01, -1.6708e-02,  ...,         │ │
│ │          -1.8322e-01,                                                    │ │
│ │          │   │      -2.6738e-01,  8.6360e-02],                           │ │
│ │          │   │     [ 2.6088e-02,  4.2557e-02, -2.6181e-01,  ...,         │ │
│ │          2.3195e-01,                                                     │ │
│ │          │   │      -1.1565e-01, -5.4056e-02],                           │ │
│ │          │   │     [-2.3699e-02,  5.2339e-02,  1.8254e-03,  ...,         │ │
│ │          6.9750e-02,                                                     │ │
│ │          │   │   │   4.1804e-02, -2.1501e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.6988e-02,  1.4807e-02, -1.6045e-02,  ...,         │ │
│ │          5.1616e-03,                                                     │ │
│ │          │   │   │   2.7796e-02,  1.5654e-02],                           │ │
│ │          │   │     [-1.3283e-02,  3.6808e-02, -7.2129e-02,  ...,         │ │
│ │          1.2933e-01,                                                     │ │
│ │          │   │   │   3.4923e-02,  2.5726e-02],                           │ │
│ │          │   │     [-2.1088e-02,  1.4829e-01,  1.8743e-01,  ...,         │ │
│ │          -2.0113e-01,                                                    │ │
│ │          │   │   │   2.3198e-01, -6.3110e-03],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 3.5297e-02, -3.3804e-01,  7.0711e-02,  ...,         │ │
│ │          -1.9556e-01,                                                    │ │
│ │          │   │      -3.7555e-01,  4.8889e-02],                           │ │
│ │          │   │     [ 2.1918e-02, -4.1238e-02, -3.4111e-01,  ...,         │ │
│ │          3.1244e-01,                                                     │ │
│ │          │   │      -1.2826e-01, -7.7778e-02],                           │ │
│ │          │   │     [-2.8042e-03,  1.4565e-02, -9.2682e-02,  ...,         │ │
│ │          9.3647e-02,                                                     │ │
│ │          │   │   │   6.9271e-02, -1.1063e-03]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.7681e-02,  2.1024e-02,  1.4474e-02,  ...,         │ │
│ │          -3.0816e-02,                                                    │ │
│ │          │   │      -7.3333e-03,  2.0389e-02],                           │ │
│ │          │   │     [-2.6116e-03,  1.6374e-02, -2.2083e-02,  ...,         │ │
│ │          1.1664e-01,                                                     │ │
│ │          │   │      -3.0558e-02,  4.1856e-03],                           │ │
│ │          │   │     [-4.1508e-02,  6.1534e-02,  1.0705e-01,  ...,         │ │
│ │          -1.5170e-02,                                                    │ │
│ │          │   │   │   1.4374e-01, -7.9883e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 6.3146e-02, -2.2285e-01, -8.6916e-02,  ...,         │ │
│ │          -1.0022e-01,                                                    │ │
│ │          │   │      -1.7261e-01,  6.4554e-02],                           │ │
│ │          │   │     [ 1.5614e-02,  5.3186e-02, -2.6123e-01,  ...,         │ │
│ │          1.9599e-01,                                                     │ │
│ │          │   │      -6.2334e-02, -3.9972e-02],                           │ │
│ │          │   │     [-5.7446e-03,  2.1188e-02, -4.5816e-02,  ...,         │ │
│ │          3.4701e-02,                                                     │ │
│ │          │   │   │   6.7876e-02, -2.1575e-02]]],                         │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-5.7718e-02, -5.5630e-02, -7.0258e-02,  ...,         │ │
│ │          -5.5808e-02,                                                    │ │
│ │          │   │      -5.3512e-02, -3.0776e-02],                           │ │
│ │          │   │     [-7.5525e-02, -1.7261e-02, -1.2381e-02,  ...,         │ │
│ │          5.1765e-03,                                                     │ │
│ │          │   │      -7.3640e-03, -5.7358e-03],                           │ │
│ │          │   │     [-2.7587e-02,  6.2952e-02,  6.7964e-02,  ...,         │ │
│ │          5.1080e-02,                                                     │ │
│ │          │   │   │   4.7412e-02,  4.5770e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 5.9783e-02,  1.1099e-01,  5.5274e-02,  ...,         │ │
│ │          2.0251e-02,                                                     │ │
│ │          │   │   │   2.3195e-02,  8.5114e-02],                           │ │
│ │          │   │     [ 8.3326e-03,  1.5435e-02, -4.1155e-02,  ...,         │ │
│ │          -6.5673e-02,                                                    │ │
│ │          │   │      -3.9964e-02,  1.6453e-02],                           │ │
│ │          │   │     [ 3.3918e-03, -3.6545e-04, -5.5715e-02,  ...,         │ │
│ │          -5.9387e-02,                                                    │ │
│ │          │   │      -2.3372e-02,  1.4784e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-5.8605e-02, -5.4044e-02, -6.3297e-02,  ...,         │ │
│ │          -3.7265e-02,                                                    │ │
│ │          │   │      -3.3020e-02, -2.1764e-02],                           │ │
│ │          │   │     [-5.9215e-02, -2.0468e-02,  5.6069e-04,  ...,         │ │
│ │          5.0389e-02,                                                     │ │
│ │          │   │   │   2.3611e-02,  9.3259e-03],                           │ │
│ │          │   │     [ 3.5097e-03,  6.8784e-02,  9.0114e-02,  ...,         │ │
│ │          9.6728e-02,                                                     │ │
│ │          │   │   │   7.6840e-02,  6.2783e-02],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 6.6074e-02,  1.1351e-01,  7.9951e-02,  ...,         │ │
│ │          5.3250e-02,                                                     │ │
│ │          │   │   │   4.3104e-02,  1.0202e-01],                           │ │
│ │          │   │     [ 2.4708e-02,  3.6277e-02, -1.0369e-02,  ...,         │ │
│ │          -4.0215e-02,                                                    │ │
│ │          │   │      -3.2247e-02,  2.6695e-02],                           │ │
│ │          │   │     [-6.0148e-03, -7.5935e-03, -5.3421e-02,  ...,         │ │
│ │          -5.1236e-02,                                                    │ │
│ │          │   │      -2.4685e-02,  1.5397e-02]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-2.0102e-02, -1.3979e-02, -3.6837e-02,  ...,         │ │
│ │          -1.3170e-02,                                                    │ │
│ │          │   │      -6.5659e-03,  1.8262e-02],                           │ │
│ │          │   │     [-5.3534e-02, -1.4746e-02, -2.5718e-02,  ...,         │ │
│ │          4.5026e-03,                                                     │ │
│ │          │   │      -1.6048e-02, -1.5727e-02],                           │ │
│ │          │   │     [-2.6570e-02,  2.9042e-02,  1.1798e-02,  ...,         │ │
│ │          1.8101e-02,                                                     │ │
│ │          │   │   │   5.3400e-03,  2.6909e-03],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 1.5337e-02,  5.7082e-02,  9.7305e-03,  ...,         │ │
│ │          1.1100e-02,                                                     │ │
│ │          │   │   │   1.3323e-03,  5.8712e-02],                           │ │
│ │          │   │     [ 4.0777e-03,  2.8672e-02, -1.6952e-02,  ...,         │ │
│ │          -2.7724e-02,                                                    │ │
│ │          │   │      -2.2432e-02,  3.0346e-02],                           │ │
│ │          │   │     [ 2.3939e-03,  2.2689e-03, -2.1608e-02,  ...,         │ │
│ │          -4.9537e-03,                                                    │ │
│ │          │   │   │   1.0053e-02,  4.4409e-02]]],                         │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 3.8198e-09,  5.2821e-09,  8.4708e-09,  ...,         │ │
│ │          9.3896e-09,                                                     │ │
│ │          │   │   │   1.0989e-08,  8.6680e-09],                           │ │
│ │          │   │     [ 1.0561e-08,  1.0032e-08,  1.2596e-08,  ...,         │ │
│ │          9.4018e-09,                                                     │ │
│ │          │   │   │   1.0029e-08,  1.3073e-08],                           │ │
│ │          │   │     [ 1.0009e-08,  6.9546e-09,  7.0832e-09,  ...,         │ │
│ │          1.1455e-08,                                                     │ │
│ │          │   │   │   8.3313e-09,  1.4117e-08],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 8.9857e-09,  6.0239e-09,  6.9334e-09,  ...,         │ │
│ │          9.9647e-09,                                                     │ │
│ │          │   │   │   8.1298e-09,  1.3150e-08],                           │ │
│ │          │   │     [ 9.3205e-09,  8.4864e-09,  1.0279e-08,  ...,         │ │
│ │          1.0536e-08,                                                     │ │
│ │          │   │   │   1.3432e-08,  1.2343e-08],                           │ │
│ │          │   │     [ 1.2704e-08,  1.2244e-08,  1.0365e-08,  ...,         │ │
│ │          1.3496e-08,                                                     │ │
│ │          │   │   │   1.1680e-08,  1.4884e-08]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4684e-09, -6.0630e-10,  2.0655e-09,  ...,         │ │
│ │          3.2167e-09,                                                     │ │
│ │          │   │   │   5.7001e-09,  4.5557e-09],                           │ │
│ │          │   │     [ 5.5310e-09,  5.3149e-09,  7.1034e-09,  ...,         │ │
│ │          3.6033e-09,                                                     │ │
│ │          │   │   │   7.9869e-09,  8.5333e-09],                           │ │
│ │          │   │     [ 6.1580e-09,  3.8952e-09,  1.4952e-09,  ...,         │ │
│ │          2.3825e-09,                                                     │ │
│ │          │   │   │   5.0903e-09,  6.6121e-09],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 4.4388e-09,  4.0306e-09,  4.0409e-09,  ...,         │ │
│ │          5.2286e-09,                                                     │ │
│ │          │   │   │   1.4921e-09,  2.7369e-09],                           │ │
│ │          │   │     [ 7.9369e-09,  4.0945e-09,  2.5078e-09,  ...,         │ │
│ │          6.5217e-09,                                                     │ │
│ │          │   │   │   4.4083e-09,  5.1524e-09],                           │ │
│ │          │   │     [ 7.3701e-09,  4.7664e-09,  4.5817e-09,  ...,         │ │
│ │          3.6753e-09,                                                     │ │
│ │          │   │   │   5.5694e-09,  5.8749e-09]],                          │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-8.0702e-09, -7.5842e-09, -5.0519e-09,  ...,         │ │
│ │          -7.1475e-09,                                                    │ │
│ │          │   │      -6.9767e-09, -2.3015e-09],                           │ │
│ │          │   │     [ 8.2218e-10,  8.6029e-10, -7.5594e-10,  ...,         │ │
│ │          -2.4140e-09,                                                    │ │
│ │          │   │   │   2.3130e-09,  4.2510e-09],                           │ │
│ │          │   │     [ 2.6394e-10, -1.6171e-09, -1.8819e-10,  ...,         │ │
│ │          -1.5929e-09,                                                    │ │
│ │          │   │   │   2.5107e-10,  1.5924e-09],                           │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 6.8491e-09, -1.8575e-09, -1.7964e-09,  ...,         │ │
│ │          -5.0751e-10,                                                    │ │
│ │          │   │   │   9.6112e-10,  3.7407e-09],                           │ │
│ │          │   │     [ 8.7351e-10,  2.8883e-10, -7.9156e-10,  ...,         │ │
│ │          -3.7688e-10,                                                    │ │
│ │          │   │      -2.9927e-09, -5.4954e-10],                           │ │
│ │          │   │     [ 4.8446e-09,  1.9827e-09,  2.2090e-09,  ...,         │ │
│ │          2.5378e-09,                                                     │ │
│ │          │   │   │   2.0013e-09,  1.1245e-09]]]], requires_grad=True)    │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
╰──────────────────────────────────────────────────────────────────────────────╯
RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type
(torch.cuda.HalfTensor) should be the same
