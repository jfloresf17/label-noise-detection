Traceback (most recent call last):
  File "/home/tidop/projects/Noisy-Student/train_teacher.py", line 274, in <module>
    typer.run(train_teacher)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 1080, in run
    app()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 338, in __call__
    raise e
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 321, in __call__
    return get_command(self)(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 665, in main
    return _main(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 197, in _main
    rv = self.invoke(ctx)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 703, in wrapper
    return callback(**use_params)
  File "/home/tidop/projects/Noisy-Student/train_teacher.py", line 132, in train_teacher
    loss.backward()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/autograd/__init__.py", line 340, in backward
    grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batched=False)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/autograd/__init__.py", line 198, in _make_grads
    raise RuntimeError(
RuntimeError: grad can be implicitly created only for scalar outputs
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/tidop/projects/Noisy-Student/train_teacher.py:132 in train_teacher     │
│                                                                              │
│   129 │   │   │   loss = symmetric_cross_entropy(masks, outputs, alpha, beta │
│   130 │   │   │                                                              │
│   131 │   │   │   # Backward pass and optimization                           │
│ ❱ 132 │   │   │   loss.backward()                                            │
│   133 │   │   │   optimizer.step()                                           │
│   134 │   │   │                                                              │
│   135 │   │   │   running_loss += loss.item()                                │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                  alpha = 0.01                                            │ │
│ │             batch_size = 16                                              │ │
│ │                   beta = 1                                               │ │
│ │ combined_train_dataset = <torch.utils.data.dataset.ConcatDataset object  │ │
│ │                          at 0x7b5b2ff39900>                              │ │
│ │   combined_val_dataset = <torch.utils.data.dataset.ConcatDataset object  │ │
│ │                          at 0x7b5b2ff3abf0>                              │ │
│ │                 config = {                                               │ │
│ │                          │   'device': 'cuda',                           │ │
│ │                          │   'learning_rate': '1e-4',                    │ │
│ │                          │   'data': {                                   │ │
│ │                          │   │   'batch_size': 16,                       │ │
│ │                          │   │   'num_workers': 16,                      │ │
│ │                          │   │   'whu_path':                             │ │
│ │                          '/media/tidop/Datos_4TB1/databases/whu_adjuste… │ │
│ │                          │   │   'alabama_path':                         │ │
│ │                          '/media/tidop/Datos_4TB1/databases/alabama',    │ │
│ │                          │   │   'datacentric_image_path':               │ │
│ │                          '/media/tidop/Datos_4TB1/databases/kaggle/data… │ │
│ │                          │   │   'label_noisy_path':                     │ │
│ │                          '/media/tidop/Datos_4TB1/databases/kaggle/data… │ │
│ │                          │   },                                          │ │
│ │                          │   'Normalize': {                              │ │
│ │                          │   │   'apply': True,                          │ │
│ │                          │   │   'WHU': {                                │ │
│ │                          │   │   │   'mean': [                           │ │
│ │                          │   │   │   │   72.62323902,                    │ │
│ │                          │   │   │   │   99.33869521,                    │ │
│ │                          │   │   │   │   82.94464024                     │ │
│ │                          │   │   │   ],                                  │ │
│ │                          │   │   │   'std': [                            │ │
│ │                          │   │   │   │   43.81751311,                    │ │
│ │                          │   │   │   │   42.46326449,                    │ │
│ │                          │   │   │   │   50.62061044                     │ │
│ │                          │   │   │   ]                                   │ │
│ │                          │   │   },                                      │ │
│ │                          │   │   'Alabama': {                            │ │
│ │                          │   │   │   'mean': [                           │ │
│ │                          │   │   │   │   83.00301721,                    │ │
│ │                          │   │   │   │   91.24630964,                    │ │
│ │                          │   │   │   │   87.26586959                     │ │
│ │                          │   │   │   ],                                  │ │
│ │                          │   │   │   'std': [                            │ │
│ │                          │   │   │   │   33.38048494,                    │ │
│ │                          │   │   │   │   36.60072106,                    │ │
│ │                          │   │   │   │   41.38057245                     │ │
│ │                          │   │   │   ]                                   │ │
│ │                          │   │   },                                      │ │
│ │                          │   │   'WHU + Alabama': {                      │ │
│ │                          │   │   │   'mean': [                           │ │
│ │                          │   │   │   │   94.21397367,                    │ │
│ │                          │   │   │   │   102.78712076,                   │ │
│ │                          │   │   │   │   99.94002467                     │ │
│ │                          │   │   │   ],                                  │ │
│ │                          │   │   │   'std': [                            │ │
│ │                          │   │   │   │   40.95295341,                    │ │
│ │                          │   │   │   │   41.52023864,                    │ │
│ │                          │   │   │   │   45.4620858                      │ │
│ │                          │   │   │   ]                                   │ │
│ │                          │   │   },                                      │ │
│ │                          │   │   'DataCentric': {                        │ │
│ │                          │   │   │   'mean': [                           │ │
│ │                          │   │   │   │   72.74413315,                    │ │
│ │                          │   │   │   │   99.76137101,                    │ │
│ │                          │   │   │   │   82.70024275                     │ │
│ │                          │   │   │   ],                                  │ │
│ │                          │   │   │   'std': [                            │ │
│ │                          │   │   │   │   36.28290664,                    │ │
│ │                          │   │   │   │   34.82507359,                    │ │
│ │                          │   │   │   │   41.48902725                     │ │
│ │                          │   │   │   ]                                   │ │
│ │                          │   │   }                                       │ │
│ │                          │   },                                          │ │
│ │                          │   'loss': {'alpha': 0.01, 'beta': 1},         │ │
│ │                          │   'trainer': {                                │ │
│ │                          │   │   'wandb_project': 'Unet-NRN-RSSEG',      │ │
│ │                          │   │   'experiment_name': 'Unet-WHU-Kaggle',   │ │
│ │                          │   │   'max_epochs': 50                        │ │
│ │                          │   }                                           │ │
│ │                          }                                               │ │
│ │            config_path = 'config.yaml'                                   │ │
│ │            data_module = <dataloader.DataCentricDataModule object at     │ │
│ │                          0x7b5b2ff87a30>                                 │ │
│ │                 device = 'cuda'                                          │ │
│ │                  epoch = 0                                               │ │
│ │                 epochs = 50                                              │ │
│ │      epochs_no_improve = 0                                               │ │
│ │                 images = tensor([[[[-1.6057e+00, -1.6476e+00,            │ │
│ │                          -1.6574e+00,  ..., -4.0016e-01,                 │ │
│ │                          │   │   │   8.6437e-02, -1.6140e-01],           │ │
│ │                          │   │     [-1.3285e+00, -1.6545e+00,            │ │
│ │                          -1.5750e+00,  ..., -1.2156e-01,                 │ │
│ │                          │   │      -1.7968e-01,  1.3901e-01],           │ │
│ │                          │   │     [-1.5669e+00, -1.4488e+00,            │ │
│ │                          -6.3042e-01,  ..., -3.5192e-01,                 │ │
│ │                          │   │      -2.7311e-01, -1.3648e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 1.3975e+00,  1.5106e+00,            │ │
│ │                          1.5059e+00,  ..., -3.0128e-01,                  │ │
│ │                          │   │      -4.2110e-01, -2.2981e-01],           │ │
│ │                          │   │     [ 1.9065e+00,  1.6992e+00,            │ │
│ │                          1.5227e+00,  ..., -1.2726e-01,                  │ │
│ │                          │   │      -1.7041e-01, -8.3912e-02],           │ │
│ │                          │   │     [ 1.7547e+00,  1.6726e+00,            │ │
│ │                          1.8519e+00,  ..., -2.6200e-01,                  │ │
│ │                          │   │      -5.4569e-02, -1.7537e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.9443e+00, -2.2536e+00,            │ │
│ │                          -2.3394e+00,  ..., -4.4449e-01,                 │ │
│ │                          │   │   │   2.2302e-02, -1.4976e-01],           │ │
│ │                          │   │     [-1.5320e+00, -2.3026e+00,            │ │
│ │                          -2.1753e+00,  ..., -1.7945e-01,                 │ │
│ │                          │   │      -2.3611e-01,  7.0243e-02],           │ │
│ │                          │   │     [-2.2006e+00, -2.0318e+00,            │ │
│ │                          -6.0187e-01,  ..., -4.5321e-01,                 │ │
│ │                          │   │      -3.4503e-01, -2.1151e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 1.2662e+00,  1.3896e+00,            │ │
│ │                          1.3815e+00,  ..., -3.4724e-01,                  │ │
│ │                          │   │      -4.6720e-01, -3.1496e-01],           │ │
│ │                          │   │     [ 1.7398e+00,  1.5684e+00,            │ │
│ │                          1.4116e+00,  ..., -1.6473e-01,                  │ │
│ │                          │   │      -2.3538e-01, -2.1151e-01],           │ │
│ │                          │   │     [ 1.6660e+00,  1.5253e+00,            │ │
│ │                          1.6927e+00,  ..., -2.4431e-01,                  │ │
│ │                          │   │      -1.6694e-01, -2.8240e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.6265e+00, -1.6386e+00,            │ │
│ │                          -1.6386e+00,  ..., -3.8765e-01,                 │ │
│ │                          │   │   │   6.9883e-02, -3.8819e-02],           │ │
│ │                          │   │     [-1.4227e+00, -1.6386e+00,            │ │
│ │                          -1.5506e+00,  ..., -1.3410e-01,                 │ │
│ │                          │   │      -1.8596e-01,  1.1751e-01],           │ │
│ │                          │   │     [-1.5772e+00, -1.4302e+00,            │ │
│ │                          -6.2458e-01,  ..., -3.8135e-01,                 │ │
│ │                          │   │      -2.9152e-01, -1.7141e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 1.1970e+00,  1.2642e+00,            │ │
│ │                          1.2657e+00,  ..., -3.0202e-01,                  │ │
│ │                          │   │      -4.1036e-01, -2.4443e-01],           │ │
│ │                          │   │     [ 1.6630e+00,  1.4685e+00,            │ │
│ │                          1.2876e+00,  ..., -1.2608e-01,                  │ │
│ │                          │   │      -2.0355e-01, -1.3366e-01],           │ │
│ │                          │   │     [ 1.4138e+00,  1.4520e+00,            │ │
│ │                          1.6220e+00,  ..., -2.1374e-01,                  │ │
│ │                          │   │      -1.2555e-01, -2.3274e-01]]],         │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[ 2.9561e+00,  2.9561e+00,            │ │
│ │                          3.0388e+00,  ..., -1.1505e+00,                  │ │
│ │                          │   │      -9.3003e-01, -8.7491e-01],           │ │
│ │                          │   │     [ 2.9561e+00,  3.0112e+00,            │ │
│ │                          3.0388e+00,  ..., -1.5915e+00,                  │ │
│ │                          │   │      -5.7173e-01, -3.5124e-01],           │ │
│ │                          │   │     [ 2.9837e+00,  3.0388e+00,            │ │
│ │                          3.0663e+00,  ..., -1.7293e+00,                  │ │
│ │                          │   │      -6.2686e-01, -2.4100e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-1.3075e-01,  5.3071e-01,            │ │
│ │                          -1.0319e-01,  ..., -4.3393e-01,                 │ │
│ │                          │   │      -3.5124e-01, -4.0637e-01],           │ │
│ │                          │   │     [-6.8198e-01, -9.3003e-01,            │ │
│ │                          6.2174e-02,  ..., -3.2368e-01,                  │ │
│ │                          │   │      -1.8588e-01, -2.4100e-01],           │ │
│ │                          │   │     [-1.0319e-01, -3.7880e-01,            │ │
│ │                          -9.8515e-01,  ..., -1.3075e-01,                 │ │
│ │                          │   │      -1.8588e-01, -1.8588e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[ 2.4763e+00,  2.4763e+00,            │ │
│ │                          2.5625e+00,  ..., -7.1102e-01,                  │ │
│ │                          │   │      -7.9717e-01, -6.8231e-01],           │ │
│ │                          │   │     [ 2.4763e+00,  2.5338e+00,            │ │
│ │                          2.5625e+00,  ..., -1.1992e+00,                  │ │
│ │                          │   │      -3.6644e-01, -1.3672e-01],           │ │
│ │                          │   │     [ 2.5051e+00,  2.5625e+00,            │ │
│ │                          2.5912e+00,  ..., -1.4002e+00,                  │ │
│ │                          │   │      -4.2387e-01, -2.1863e-02],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-9.4074e-01, -1.9415e-01,            │ │
│ │                          -8.5460e-01,  ..., -3.3773e-01,                 │ │
│ │                          │   │      -2.5158e-01, -3.0901e-01],           │ │
│ │                          │   │     [-1.5150e+00, -1.7735e+00,            │ │
│ │                          -6.8231e-01,  ..., -2.5158e-01,                 │ │
│ │                          │   │      -1.0801e-01, -1.6544e-01],           │ │
│ │                          │   │     [-9.1203e-01, -1.1992e+00,            │ │
│ │                          -1.8309e+00,  ..., -7.9293e-02,                 │ │
│ │                          │   │      -1.9415e-01, -1.9415e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[ 2.4657e+00,  2.4657e+00,            │ │
│ │                          2.5380e+00,  ..., -1.0533e+00,                  │ │
│ │                          │   │      -9.0868e-01, -8.1227e-01],           │ │
│ │                          │   │     [ 2.4657e+00,  2.5139e+00,            │ │
│ │                          2.5380e+00,  ..., -1.3907e+00,                  │ │
│ │                          │   │      -5.2304e-01, -3.5432e-01],           │ │
│ │                          │   │     [ 2.4898e+00,  2.5380e+00,            │ │
│ │                          2.5621e+00,  ..., -1.4389e+00,                  │ │
│ │                          │   │      -5.7124e-01, -2.3380e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-4.7483e-01,  1.5184e-01,            │ │
│ │                          -4.0252e-01,  ..., -4.0981e-02,                 │ │
│ │                          │   │      -1.6149e-01, -2.0970e-01],           │ │
│ │                          │   │     [-9.5689e-01, -1.1738e+00,            │ │
│ │                          -2.5791e-01,  ...,  7.9533e-02,                 │ │
│ │                          │   │   │   7.2250e-03, -4.0981e-02],           │ │
│ │                          │   │     [-4.5073e-01, -6.9175e-01,            │ │
│ │                          -1.2220e+00,  ...,  2.7236e-01,                 │ │
│ │                          │   │   │   7.2250e-03,  7.2250e-03]]],         │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-5.4611e-01, -5.0775e-01,            │ │
│ │                          -7.4412e-01,  ..., -1.6583e-01,                 │ │
│ │                          │   │      -2.1229e-01, -3.4165e-01],           │ │
│ │                          │   │     [-6.3979e-01, -5.2130e-01,            │ │
│ │                          -6.4040e-01,  ..., -2.9558e-01,                 │ │
│ │                          │   │      -1.8147e-01, -1.9354e-01],           │ │
│ │                          │   │     [-3.8752e-01, -3.3765e-01,            │ │
│ │                          -5.0810e-01,  ..., -3.1127e-01,                 │ │
│ │                          │   │      -2.3460e-01, -2.5711e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 4.2016e-02,  4.5969e-01,            │ │
│ │                          6.6829e-01,  ...,  2.0216e+00,                  │ │
│ │                          │   │   │   1.9338e+00,  1.9428e+00],           │ │
│ │                          │   │     [-2.2533e-01, -7.5557e-02,            │ │
│ │                          2.7569e-01,  ...,  2.0123e+00,                  │ │
│ │                          │   │   │   1.9702e+00,  2.0528e+00],           │ │
│ │                          │   │     [-5.1537e-01, -3.2802e-01,            │ │
│ │                          1.8302e-01,  ...,  2.0634e+00,                  │ │
│ │                          │   │   │   2.1078e+00,  2.1222e+00]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-3.7468e-01, -3.3599e-01,            │ │
│ │                          -5.3953e-01,  ...,  1.0346e-01,                 │ │
│ │                          │   │   │   5.1739e-02, -8.6796e-02],           │ │
│ │                          │   │     [-4.8906e-01, -3.6196e-01,            │ │
│ │                          -4.4107e-01,  ..., -5.8019e-02,                 │ │
│ │                          │   │   │   7.0032e-02,  7.8653e-02],           │ │
│ │                          │   │     [-1.3918e-01, -1.1689e-01,            │ │
│ │                          -3.0676e-01,  ..., -4.0357e-02,                 │ │
│ │                          │   │   │   4.0595e-02,  3.3236e-02],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 5.8468e-02,  5.9843e-01,            │ │
│ │                          8.4754e-01,  ...,  1.9312e+00,                  │ │
│ │                          │   │   │   1.8797e+00,  1.8743e+00],           │ │
│ │                          │   │     [-3.1286e-01, -9.5920e-02,            │ │
│ │                          2.5990e-01,  ...,  1.8933e+00,                  │ │
│ │                          │   │   │   1.8650e+00,  1.9155e+00],           │ │
│ │                          │   │     [-5.7846e-01, -4.6383e-01,            │ │
│ │                          -3.4049e-02,  ...,  1.7999e+00,                 │ │
│ │                          │   │   │   1.8647e+00,  1.9245e+00]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-2.5693e-01, -2.7971e-01,            │ │
│ │                          -5.9790e-01,  ...,  1.1398e-01,                 │ │
│ │                          │   │   │   7.3763e-02, -3.7610e-02],           │ │
│ │                          │   │     [-3.7037e-01, -2.6127e-01,            │ │
│ │                          -3.8629e-01,  ..., -2.2983e-02,                 │ │
│ │                          │   │   │   9.9250e-02,  1.0234e-01],           │ │
│ │                          │   │     [-4.9034e-03,  5.8197e-02,            │ │
│ │                          -1.9707e-01,  ..., -3.2243e-02,                 │ │
│ │                          │   │   │   5.4493e-02,  3.6370e-02],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 1.3620e-01,  7.4622e-01,            │ │
│ │                          1.0351e+00,  ...,  1.8738e+00,                  │ │
│ │                          │   │   │   1.8695e+00,  1.8302e+00],           │ │
│ │                          │   │     [-2.3808e-01,  2.2700e-02,            │ │
│ │                          3.6440e-01,  ...,  1.8130e+00,                  │ │
│ │                          │   │   │   1.8377e+00,  1.8309e+00],           │ │
│ │                          │   │     [-4.7020e-01, -3.6472e-01,            │ │
│ │                          2.0496e-02,  ...,  1.6104e+00,                  │ │
│ │                          │   │   │   1.7226e+00,  1.8254e+00]]],         │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   ...,                                    │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-1.5200e+00, -1.4972e+00,            │ │
│ │                          -1.3758e+00,  ...,  1.0254e+00,                 │ │
│ │                          │   │   │   6.8592e-01, -6.3042e-01],           │ │
│ │                          │   │     [-1.5070e+00, -1.5048e+00,            │ │
│ │                          -1.1657e+00,  ...,  1.0502e+00,                 │ │
│ │                          │   │   │   9.1648e-01, -6.4020e-01],           │ │
│ │                          │   │     [-1.5025e+00, -1.4770e+00,            │ │
│ │                          -6.5466e-01,  ...,  1.0285e+00,                 │ │
│ │                          │   │   │   6.8755e-01, -1.0253e+00],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-4.6903e-01, -3.3836e-02,            │ │
│ │                          -3.4657e-01,  ..., -4.0968e-02,                 │ │
│ │                          │   │   │   8.5984e-03, -1.4260e-01],           │ │
│ │                          │   │     [-6.4468e-01, -7.0494e-01,            │ │
│ │                          -5.8370e-01,  ...,  7.4925e-02,                 │ │
│ │                          │   │   │   9.0258e-02, -1.5890e-01],           │ │
│ │                          │   │     [-5.9874e-01, -4.5151e-01,            │ │
│ │                          -4.6577e-01,  ...,  1.8547e-01,                 │ │
│ │                          │   │      -7.4946e-02, -1.6233e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.6430e+00, -1.6190e+00,            │ │
│ │                          -1.4163e+00,  ...,  9.5420e-01,                 │ │
│ │                          │   │   │   6.8212e-01, -7.1399e-01],           │ │
│ │                          │   │     [-1.6556e+00, -1.6399e+00,            │ │
│ │                          -1.0773e+00,  ...,  9.6971e-01,                 │ │
│ │                          │   │   │   8.2620e-01, -7.8974e-01],           │ │
│ │                          │   │     [-1.6766e+00, -1.6388e+00,            │ │
│ │                          -6.6222e-01,  ...,  9.2555e-01,                 │ │
│ │                          │   │   │   5.7672e-01, -1.2212e+00],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-2.3632e-01,  2.0839e-01,            │ │
│ │                          -5.4340e-02,  ...,  1.1897e-01,                 │ │
│ │                          │   │   │   6.8561e-02, -2.0605e-01],           │ │
│ │                          │   │     [-3.3978e-01, -3.4540e-01,            │ │
│ │                          -1.9969e-01,  ...,  2.3304e-01,                 │ │
│ │                          │   │   │   1.3443e-01, -2.3170e-01],           │ │
│ │                          │   │     [-3.6074e-01, -1.2152e-01,            │ │
│ │                          -1.1816e-01,  ...,  3.7681e-01,                 │ │
│ │                          │   │      -2.3536e-02, -1.5937e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.5745e+00, -1.5599e+00,            │ │
│ │                          -1.4410e+00,  ...,  9.4474e-01,                 │ │
│ │                          │   │   │   6.9533e-01, -6.6855e-01],           │ │
│ │                          │   │     [-1.5839e+00, -1.5781e+00,            │ │
│ │                          -1.2107e+00,  ...,  9.6383e-01,                 │ │
│ │                          │   │   │   8.7401e-01, -7.1114e-01],           │ │
│ │                          │   │     [-1.5952e+00, -1.5580e+00,            │ │
│ │                          -7.2397e-01,  ...,  9.2000e-01,                 │ │
│ │                          │   │   │   6.1102e-01, -1.1327e+00],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-4.9595e-01,  6.2210e-02,            │ │
│ │                          -2.1714e-01,  ...,  2.2241e-01,                 │ │
│ │                          │   │   │   2.3352e-01, -1.5839e-02],           │ │
│ │                          │   │     [-5.7956e-01, -5.5605e-01,            │ │
│ │                          -4.1160e-01,  ...,  4.2057e-01,                 │ │
│ │                          │   │   │   3.7088e-01, -4.9352e-02],           │ │
│ │                          │   │     [-5.6091e-01, -3.9153e-01,            │ │
│ │                          -3.6578e-01,  ...,  5.8069e-01,                 │ │
│ │                          │   │   │   2.1452e-01,  3.4556e-02]]],         │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[ 1.2411e-01, -3.0194e-01,            │ │
│ │                          -3.7041e-01,  ..., -5.7458e-01,                 │ │
│ │                          │   │      -4.3276e-01, -6.6954e-01],           │ │
│ │                          │   │     [ 3.0605e-02,  1.1451e-01,            │ │
│ │                          -2.7417e-02,  ..., -5.8584e-01,                 │ │
│ │                          │   │      -5.1666e-01, -3.8345e-01],           │ │
│ │                          │   │     [ 3.7905e-01,  2.2434e-01,            │ │
│ │                          4.2118e-02,  ..., -5.2736e-01,                  │ │
│ │                          │   │      -3.7902e-01, -3.7448e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 1.0609e+00,  1.6671e+00,            │ │
│ │                          2.3229e+00,  ..., -6.7300e-04,                  │ │
│ │                          │   │      -2.3353e-01, -2.3592e-01],           │ │
│ │                          │   │     [ 5.1965e-01, -6.2364e-01,            │ │
│ │                          2.5002e-02,  ...,  4.4186e-01,                  │ │
│ │                          │   │      -1.5116e-01, -3.5655e-01],           │ │
│ │                          │   │     [-2.6946e-01, -1.2747e+00,            │ │
│ │                          -8.5008e-01,  ...,  3.5419e-01,                 │ │
│ │                          │   │      -7.0463e-02, -6.5231e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[ 3.6594e-01, -6.7692e-02,            │ │
│ │                          -3.3347e-01,  ..., -4.6594e-01,                 │ │
│ │                          │   │      -2.9772e-01, -6.1546e-01],           │ │
│ │                          │   │     [ 2.6369e-01,  3.7802e-01,            │ │
│ │                          1.9440e-01,  ..., -4.7456e-01,                  │ │
│ │                          │   │      -4.1347e-01, -2.3296e-01],           │ │
│ │                          │   │     [ 5.0549e-01,  5.2300e-01,            │ │
│ │                          3.6514e-01,  ..., -3.3179e-01,                  │ │
│ │                          │   │      -1.5811e-01, -1.0091e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 6.5520e-01,  1.1379e+00,            │ │
│ │                          1.7064e+00,  ...,  1.9253e-02,                  │ │
│ │                          │   │      -2.0373e-01, -1.7871e-01],           │ │
│ │                          │   │     [ 2.3593e-01, -8.7012e-01,            │ │
│ │                          -2.8873e-01,  ...,  3.9973e-01,                 │ │
│ │                          │   │      -1.1689e-01, -2.8973e-01],           │ │
│ │                          │   │     [-2.1368e-01, -1.4016e+00,            │ │
│ │                          -9.4576e-01,  ...,  2.7588e-01,                 │ │
│ │                          │   │      -7.6102e-02, -5.9480e-01]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[ 2.7202e-01, -1.8481e-01,            │ │
│ │                          -3.5767e-01,  ..., -7.7428e-01,                 │ │
│ │                          │   │      -6.7339e-01, -9.3383e-01],           │ │
│ │                          │   │     [ 7.9055e-02,  2.2025e-01,            │ │
│ │                          7.1470e-02,  ..., -7.7860e-01,                  │ │
│ │                          │   │      -7.4496e-01, -6.1977e-01],           │ │
│ │                          │   │     [ 4.7062e-01,  3.6872e-01,            │ │
│ │                          1.9555e-01,  ..., -6.2921e-01,                  │ │
│ │                          │   │      -4.5697e-01, -5.3934e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 9.8460e-01,  1.4608e+00,            │ │
│ │                          1.9852e+00,  ..., -6.4653e-02,                  │ │
│ │                          │   │      -3.2023e-01, -3.4532e-01],           │ │
│ │                          │   │     [ 4.1559e-01, -6.6316e-01,            │ │
│ │                          -1.4031e-02,  ...,  3.1378e-01,                 │ │
│ │                          │   │      -2.1559e-01, -4.0635e-01],           │ │
│ │                          │   │     [-3.2466e-01, -1.3013e+00,            │ │
│ │                          -8.9704e-01,  ...,  1.8136e-01,                 │ │
│ │                          │   │      -1.7741e-01, -6.9516e-01]]],         │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-1.1129e+00, -1.1203e+00,            │ │
│ │                          -1.1048e+00,  ...,  1.4798e-01,                 │ │
│ │                          │   │   │   1.3982e-01,  1.4600e-01],           │ │
│ │                          │   │     [-1.1248e+00, -1.0954e+00,            │ │
│ │                          -1.0754e+00,  ...,  7.7064e-01,                 │ │
│ │                          │   │   │   4.5042e-01,  1.7569e-01],           │ │
│ │                          │   │     [-1.1117e+00, -1.0733e+00,            │ │
│ │                          -1.0819e+00,  ...,  1.6354e+00,                 │ │
│ │                          │   │   │   5.7843e-01,  4.2551e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-6.8136e-01, -1.1696e+00,            │ │
│ │                          -1.4188e+00,  ..., -3.1875e-01,                 │ │
│ │                          │   │      -3.1127e-01, -2.0902e-01],           │ │
│ │                          │   │     [-2.2044e-01, -4.7102e-01,            │ │
│ │                          -1.2520e+00,  ..., -2.6598e-01,                 │ │
│ │                          │   │      -2.9664e-01, -2.8849e-01],           │ │
│ │                          │   │     [-8.8744e-02, -1.0999e-01,            │ │
│ │                          -5.5706e-01,  ..., -5.6562e-01,                 │ │
│ │                          │   │      -3.1702e-01, -4.1703e-02]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.1946e+00, -1.1850e+00,            │ │
│ │                          -1.1670e+00,  ...,  1.9893e-01,                 │ │
│ │                          │   │   │   1.9766e-01,  1.7033e-01],           │ │
│ │                          │   │     [-1.2048e+00, -1.1641e+00,            │ │
│ │                          -1.1343e+00,  ...,  7.0220e-01,                 │ │
│ │                          │   │   │   4.4057e-01,  1.9051e-01],           │ │
│ │                          │   │     [-1.1737e+00, -1.1384e+00,            │ │
│ │                          -1.1431e+00,  ...,  1.6181e+00,                 │ │
│ │                          │   │   │   5.7819e-01,  4.3821e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-6.3667e-01, -1.1339e+00,            │ │
│ │                          -1.4394e+00,  ..., -3.1743e-01,                 │ │
│ │                          │   │      -3.0566e-01, -1.9553e-01],           │ │
│ │                          │   │     [-1.0974e-01, -3.4650e-01,            │ │
│ │                          -1.2083e+00,  ..., -2.3575e-01,                 │ │
│ │                          │   │      -2.8395e-01, -2.8469e-01],           │ │
│ │                          │   │     [ 5.1619e-02,  6.6037e-02,            │ │
│ │                          -4.1253e-01,  ..., -4.9201e-01,                 │ │
│ │                          │   │      -2.7585e-01, -2.4797e-02]],          │ │
│ │                          │   │                                           │ │
│ │                          │   │    [[-1.2644e+00, -1.2547e+00,            │ │
│ │                          -1.2417e+00,  ...,  1.8594e-01,                 │ │
│ │                          │   │   │   2.0993e-01,  2.1114e-01],           │ │
│ │                          │   │     [-1.2650e+00, -1.2274e+00,            │ │
│ │                          -1.2070e+00,  ...,  7.1659e-01,                 │ │
│ │                          │   │   │   4.6163e-01,  2.1240e-01],           │ │
│ │                          │   │     [-1.2420e+00, -1.2135e+00,            │ │
│ │                          -1.2219e+00,  ...,  1.6302e+00,                 │ │
│ │                          │   │   │   5.8077e-01,  4.3076e-01],           │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-5.2276e-01, -1.0734e+00,            │ │
│ │                          -1.4410e+00,  ..., -3.5665e-01,                 │ │
│ │                          │   │      -3.0819e-01, -1.7070e-01],           │ │
│ │                          │   │     [ 1.4361e-01, -1.1527e-01,            │ │
│ │                          -1.1549e+00,  ..., -2.4029e-01,                 │ │
│ │                          │   │      -2.7455e-01, -2.6630e-01],           │ │
│ │                          │   │     [ 3.8853e-01,  4.3464e-01,            │ │
│ │                          -2.3984e-01,  ..., -4.9842e-01,                 │ │
│ │                          │   │      -2.6489e-01, -3.3411e-03]]]],        │ │
│ │                          device='cuda:0')                                │ │
│ │            input_files = [                                               │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │   ... +4990                                   │ │
│ │                          ]                                               │ │
│ │            input_paths = '/media/tidop/Datos_4TB1/databases/kaggle/data… │ │
│ │   kaggle_train_dataset = <dataloader.StudentDataset object at            │ │
│ │                          0x7b5bf232cc10>                                 │ │
│ │     kaggle_val_dataset = <dataloader.StudentDataset object at            │ │
│ │                          0x7b5b2ff39930>                                 │ │
│ │            label_files = [                                               │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │                                               │ │
│ │                          PosixPath('/media/tidop/Datos_4TB1/databases/k… │ │
│ │                          │   ... +4990                                   │ │
│ │                          ]                                               │ │
│ │            label_paths = '/media/tidop/Datos_4TB1/databases/kaggle/data… │ │
│ │                 logits = tensor([[[[-0.1435, -0.2862, -0.1191,  ...,     │ │
│ │                          -0.1700, -0.1469, -0.1088],                     │ │
│ │                          │   │     [ 0.0118, -0.3578, -0.3544,  ...,     │ │
│ │                          -0.1216, -0.0964, -0.0388],                     │ │
│ │                          │   │     [-0.1330, -0.1225, -0.0639,  ...,     │ │
│ │                          -0.0951, -0.1856, -0.0324],                     │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-0.1181, -0.1125,  0.0098,  ...,     │ │
│ │                          -0.2579, -0.0732, -0.0880],                     │ │
│ │                          │   │     [-0.1081, -0.1005, -0.0391,  ...,     │ │
│ │                          -0.2145, -0.1832, -0.0291],                     │ │
│ │                          │   │     [ 0.0034, -0.0654, -0.1045,  ...,     │ │
│ │                          -0.2041, -0.1404, -0.0995]]],                   │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[ 0.0925, -0.1838, -0.0941,  ...,     │ │
│ │                          -0.1226, -0.1168, -0.1119],                     │ │
│ │                          │   │     [-0.2711, -0.6367, -0.7013,  ...,     │ │
│ │                          -0.2850, -0.2475, -0.1040],                     │ │
│ │                          │   │     [-0.2631, -0.4233, -0.2159,  ...,     │ │
│ │                          -0.2824, -0.0163, -0.1019],                     │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [ 0.0364, -0.1551, -0.2247,  ...,     │ │
│ │                          -0.2036, -0.1441, -0.0686],                     │ │
│ │                          │   │     [-0.1397, -0.0617, -0.1824,  ...,     │ │
│ │                          -0.1872, -0.1368, -0.1157],                     │ │
│ │                          │   │     [-0.0806, -0.2077, -0.1279,  ...,     │ │
│ │                          -0.1422, -0.1146, -0.0967]]],                   │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-0.1456, -0.0756, -0.1700,  ...,     │ │
│ │                          -0.0709, -0.0644, -0.0713],                     │ │
│ │                          │   │     [-0.1714, -0.1685, -0.1953,  ...,     │ │
│ │                          -0.1016, -0.0751, -0.0663],                     │ │
│ │                          │   │     [-0.2134, -0.2438, -0.1683,  ...,     │ │
│ │                          -0.0936, -0.0770, -0.0614],                     │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-0.1703, -0.1441, -0.1726,  ...,     │ │
│ │                          0.1431,  0.1101,  0.1762],                      │ │
│ │                          │   │     [-0.0855, -0.0510,  0.0054,  ...,     │ │
│ │                          -0.1426,  0.1856,  0.0551],                     │ │
│ │                          │   │     [-0.1975, -0.1217, -0.1272,  ...,     │ │
│ │                          -0.0467, -0.2180,  0.0481]]],                   │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   ...,                                    │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-0.0819, -0.1419, -0.0569,  ...,     │ │
│ │                          0.0392, -0.1681, -0.1737],                      │ │
│ │                          │   │     [-0.0705, -0.3209, -0.1633,  ...,     │ │
│ │                          0.0051, -0.1476, -0.1832],                      │ │
│ │                          │   │     [-0.0947, -0.1946, -0.1712,  ...,     │ │
│ │                          0.0740, -0.1749, -0.1616],                      │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-0.0695, -0.0987, -0.1791,  ...,     │ │
│ │                          -0.0666, -0.1180, -0.1357],                     │ │
│ │                          │   │     [-0.0946, -0.1006, -0.1779,  ...,     │ │
│ │                          -0.1269, -0.2001, -0.1434],                     │ │
│ │                          │   │     [-0.1736, -0.1371, -0.1244,  ...,     │ │
│ │                          -0.1163, -0.1624, -0.1455]]],                   │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-0.1706, -0.0217, -0.0869,  ...,     │ │
│ │                          -0.1163, -0.1295, -0.0699],                     │ │
│ │                          │   │     [-0.2415, -0.1319, -0.3108,  ...,     │ │
│ │                          -0.2616, -0.1469, -0.1334],                     │ │
│ │                          │   │     [-0.2616, -0.1679, -0.0996,  ...,     │ │
│ │                          -0.1284, -0.1505,  0.0127],                     │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-0.2909, -0.2728, -0.0820,  ...,     │ │
│ │                          0.0184,  0.1696,  0.2062],                      │ │
│ │                          │   │     [-0.1384, -0.2432, -0.1391,  ...,     │ │
│ │                          -0.0559, -0.0759, -0.0235],                     │ │
│ │                          │   │     [-0.1187, -0.1602, -0.0933,  ...,     │ │
│ │                          -0.3103, -0.0865, -0.0971]]],                   │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[-0.1835, -0.1952, -0.1724,  ...,     │ │
│ │                          0.0046, -0.0602, -0.1236],                      │ │
│ │                          │   │     [-0.0693, -0.3047, -0.2680,  ...,     │ │
│ │                          -0.0793, -0.1673, -0.1456],                     │ │
│ │                          │   │     [-0.0913, -0.1910, -0.1142,  ...,     │ │
│ │                          -0.1876, -0.2264, -0.0314],                     │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [-0.0287, -0.1845, -0.2633,  ...,     │ │
│ │                          -0.0985, -0.0867, -0.0833],                     │ │
│ │                          │   │     [-0.1299, -0.1301, -0.1425,  ...,     │ │
│ │                          -0.1327, -0.0888, -0.0336],                     │ │
│ │                          │   │     [-0.1466, -0.1208, -0.2148,  ...,     │ │
│ │                          -0.1540, -0.1479, -0.0994]]]],                  │ │
│ │                          │      device='cuda:0',                         │ │
│ │                          grad_fn=<ConvolutionBackward0>)                 │ │
│ │                   loss = tensor([[1099.6238],                            │ │
│ │                          │   │   [ 798.7560],                            │ │
│ │                          │   │   [ 965.1544],                            │ │
│ │                          │   │   [1096.7944],                            │ │
│ │                          │   │   [ 889.6296],                            │ │
│ │                          │   │   [ 947.9906],                            │ │
│ │                          │   │   [1034.4781],                            │ │
│ │                          │   │   [1042.3556],                            │ │
│ │                          │   │   [ 821.4948],                            │ │
│ │                          │   │   [1104.9583],                            │ │
│ │                          │   │   [ 802.3161],                            │ │
│ │                          │   │   [ 880.2845],                            │ │
│ │                          │   │   [ 832.3288],                            │ │
│ │                          │   │   [ 819.6701],                            │ │
│ │                          │   │   [1094.4921],                            │ │
│ │                          │   │   [ 636.5009]], device='cuda:0',          │ │
│ │                          grad_fn=<AddBackward0>)                         │ │
│ │                     lr = 0.0001                                          │ │
│ │                  masks = tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.]]],     │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.]]],     │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 1., 1., 1.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 1., 1., 1.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 1., 1., 1.]]],     │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   ...,                                    │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.]]],     │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.]]],     │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [1., 1., 1.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.],       │ │
│ │                          │   │     [0., 0., 0.,  ..., 0., 0., 0.]]]],    │ │
│ │                          device='cuda:0')                                │ │
│ │            max_val_iou = 0                                               │ │
│ │                   mean = [72.74413315, 99.76137101, 82.70024275]         │ │
│ │              normalize = True                                            │ │
│ │            num_workers = 16                                              │ │
│ │              optimizer = Adam (                                          │ │
│ │                          Parameter Group 0                               │ │
│ │                          │   amsgrad: False                              │ │
│ │                          │   betas: (0.9, 0.999)                         │ │
│ │                          │   capturable: False                           │ │
│ │                          │   differentiable: False                       │ │
│ │                          │   eps: 1e-08                                  │ │
│ │                          │   foreach: None                               │ │
│ │                          │   fused: None                                 │ │
│ │                          │   lr: 0.0001                                  │ │
│ │                          │   maximize: False                             │ │
│ │                          │   weight_decay: 0                             │ │
│ │                          )                                               │ │
│ │                outputs = tensor([[[[0.4642, 0.4289, 0.4703,  ...,        │ │
│ │                          0.4576, 0.4633, 0.4728],                        │ │
│ │                          │   │     [0.5029, 0.4115, 0.4123,  ...,        │ │
│ │                          0.4696, 0.4759, 0.4903],                        │ │
│ │                          │   │     [0.4668, 0.4694, 0.4840,  ...,        │ │
│ │                          0.4762, 0.4537, 0.4919],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.4705, 0.4719, 0.5024,  ...,        │ │
│ │                          0.4359, 0.4817, 0.4780],                        │ │
│ │                          │   │     [0.4730, 0.4749, 0.4902,  ...,        │ │
│ │                          0.4466, 0.4543, 0.4927],                        │ │
│ │                          │   │     [0.5008, 0.4837, 0.4739,  ...,        │ │
│ │                          0.4492, 0.4649, 0.4751]]],                      │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0.5231, 0.4542, 0.4765,  ...,        │ │
│ │                          0.4694, 0.4708, 0.4720],                        │ │
│ │                          │   │     [0.4326, 0.3460, 0.3315,  ...,        │ │
│ │                          0.4292, 0.4384, 0.4740],                        │ │
│ │                          │   │     [0.4346, 0.3957, 0.4462,  ...,        │ │
│ │                          0.4299, 0.4959, 0.4746],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.5091, 0.4613, 0.4441,  ...,        │ │
│ │                          0.4493, 0.4640, 0.4829],                        │ │
│ │                          │   │     [0.4651, 0.4846, 0.4545,  ...,        │ │
│ │                          0.4533, 0.4659, 0.4711],                        │ │
│ │                          │   │     [0.4799, 0.4483, 0.4681,  ...,        │ │
│ │                          0.4645, 0.4714, 0.4759]]],                      │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0.4637, 0.4811, 0.4576,  ...,        │ │
│ │                          0.4823, 0.4839, 0.4822],                        │ │
│ │                          │   │     [0.4572, 0.4580, 0.4513,  ...,        │ │
│ │                          0.4746, 0.4812, 0.4834],                        │ │
│ │                          │   │     [0.4468, 0.4393, 0.4580,  ...,        │ │
│ │                          0.4766, 0.4808, 0.4846],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.4575, 0.4640, 0.4570,  ...,        │ │
│ │                          0.5357, 0.5275, 0.5439],                        │ │
│ │                          │   │     [0.4786, 0.4872, 0.5014,  ...,        │ │
│ │                          0.4644, 0.5463, 0.5138],                        │ │
│ │                          │   │     [0.4508, 0.4696, 0.4683,  ...,        │ │
│ │                          0.4883, 0.4457, 0.5120]]],                      │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   ...,                                    │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0.4795, 0.4646, 0.4858,  ...,        │ │
│ │                          0.5098, 0.4581, 0.4567],                        │ │
│ │                          │   │     [0.4824, 0.4204, 0.4593,  ...,        │ │
│ │                          0.5013, 0.4632, 0.4543],                        │ │
│ │                          │   │     [0.4763, 0.4515, 0.4573,  ...,        │ │
│ │                          0.5185, 0.4564, 0.4597],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.4826, 0.4754, 0.4553,  ...,        │ │
│ │                          0.4834, 0.4705, 0.4661],                        │ │
│ │                          │   │     [0.4764, 0.4749, 0.4556,  ...,        │ │
│ │                          0.4683, 0.4502, 0.4642],                        │ │
│ │                          │   │     [0.4567, 0.4658, 0.4689,  ...,        │ │
│ │                          0.4710, 0.4595, 0.4637]]],                      │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0.4575, 0.4946, 0.4783,  ...,        │ │
│ │                          0.4709, 0.4677, 0.4825],                        │ │
│ │                          │   │     [0.4399, 0.4671, 0.4229,  ...,        │ │
│ │                          0.4350, 0.4633, 0.4667],                        │ │
│ │                          │   │     [0.4350, 0.4581, 0.4751,  ...,        │ │
│ │                          0.4679, 0.4624, 0.5032],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.4278, 0.4322, 0.4795,  ...,        │ │
│ │                          0.5046, 0.5423, 0.5514],                        │ │
│ │                          │   │     [0.4655, 0.4395, 0.4653,  ...,        │ │
│ │                          0.4860, 0.4810, 0.4941],                        │ │
│ │                          │   │     [0.4704, 0.4600, 0.4767,  ...,        │ │
│ │                          0.4230, 0.4784, 0.4758]]],                      │ │
│ │                          │   │                                           │ │
│ │                          │   │                                           │ │
│ │                          │   │   [[[0.4543, 0.4513, 0.4570,  ...,        │ │
│ │                          0.5011, 0.4849, 0.4691],                        │ │
│ │                          │   │     [0.4827, 0.4244, 0.4334,  ...,        │ │
│ │                          0.4802, 0.4583, 0.4637],                        │ │
│ │                          │   │     [0.4772, 0.4524, 0.4715,  ...,        │ │
│ │                          0.4532, 0.4436, 0.4921],                        │ │
│ │                          │   │     ...,                                  │ │
│ │                          │   │     [0.4928, 0.4540, 0.4346,  ...,        │ │
│ │                          0.4754, 0.4783, 0.4792],                        │ │
│ │                          │   │     [0.4676, 0.4675, 0.4644,  ...,        │ │
│ │                          0.4669, 0.4778, 0.4916],                        │ │
│ │                          │   │     [0.4634, 0.4698, 0.4465,  ...,        │ │
│ │                          0.4616, 0.4631, 0.4752]]]],                     │ │
│ │                          │      device='cuda:0',                         │ │
│ │                          grad_fn=<SigmoidBackward0>)                     │ │
│ │               patience = 5                                               │ │
│ │           running_dice = 0.0                                             │ │
│ │             running_f1 = 0.0                                             │ │
│ │            running_iou = 0.0                                             │ │
│ │           running_loss = 0.0                                             │ │
│ │      running_precision = 0.0                                             │ │
│ │         running_recall = 0.0                                             │ │
│ │              scheduler = <torch.optim.lr_scheduler.ReduceLROnPlateau     │ │
│ │                          object at 0x7b5b2ff0bf40>                       │ │
│ │                    std = [36.28290664, 34.82507359, 41.48902725]         │ │
│ │                teacher = ResUnetTeacher(                                 │ │
│ │                            (inc): DoubleConv(                            │ │
│ │                          │   (conv): Sequential(                         │ │
│ │                          │     (0): Conv2d(3, 64, kernel_size=(3, 3),    │ │
│ │                          stride=(1, 1), padding=(1, 1), bias=False)      │ │
│ │                          │     (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │     (2): ReLU(inplace=True)                   │ │
│ │                          │     (3): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                          stride=(1, 1), padding=(1, 1), bias=False)      │ │
│ │                          │     (4): BatchNorm2d(64, eps=1e-05,           │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │     (5): ReLU(inplace=True)                   │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (down1): Down(                                │ │
│ │                          │   (pool): MaxPool2d(kernel_size=2, stride=2,  │ │
│ │                          padding=0, dilation=1, ceil_mode=False)         │ │
│ │                          │   (conv): DoubleConv(                         │ │
│ │                          │     (conv): Sequential(                       │ │
│ │                          │   │   (0): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (2): ReLU(inplace=True)                 │ │
│ │                          │   │   (3): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (4): BatchNorm2d(128, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (5): ReLU(inplace=True)                 │ │
│ │                          │     )                                         │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (down2): Down(                                │ │
│ │                          │   (pool): MaxPool2d(kernel_size=2, stride=2,  │ │
│ │                          padding=0, dilation=1, ceil_mode=False)         │ │
│ │                          │   (conv): DoubleConv(                         │ │
│ │                          │     (conv): Sequential(                       │ │
│ │                          │   │   (0): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (2): ReLU(inplace=True)                 │ │
│ │                          │   │   (3): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (4): BatchNorm2d(256, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (5): ReLU(inplace=True)                 │ │
│ │                          │     )                                         │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (up1): Up(                                    │ │
│ │                          │   (up): ConvTranspose2d(256, 128,             │ │
│ │                          kernel_size=(2, 2), stride=(2, 2))              │ │
│ │                          │   (conv): DoubleConv(                         │ │
│ │                          │     (conv): Sequential(                       │ │
│ │                          │   │   (0): Conv2d(256, 128, kernel_size=(3,   │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (2): ReLU(inplace=True)                 │ │
│ │                          │   │   (3): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (4): BatchNorm2d(128, eps=1e-05,        │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (5): ReLU(inplace=True)                 │ │
│ │                          │     )                                         │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (att1): AttentionBlock(                       │ │
│ │                          │   (channel_attention): ChannelAttention(      │ │
│ │                          │     (avg_pool):                               │ │
│ │                          AdaptiveAvgPool2d(output_size=1)                │ │
│ │                          │     (max_pool):                               │ │
│ │                          AdaptiveMaxPool2d(output_size=1)                │ │
│ │                          │     (fc): Sequential(                         │ │
│ │                          │   │   (0): Conv2d(128, 8, kernel_size=(1, 1), │ │
│ │                          stride=(1, 1), bias=False)                      │ │
│ │                          │   │   (1): ReLU(inplace=True)                 │ │
│ │                          │   │   (2): Conv2d(8, 128, kernel_size=(1, 1), │ │
│ │                          stride=(1, 1), bias=False)                      │ │
│ │                          │     )                                         │ │
│ │                          │     (sigmoid): Sigmoid()                      │ │
│ │                          │   )                                           │ │
│ │                          │   (spatial_attention): SpatialAttention(      │ │
│ │                          │     (avg_pool): AvgPool2d(kernel_size=7,      │ │
│ │                          stride=1, padding=3)                            │ │
│ │                          │     (max_pool): MaxPool2d(kernel_size=7,      │ │
│ │                          stride=1, padding=3, dilation=1,                │ │
│ │                          ceil_mode=False)                                │ │
│ │                          │     (conv): Conv2d(256, 1, kernel_size=(7,    │ │
│ │                          7), stride=(1, 1), padding=(3, 3), bias=False)  │ │
│ │                          │     (sigmoid): Sigmoid()                      │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (up2): Up(                                    │ │
│ │                          │   (up): ConvTranspose2d(128, 64,              │ │
│ │                          kernel_size=(2, 2), stride=(2, 2))              │ │
│ │                          │   (conv): DoubleConv(                         │ │
│ │                          │     (conv): Sequential(                       │ │
│ │                          │   │   (0): Conv2d(128, 64, kernel_size=(3,    │ │
│ │                          3), stride=(1, 1), padding=(1, 1), bias=False)  │ │
│ │                          │   │   (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (2): ReLU(inplace=True)                 │ │
│ │                          │   │   (3): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                          stride=(1, 1), padding=(1, 1), bias=False)      │ │
│ │                          │   │   (4): BatchNorm2d(64, eps=1e-05,         │ │
│ │                          momentum=0.1, affine=True,                      │ │
│ │                          track_running_stats=True)                       │ │
│ │                          │   │   (5): ReLU(inplace=True)                 │ │
│ │                          │     )                                         │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (att2): AttentionBlock(                       │ │
│ │                          │   (channel_attention): ChannelAttention(      │ │
│ │                          │     (avg_pool):                               │ │
│ │                          AdaptiveAvgPool2d(output_size=1)                │ │
│ │                          │     (max_pool):                               │ │
│ │                          AdaptiveMaxPool2d(output_size=1)                │ │
│ │                          │     (fc): Sequential(                         │ │
│ │                          │   │   (0): Conv2d(64, 4, kernel_size=(1, 1),  │ │
│ │                          stride=(1, 1), bias=False)                      │ │
│ │                          │   │   (1): ReLU(inplace=True)                 │ │
│ │                          │   │   (2): Conv2d(4, 64, kernel_size=(1, 1),  │ │
│ │                          stride=(1, 1), bias=False)                      │ │
│ │                          │     )                                         │ │
│ │                          │     (sigmoid): Sigmoid()                      │ │
│ │                          │   )                                           │ │
│ │                          │   (spatial_attention): SpatialAttention(      │ │
│ │                          │     (avg_pool): AvgPool2d(kernel_size=7,      │ │
│ │                          stride=1, padding=3)                            │ │
│ │                          │     (max_pool): MaxPool2d(kernel_size=7,      │ │
│ │                          stride=1, padding=3, dilation=1,                │ │
│ │                          ceil_mode=False)                                │ │
│ │                          │     (conv): Conv2d(128, 1, kernel_size=(7,    │ │
│ │                          7), stride=(1, 1), padding=(3, 3), bias=False)  │ │
│ │                          │     (sigmoid): Sigmoid()                      │ │
│ │                          │   )                                           │ │
│ │                            )                                             │ │
│ │                            (outc): Conv2d(64, 1, kernel_size=(1, 1),     │ │
│ │                          stride=(1, 1))                                  │ │
│ │                          )                                               │ │
│ │           train_loader = <torch.utils.data.dataloader.DataLoader object  │ │
│ │                          at 0x7b5b2ff3a950>                              │ │
│ │             val_loader = <torch.utils.data.dataloader.DataLoader object  │ │
│ │                          at 0x7b5b2ff3a9b0>                              │ │
│ │               whu_mean = [72.62323902, 99.33869521, 82.94464024]         │ │
│ │             whu_module = <dataloader.BuildingDataModule object at        │ │
│ │                          0x7b5b2ff0ba30>                                 │ │
│ │               whu_path = '/media/tidop/Datos_4TB1/databases/whu_adjuste… │ │
│ │                whu_std = [43.81751311, 42.46326449, 50.62061044]         │ │
│ │      whu_train_dataset = <dataloader.TeacherDataset object at            │ │
│ │                          0x7b5b2ff87fa0>                                 │ │
│ │        whu_val_dataset = <dataloader.TeacherDataset object at            │ │
│ │                          0x7b5b2ff878b0>                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/_tensor.py:581 in backward                                                │
│                                                                              │
│    578 │   │   │   │   create_graph=create_graph,                            │
│    579 │   │   │   │   inputs=inputs,                                        │
│    580 │   │   │   )                                                         │
│ ❱  581 │   │   torch.autograd.backward(                                      │
│    582 │   │   │   self, gradient, retain_graph, create_graph, inputs=inputs │
│    583 │   │   )                                                             │
│    584                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ create_graph = False                                                     │ │
│ │     gradient = None                                                      │ │
│ │       inputs = None                                                      │ │
│ │ retain_graph = None                                                      │ │
│ │         self = tensor([[1099.6238],                                      │ │
│ │                │   │   [ 798.7560],                                      │ │
│ │                │   │   [ 965.1544],                                      │ │
│ │                │   │   [1096.7944],                                      │ │
│ │                │   │   [ 889.6296],                                      │ │
│ │                │   │   [ 947.9906],                                      │ │
│ │                │   │   [1034.4781],                                      │ │
│ │                │   │   [1042.3556],                                      │ │
│ │                │   │   [ 821.4948],                                      │ │
│ │                │   │   [1104.9583],                                      │ │
│ │                │   │   [ 802.3161],                                      │ │
│ │                │   │   [ 880.2845],                                      │ │
│ │                │   │   [ 832.3288],                                      │ │
│ │                │   │   [ 819.6701],                                      │ │
│ │                │   │   [1094.4921],                                      │ │
│ │                │   │   [ 636.5009]], device='cuda:0',                    │ │
│ │                grad_fn=<AddBackward0>)                                   │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/autograd/__init__.py:340 in backward                                      │
│                                                                              │
│   337 │   )                                                                  │
│   338 │                                                                      │
│   339 │   grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, len(tens │
│ ❱ 340 │   grad_tensors_ = _make_grads(tensors, grad_tensors_, is_grads_batch │
│   341 │   if retain_graph is None:                                           │
│   342 │   │   retain_graph = create_graph                                    │
│   343                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   create_graph = False                                                   │ │
│ │   grad_tensors = None                                                    │ │
│ │  grad_tensors_ = (None,)                                                 │ │
│ │ grad_variables = None                                                    │ │
│ │         inputs = ()                                                      │ │
│ │   retain_graph = None                                                    │ │
│ │        tensors = (                                                       │ │
│ │                  │   tensor([[1099.6238],                                │ │
│ │                  │   │   [ 798.7560],                                    │ │
│ │                  │   │   [ 965.1544],                                    │ │
│ │                  │   │   [1096.7944],                                    │ │
│ │                  │   │   [ 889.6296],                                    │ │
│ │                  │   │   [ 947.9906],                                    │ │
│ │                  │   │   [1034.4781],                                    │ │
│ │                  │   │   [1042.3556],                                    │ │
│ │                  │   │   [ 821.4948],                                    │ │
│ │                  │   │   [1104.9583],                                    │ │
│ │                  │   │   [ 802.3161],                                    │ │
│ │                  │   │   [ 880.2845],                                    │ │
│ │                  │   │   [ 832.3288],                                    │ │
│ │                  │   │   [ 819.6701],                                    │ │
│ │                  │   │   [1094.4921],                                    │ │
│ │                  │   │   [ 636.5009]], device='cuda:0',                  │ │
│ │                  grad_fn=<AddBackward0>),                                │ │
│ │                  )                                                       │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/autograd/__init__.py:198 in _make_grads                                   │
│                                                                              │
│   195 │   │   │   │   │   assert isinstance(out, torch.Tensor)               │
│   196 │   │   │   │   │   out_numel_is_1 = out.numel() == 1                  │
│   197 │   │   │   │   if not out_numel_is_1:                                 │
│ ❱ 198 │   │   │   │   │   raise RuntimeError(                                │
│   199 │   │   │   │   │   │   "grad can be implicitly created only for scala │
│   200 │   │   │   │   │   )                                                  │
│   201 │   │   │   │   if not out_dtype.is_floating_point:                    │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │              grad = None                                                 │ │
│ │             grads = (None,)                                              │ │
│ │  is_grads_batched = False                                                │ │
│ │      NestedTensor = <class                                               │ │
│ │                     'torch.nested._internal.nested_tensor.NestedTensor'> │ │
│ │         new_grads = []                                                   │ │
│ │               out = tensor([[1099.6238],                                 │ │
│ │                     │   │   [ 798.7560],                                 │ │
│ │                     │   │   [ 965.1544],                                 │ │
│ │                     │   │   [1096.7944],                                 │ │
│ │                     │   │   [ 889.6296],                                 │ │
│ │                     │   │   [ 947.9906],                                 │ │
│ │                     │   │   [1034.4781],                                 │ │
│ │                     │   │   [1042.3556],                                 │ │
│ │                     │   │   [ 821.4948],                                 │ │
│ │                     │   │   [1104.9583],                                 │ │
│ │                     │   │   [ 802.3161],                                 │ │
│ │                     │   │   [ 880.2845],                                 │ │
│ │                     │   │   [ 832.3288],                                 │ │
│ │                     │   │   [ 819.6701],                                 │ │
│ │                     │   │   [1094.4921],                                 │ │
│ │                     │   │   [ 636.5009]], device='cuda:0',               │ │
│ │                     grad_fn=<AddBackward0>)                              │ │
│ │        out_device = None                                                 │ │
│ │         out_dtype = torch.float32                                        │ │
│ │ out_is_cpp_nested = False                                                │ │
│ │     out_is_nested = False                                                │ │
│ │    out_numel_is_1 = False                                                │ │
│ │          out_size = torch.Size([16, 1])                                  │ │
│ │           outputs = (                                                    │ │
│ │                     │   tensor([[1099.6238],                             │ │
│ │                     │   │   [ 798.7560],                                 │ │
│ │                     │   │   [ 965.1544],                                 │ │
│ │                     │   │   [1096.7944],                                 │ │
│ │                     │   │   [ 889.6296],                                 │ │
│ │                     │   │   [ 947.9906],                                 │ │
│ │                     │   │   [1034.4781],                                 │ │
│ │                     │   │   [1042.3556],                                 │ │
│ │                     │   │   [ 821.4948],                                 │ │
│ │                     │   │   [1104.9583],                                 │ │
│ │                     │   │   [ 802.3161],                                 │ │
│ │                     │   │   [ 880.2845],                                 │ │
│ │                     │   │   [ 832.3288],                                 │ │
│ │                     │   │   [ 819.6701],                                 │ │
│ │                     │   │   [1094.4921],                                 │ │
│ │                     │   │   [ 636.5009]], device='cuda:0',               │ │
│ │                     grad_fn=<AddBackward0>),                             │ │
│ │                     )                                                    │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
╰──────────────────────────────────────────────────────────────────────────────╯
RuntimeError: grad can be implicitly created only for scalar outputs
