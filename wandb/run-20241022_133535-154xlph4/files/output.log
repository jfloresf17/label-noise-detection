LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

   | Name            | Type               | Params | Mode
----------------------------------------------------------------
0  | model           | Unet               | 24.4 M | train
1  | loss            | BCEWithLogitsLoss  | 0      | train
2  | train_f1        | BinaryF1Score      | 0      | train
3  | train_iou       | BinaryJaccardIndex | 0      | train
4  | train_precision | BinaryPrecision    | 0      | train
5  | train_recall    | BinaryRecall       | 0      | train
6  | val_f1          | BinaryF1Score      | 0      | train
7  | val_iou         | BinaryJaccardIndex | 0      | train
8  | val_precision   | BinaryPrecision    | 0      | train
9  | val_recall      | BinaryRecall       | 0      | train
10 | test_f1         | BinaryF1Score      | 0      | train
11 | test_iou        | BinaryJaccardIndex | 0      | train
12 | test_precision  | BinaryPrecision    | 0      | train
13 | test_recall     | BinaryRecall       | 0      | train
----------------------------------------------------------------
24.4 M    Trainable params
0         Non-trainable params
24.4 M    Total params
97.745    Total estimated model params size (MB)
201       Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 183, in <module>
    app()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 338, in __call__
    raise e
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 321, in __call__
    return get_command(self)(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1157, in __call__
    return self.main(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 665, in main
    return _main(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/core.py", line 197, in _main
    rv = self.invoke(ctx)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/click/core.py", line 783, in invoke
    return __callback(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/typer/main.py", line 703, in wrapper
    return callback(**use_params)
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 176, in train
    train_teacher(config)
  File "/home/tidop/projects/Noisy-Student/trainer.py", line 79, in train_teacher
    trainer.fit(teacher_model, clean_dataloader)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 410, in validation_step
    return self._forward_redirection(self.model, self.lightning_module, "validation_step", *args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 640, in __call__
    wrapper_output = wrapper_module(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 633, in wrapped_forward
    out = method(*_args, **_kwargs)
  File "/home/tidop/projects/Noisy-Student/models/teacher_unet.py", line 68, in validation_step
    ce_loss = self.loss(outputs, labels)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 725, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/torch/nn/functional.py", line 3197, in binary_cross_entropy_with_logits
    raise ValueError(f"Target size ({target.size()}) must be the same as input size ({input.size()})")
ValueError: Target size (torch.Size([16, 1, 1, 256, 256])) must be the same as input size (torch.Size([16, 1, 256, 256]))
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/tidop/projects/Noisy-Student/trainer.py:176 in train                   │
│                                                                              │
│   173 │                                                                      │
│   174 │   ## Train the model                                                 │
│   175 │   if model == "teacher":                                             │
│ ❱ 176 │   │   train_teacher(config)                                          │
│   177 │   elif model == "student":                                           │
│   178 │   │   train_student(config)                                          │
│   179 │   else:                                                              │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │      config = {                                                          │ │
│ │               │   'device': 'cuda',                                      │ │
│ │               │   'data': {                                              │ │
│ │               │   │   'batch_size': 16,                                  │ │
│ │               │   │   'num_workers': 16,                                 │ │
│ │               │   │   'whu_path':                                        │ │
│ │               '/media/tidop/Datos_4TB/databases/whu',                    │ │
│ │               │   │   'datacentric_image_path':                          │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/training… │ │
│ │               │   │   'label_noisy_path':                                │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/training… │ │
│ │               │   │   'teacher_output_path':                             │ │
│ │               '/media/tidop/Datos_4TB/databases/kaggle/dataset/teacher_… │ │
│ │               │   },                                                     │ │
│ │               │   'Normalize': {                                         │ │
│ │               │   │   'apply': True,                                     │ │
│ │               │   │   'WHU': {                                           │ │
│ │               │   │   │   'mean': [                                      │ │
│ │               │   │   │   │   105.34253814,                              │ │
│ │               │   │   │   │   114.2284708,                               │ │
│ │               │   │   │   │   112.52936415                               │ │
│ │               │   │   │   ],                                             │ │
│ │               │   │   │   'std': [                                       │ │
│ │               │   │   │   │   42.12451161,                               │ │
│ │               │   │   │   │   39.52149692,                               │ │
│ │               │   │   │   │   42.81161886                                │ │
│ │               │   │   │   ]                                              │ │
│ │               │   │   },                                                 │ │
│ │               │   │   'DataCentric': {                                   │ │
│ │               │   │   │   'mean': [                                      │ │
│ │               │   │   │   │   72.74413315,                               │ │
│ │               │   │   │   │   99.76137101,                               │ │
│ │               │   │   │   │   82.70024275                                │ │
│ │               │   │   │   ],                                             │ │
│ │               │   │   │   'std': [                                       │ │
│ │               │   │   │   │   36.28290664,                               │ │
│ │               │   │   │   │   34.82507359,                               │ │
│ │               │   │   │   │   41.48902725                                │ │
│ │               │   │   │   ]                                              │ │
│ │               │   │   }                                                  │ │
│ │               │   },                                                     │ │
│ │               │   'teacher_model': {                                     │ │
│ │               │   │   'encoder_name': 'resnet34',                        │ │
│ │               │   │   'encoder_weights': 'imagenet',                     │ │
│ │               │   │   'in_channels': 3,                                  │ │
│ │               │   │   'out_channels': 1,                                 │ │
│ │               │   │   'learning_rate': '1e-3',                           │ │
│ │               │   │   'checkpoint_dir': 'checkpoints/',                  │ │
│ │               │   │   'checkpoint_name': 'best_teacher'                  │ │
│ │               │   },                                                     │ │
│ │               │   'student_model': {                                     │ │
│ │               │   │   'encoder_name': 'resnet34',                        │ │
│ │               │   │   'encoder_weights': None,                           │ │
│ │               │   │   'in_channels': 3,                                  │ │
│ │               │   │   'out_channels': 1,                                 │ │
│ │               │   │   'learning_rate': '1e-4',                           │ │
│ │               │   │   'checkpoint_dir': 'checkpoints/',                  │ │
│ │               │   │   'checkpoint_name': 'best_student'                  │ │
│ │               │   },                                                     │ │
│ │               │   'knowledge_distillation': {                            │ │
│ │               │   │   'temperature': 3.0,                                │ │
│ │               │   │   'alpha': 0.75,                                     │ │
│ │               │   │   'beta': 0.25                                       │ │
│ │               │   },                                                     │ │
│ │               │   'trainer': {                                           │ │
│ │               │   │   'wandb_project': 'teacher_student',                │ │
│ │               │   │   'experiment_name': 'teacher_model',                │ │
│ │               │   │   'strategy': 'ddp',                                 │ │
│ │               │   │   'accelerator': 'gpu',                              │ │
│ │               │   │   'precision': '16-mixed',                           │ │
│ │               │   │   'max_epochs': 50,                                  │ │
│ │               │   │   'log_every_n_steps': 50,                           │ │
│ │               │   │   'early_stopping': {                                │ │
│ │               │   │   │   'enabled': True,                               │ │
│ │               │   │   │   'patience': 10,                                │ │
│ │               │   │   │   'monitor': 'val_loss',                         │ │
│ │               │   │   │   'mode': 'min'                                  │ │
│ │               │   │   },                                                 │ │
│ │               │   │   'checkpoint_callback': {                           │ │
│ │               │   │   │   'monitor': 'val_loss',                         │ │
│ │               │   │   │   'mode': 'min',                                 │ │
│ │               │   │   │   'save_top_k': 1                                │ │
│ │               │   │   }                                                  │ │
│ │               │   }                                                      │ │
│ │               }                                                          │ │
│ │ config_path = 'config.yaml'                                              │ │
│ │       model = 'teacher'                                                  │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/projects/Noisy-Student/trainer.py:79 in train_teacher            │
│                                                                              │
│    76 │                                                                      │
│    77 │                                                                      │
│    78 │   # Train teacher model                                              │
│ ❱  79 │   trainer.fit(teacher_model, clean_dataloader)                       │
│    80 │                                                                      │
│    81 │   # Test teacher model                                               │
│    82 │   trainer.test(teacher_model, clean_dataloader, ckpt_path="best")    │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │           batch_size = 16                                                │ │
│ │            callbacks = [                                                 │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.early_stopping.Earl… │ │
│ │                        object at 0x7f0a157a1e10>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.model_checkpoint.Mo… │ │
│ │                        object at 0x7f0a157a1d50>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.progress.tqdm_progr… │ │
│ │                        object at 0x7f0a157a0490>,                        │ │
│ │                        │                                                 │ │
│ │                        <pytorch_lightning.callbacks.model_summary.Model… │ │
│ │                        object at 0x7f0a157a24d0>                         │ │
│ │                        ]                                                 │ │
│ │           checkpoint = <pytorch_lightning.callbacks.model_checkpoint.Mo… │ │
│ │                        object at 0x7f0a157a1d50>                         │ │
│ │    checkpoint_params = {                                                 │ │
│ │                        │   'monitor': 'val_loss',                        │ │
│ │                        │   'mode': 'min',                                │ │
│ │                        │   'save_top_k': 1                               │ │
│ │                        }                                                 │ │
│ │     clean_dataloader = <dataloader.WHUDataModule object at               │ │
│ │                        0x7f0a15126560>                                   │ │
│ │        CLEAN_DATASET = PosixPath('/media/tidop/Datos_4TB/databases/whu') │ │
│ │               config = {                                                 │ │
│ │                        │   'device': 'cuda',                             │ │
│ │                        │   'data': {                                     │ │
│ │                        │   │   'batch_size': 16,                         │ │
│ │                        │   │   'num_workers': 16,                        │ │
│ │                        │   │   'whu_path':                               │ │
│ │                        '/media/tidop/Datos_4TB/databases/whu',           │ │
│ │                        │   │   'datacentric_image_path':                 │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   │   'label_noisy_path':                       │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   │   'teacher_output_path':                    │ │
│ │                        '/media/tidop/Datos_4TB/databases/kaggle/dataset… │ │
│ │                        │   },                                            │ │
│ │                        │   'Normalize': {                                │ │
│ │                        │   │   'apply': True,                            │ │
│ │                        │   │   'WHU': {                                  │ │
│ │                        │   │   │   'mean': [                             │ │
│ │                        │   │   │   │   105.34253814,                     │ │
│ │                        │   │   │   │   114.2284708,                      │ │
│ │                        │   │   │   │   112.52936415                      │ │
│ │                        │   │   │   ],                                    │ │
│ │                        │   │   │   'std': [                              │ │
│ │                        │   │   │   │   42.12451161,                      │ │
│ │                        │   │   │   │   39.52149692,                      │ │
│ │                        │   │   │   │   42.81161886                       │ │
│ │                        │   │   │   ]                                     │ │
│ │                        │   │   },                                        │ │
│ │                        │   │   'DataCentric': {                          │ │
│ │                        │   │   │   'mean': [                             │ │
│ │                        │   │   │   │   72.74413315,                      │ │
│ │                        │   │   │   │   99.76137101,                      │ │
│ │                        │   │   │   │   82.70024275                       │ │
│ │                        │   │   │   ],                                    │ │
│ │                        │   │   │   'std': [                              │ │
│ │                        │   │   │   │   36.28290664,                      │ │
│ │                        │   │   │   │   34.82507359,                      │ │
│ │                        │   │   │   │   41.48902725                       │ │
│ │                        │   │   │   ]                                     │ │
│ │                        │   │   }                                         │ │
│ │                        │   },                                            │ │
│ │                        │   'teacher_model': {                            │ │
│ │                        │   │   'encoder_name': 'resnet34',               │ │
│ │                        │   │   'encoder_weights': 'imagenet',            │ │
│ │                        │   │   'in_channels': 3,                         │ │
│ │                        │   │   'out_channels': 1,                        │ │
│ │                        │   │   'learning_rate': '1e-3',                  │ │
│ │                        │   │   'checkpoint_dir': 'checkpoints/',         │ │
│ │                        │   │   'checkpoint_name': 'best_teacher'         │ │
│ │                        │   },                                            │ │
│ │                        │   'student_model': {                            │ │
│ │                        │   │   'encoder_name': 'resnet34',               │ │
│ │                        │   │   'encoder_weights': None,                  │ │
│ │                        │   │   'in_channels': 3,                         │ │
│ │                        │   │   'out_channels': 1,                        │ │
│ │                        │   │   'learning_rate': '1e-4',                  │ │
│ │                        │   │   'checkpoint_dir': 'checkpoints/',         │ │
│ │                        │   │   'checkpoint_name': 'best_student'         │ │
│ │                        │   },                                            │ │
│ │                        │   'knowledge_distillation': {                   │ │
│ │                        │   │   'temperature': 3.0,                       │ │
│ │                        │   │   'alpha': 0.75,                            │ │
│ │                        │   │   'beta': 0.25                              │ │
│ │                        │   },                                            │ │
│ │                        │   'trainer': {                                  │ │
│ │                        │   │   'wandb_project': 'teacher_student',       │ │
│ │                        │   │   'experiment_name': 'teacher_model',       │ │
│ │                        │   │   'strategy': 'ddp',                        │ │
│ │                        │   │   'accelerator': 'gpu',                     │ │
│ │                        │   │   'precision': '16-mixed',                  │ │
│ │                        │   │   'max_epochs': 50,                         │ │
│ │                        │   │   'log_every_n_steps': 50,                  │ │
│ │                        │   │   'early_stopping': {                       │ │
│ │                        │   │   │   'enabled': True,                      │ │
│ │                        │   │   │   'patience': 10,                       │ │
│ │                        │   │   │   'monitor': 'val_loss',                │ │
│ │                        │   │   │   'mode': 'min'                         │ │
│ │                        │   │   },                                        │ │
│ │                        │   │   'checkpoint_callback': {                  │ │
│ │                        │   │   │   'monitor': 'val_loss',                │ │
│ │                        │   │   │   'mode': 'min',                        │ │
│ │                        │   │   │   'save_top_k': 1                       │ │
│ │                        │   │   }                                         │ │
│ │                        │   }                                             │ │
│ │                        }                                                 │ │
│ │    early_stop_params = {                                                 │ │
│ │                        │   'enabled': True,                              │ │
│ │                        │   'patience': 10,                               │ │
│ │                        │   'monitor': 'val_loss',                        │ │
│ │                        │   'mode': 'min'                                 │ │
│ │                        }                                                 │ │
│ │       early_stopping = <pytorch_lightning.callbacks.early_stopping.Earl… │ │
│ │                        object at 0x7f0a157a1e10>                         │ │
│ │      experiment_name = 'teacher_model'                                   │ │
│ │             mean_whu = [105.34253814, 114.2284708, 112.52936415]         │ │
│ │          num_workers = 16                                                │ │
│ │         project_name = 'teacher_student'                                 │ │
│ │              std_whu = [42.12451161, 39.52149692, 42.81161886]           │ │
│ │        teacher_model = TeacherUNetModel(                                 │ │
│ │                          (model): Unet(                                  │ │
│ │                        │   (encoder): ResNetEncoder(                     │ │
│ │                        │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),  │ │
│ │                        stride=(2, 2), padding=(3, 3), bias=False)        │ │
│ │                        │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │     (relu): ReLU(inplace=True)                  │ │
│ │                        │     (maxpool): MaxPool2d(kernel_size=3,         │ │
│ │                        stride=2, padding=1, dilation=1, ceil_mode=False) │ │
│ │                        │     (layer1): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(64, 64, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │     (bn2): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer2): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(64, 128,                │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(64, 128, kernel_size=(1,  │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(128, 128,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer3): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(128, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(128, 256, kernel_size=(1, │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (4): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (5): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(256, 256,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │     (layer4): Sequential(                       │ │
│ │                        │   │   (0): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(256, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(2, 2), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (downsample): Sequential(               │ │
│ │                        │   │   │   (0): Conv2d(256, 512, kernel_size=(1, │ │
│ │                        1), stride=(2, 2), bias=False)                    │ │
│ │                        │   │   │   (1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): BasicBlock(                          │ │
│ │                        │   │     (conv1): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn1): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │     (relu): ReLU(inplace=True)              │ │
│ │                        │   │     (conv2): Conv2d(512, 512,               │ │
│ │                        kernel_size=(3, 3), stride=(1, 1), padding=(1,    │ │
│ │                        1), bias=False)                                   │ │
│ │                        │   │     (bn2): BatchNorm2d(512, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                        │   (decoder): UnetDecoder(                       │ │
│ │                        │     (center): Identity()                        │ │
│ │                        │     (blocks): ModuleList(                       │ │
│ │                        │   │   (0): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(768, 256, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(256, 256, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(256, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (1): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(384, 128, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(128, 128, kernel_size=(3, │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(128, eps=1e-05,      │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (2): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(192, 64, kernel_size=(3,  │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(64, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (3): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(128, 32, kernel_size=(3,  │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(32, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(32, 32, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(32, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │   │   (4): DecoderBlock(                        │ │
│ │                        │   │     (conv1): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(32, 16, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(16, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention1): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (conv2): Conv2dReLU(                    │ │
│ │                        │   │   │   (0): Conv2d(16, 16, kernel_size=(3,   │ │
│ │                        3), stride=(1, 1), padding=(1, 1), bias=False)    │ │
│ │                        │   │   │   (1): BatchNorm2d(16, eps=1e-05,       │ │
│ │                        momentum=0.1, affine=True,                        │ │
│ │                        track_running_stats=True)                         │ │
│ │                        │   │   │   (2): ReLU(inplace=True)               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │     (attention2): Attention(                │ │
│ │                        │   │   │   (attention): Identity()               │ │
│ │                        │   │     )                                       │ │
│ │                        │   │   )                                         │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                        │   (segmentation_head): SegmentationHead(        │ │
│ │                        │     (0): Conv2d(16, 1, kernel_size=(3, 3),      │ │
│ │                        stride=(1, 1), padding=(1, 1))                    │ │
│ │                        │     (1): Identity()                             │ │
│ │                        │     (2): Activation(                            │ │
│ │                        │   │   (activation): Identity()                  │ │
│ │                        │     )                                           │ │
│ │                        │   )                                             │ │
│ │                          )                                               │ │
│ │                          (loss): BCEWithLogitsLoss()                     │ │
│ │                          (train_f1): BinaryF1Score()                     │ │
│ │                          (train_iou): BinaryJaccardIndex()               │ │
│ │                          (train_precision): BinaryPrecision()            │ │
│ │                          (train_recall): BinaryRecall()                  │ │
│ │                          (val_f1): BinaryF1Score()                       │ │
│ │                          (val_iou): BinaryJaccardIndex()                 │ │
│ │                          (val_precision): BinaryPrecision()              │ │
│ │                          (val_recall): BinaryRecall()                    │ │
│ │                          (test_f1): BinaryF1Score()                      │ │
│ │                          (test_iou): BinaryJaccardIndex()                │ │
│ │                          (test_precision): BinaryPrecision()             │ │
│ │                          (test_recall): BinaryRecall()                   │ │
│ │                        )                                                 │ │
│ │ teacher_wandb_logger = <pytorch_lightning.loggers.wandb.WandbLogger      │ │
│ │                        object at 0x7f0a157a0040>                         │ │
│ │              trainer = <pytorch_lightning.trainer.trainer.Trainer object │ │
│ │                        at 0x7f0a157a0dc0>                                │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:538 in fit                                 │
│                                                                              │
│    535 │   │   self.state.fn = TrainerFn.FITTING                             │
│    536 │   │   self.state.status = TrainerStatus.RUNNING                     │
│    537 │   │   self.training = True                                          │
│ ❱  538 │   │   call._call_and_handle_interrupt(                              │
│    539 │   │   │   self, self._fit_impl, model, train_dataloaders, val_datal │
│    540 │   │   )                                                             │
│    541                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         ckpt_path = None                                                 │ │
│ │        datamodule = None                                                 │ │
│ │             model = TeacherUNetModel(                                    │ │
│ │                       (model): Unet(                                     │ │
│ │                     │   (encoder): ResNetEncoder(                        │ │
│ │                     │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),     │ │
│ │                     stride=(2, 2), padding=(3, 3), bias=False)           │ │
│ │                     │     (bn1): BatchNorm2d(64, eps=1e-05,              │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │     (relu): ReLU(inplace=True)                     │ │
│ │                     │     (maxpool): MaxPool2d(kernel_size=3, stride=2,  │ │
│ │                     padding=1, dilation=1, ceil_mode=False)              │ │
│ │                     │     (layer1): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer2): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 128, kernel_size=(3,   │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), │ │
│ │                     stride=(2, 2), bias=False)                           │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer3): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 256, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(128, 256, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (5): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer4): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 512, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(256, 512, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (decoder): UnetDecoder(                          │ │
│ │                     │     (center): Identity()                           │ │
│ │                     │     (blocks): ModuleList(                          │ │
│ │                     │   │   (0): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(768, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(256, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(384, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (segmentation_head): SegmentationHead(           │ │
│ │                     │     (0): Conv2d(16, 1, kernel_size=(3, 3),         │ │
│ │                     stride=(1, 1), padding=(1, 1))                       │ │
│ │                     │     (1): Identity()                                │ │
│ │                     │     (2): Activation(                               │ │
│ │                     │   │   (activation): Identity()                     │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                       )                                                  │ │
│ │                       (loss): BCEWithLogitsLoss()                        │ │
│ │                       (train_f1): BinaryF1Score()                        │ │
│ │                       (train_iou): BinaryJaccardIndex()                  │ │
│ │                       (train_precision): BinaryPrecision()               │ │
│ │                       (train_recall): BinaryRecall()                     │ │
│ │                       (val_f1): BinaryF1Score()                          │ │
│ │                       (val_iou): BinaryJaccardIndex()                    │ │
│ │                       (val_precision): BinaryPrecision()                 │ │
│ │                       (val_recall): BinaryRecall()                       │ │
│ │                       (test_f1): BinaryF1Score()                         │ │
│ │                       (test_iou): BinaryJaccardIndex()                   │ │
│ │                       (test_precision): BinaryPrecision()                │ │
│ │                       (test_recall): BinaryRecall()                      │ │
│ │                     )                                                    │ │
│ │              self = <pytorch_lightning.trainer.trainer.Trainer object at │ │
│ │                     0x7f0a157a0dc0>                                      │ │
│ │ train_dataloaders = <dataloader.WHUDataModule object at 0x7f0a15126560>  │ │
│ │   val_dataloaders = None                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/call.py:46 in _call_and_handle_interrupt              │
│                                                                              │
│    43 │   """                                                                │
│    44 │   try:                                                               │
│    45 │   │   if trainer.strategy.launcher is not None:                      │
│ ❱  46 │   │   │   return trainer.strategy.launcher.launch(trainer_fn, *args, │
│    47 │   │   return trainer_fn(*args, **kwargs)                             │
│    48 │                                                                      │
│    49 │   except _TunerExitException:                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │       args = (                                                           │ │
│ │              │   TeacherUNetModel(                                       │ │
│ │                (model): Unet(                                            │ │
│ │              │   (encoder): ResNetEncoder(                               │ │
│ │              │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │              2), padding=(3, 3), bias=False)                             │ │
│ │              │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │     (relu): ReLU(inplace=True)                            │ │
│ │              │     (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │              padding=1, dilation=1, ceil_mode=False)                     │ │
│ │              │     (layer1): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer2): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer3): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (5): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer4): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (decoder): UnetDecoder(                                 │ │
│ │              │     (center): Identity()                                  │ │
│ │              │     (blocks): ModuleList(                                 │ │
│ │              │   │   (0): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (segmentation_head): SegmentationHead(                  │ │
│ │              │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │              padding=(1, 1))                                             │ │
│ │              │     (1): Identity()                                       │ │
│ │              │     (2): Activation(                                      │ │
│ │              │   │   (activation): Identity()                            │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │                )                                                         │ │
│ │                (loss): BCEWithLogitsLoss()                               │ │
│ │                (train_f1): BinaryF1Score()                               │ │
│ │                (train_iou): BinaryJaccardIndex()                         │ │
│ │                (train_precision): BinaryPrecision()                      │ │
│ │                (train_recall): BinaryRecall()                            │ │
│ │                (val_f1): BinaryF1Score()                                 │ │
│ │                (val_iou): BinaryJaccardIndex()                           │ │
│ │                (val_precision): BinaryPrecision()                        │ │
│ │                (val_recall): BinaryRecall()                              │ │
│ │                (test_f1): BinaryF1Score()                                │ │
│ │                (test_iou): BinaryJaccardIndex()                          │ │
│ │                (test_precision): BinaryPrecision()                       │ │
│ │                (test_recall): BinaryRecall()                             │ │
│ │              ),                                                          │ │
│ │              │   <dataloader.WHUDataModule object at 0x7f0a15126560>,    │ │
│ │              │   None,                                                   │ │
│ │              │   None,                                                   │ │
│ │              │   None                                                    │ │
│ │              )                                                           │ │
│ │     kwargs = {}                                                          │ │
│ │    trainer = <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7f0a157a0dc0>                                             │ │
│ │ trainer_fn = <bound method Trainer._fit_impl of                          │ │
│ │              <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7f0a157a0dc0>>                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/launchers/subprocess_script.py:105 in launch       │
│                                                                              │
│   102 │   │   │   _launch_process_observer(self.procs)                       │
│   103 │   │                                                                  │
│   104 │   │   _set_num_threads_if_needed(num_processes=self.num_processes)   │
│ ❱ 105 │   │   return function(*args, **kwargs)                               │
│   106 │                                                                      │
│   107 │   @override                                                          │
│   108 │   def kill(self, signum: _SIGNUM) -> None:                           │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │     args = (                                                             │ │
│ │            │   TeacherUNetModel(                                         │ │
│ │              (model): Unet(                                              │ │
│ │            │   (encoder): ResNetEncoder(                                 │ │
│ │            │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │            2), padding=(3, 3), bias=False)                               │ │
│ │            │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │     (relu): ReLU(inplace=True)                              │ │
│ │            │     (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │            padding=1, dilation=1, ceil_mode=False)                       │ │
│ │            │     (layer1): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer2): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer3): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (4): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (5): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │     (layer4): Sequential(                                   │ │
│ │            │   │   (0): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │            stride=(2, 2), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (downsample): Sequential(                           │ │
│ │            │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │            stride=(2, 2), bias=False)                                    │ │
│ │            │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): BasicBlock(                                      │ │
│ │            │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │     (relu): ReLU(inplace=True)                          │ │
│ │            │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (decoder): UnetDecoder(                                   │ │
│ │            │     (center): Identity()                                    │ │
│ │            │     (blocks): ModuleList(                                   │ │
│ │            │   │   (0): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (1): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (2): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (3): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │   │   (4): DecoderBlock(                                    │ │
│ │            │   │     (conv1): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention1): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (conv2): Conv2dReLU(                                │ │
│ │            │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │            stride=(1, 1), padding=(1, 1), bias=False)                    │ │
│ │            │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │            affine=True, track_running_stats=True)                        │ │
│ │            │   │   │   (2): ReLU(inplace=True)                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │     (attention2): Attention(                            │ │
│ │            │   │   │   (attention): Identity()                           │ │
│ │            │   │     )                                                   │ │
│ │            │   │   )                                                     │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │            │   (segmentation_head): SegmentationHead(                    │ │
│ │            │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │            padding=(1, 1))                                               │ │
│ │            │     (1): Identity()                                         │ │
│ │            │     (2): Activation(                                        │ │
│ │            │   │   (activation): Identity()                              │ │
│ │            │     )                                                       │ │
│ │            │   )                                                         │ │
│ │              )                                                           │ │
│ │              (loss): BCEWithLogitsLoss()                                 │ │
│ │              (train_f1): BinaryF1Score()                                 │ │
│ │              (train_iou): BinaryJaccardIndex()                           │ │
│ │              (train_precision): BinaryPrecision()                        │ │
│ │              (train_recall): BinaryRecall()                              │ │
│ │              (val_f1): BinaryF1Score()                                   │ │
│ │              (val_iou): BinaryJaccardIndex()                             │ │
│ │              (val_precision): BinaryPrecision()                          │ │
│ │              (val_recall): BinaryRecall()                                │ │
│ │              (test_f1): BinaryF1Score()                                  │ │
│ │              (test_iou): BinaryJaccardIndex()                            │ │
│ │              (test_precision): BinaryPrecision()                         │ │
│ │              (test_recall): BinaryRecall()                               │ │
│ │            ),                                                            │ │
│ │            │   <dataloader.WHUDataModule object at 0x7f0a15126560>,      │ │
│ │            │   None,                                                     │ │
│ │            │   None,                                                     │ │
│ │            │   None                                                      │ │
│ │            )                                                             │ │
│ │ function = <bound method Trainer._fit_impl of                            │ │
│ │            <pytorch_lightning.trainer.trainer.Trainer object at          │ │
│ │            0x7f0a157a0dc0>>                                              │ │
│ │   kwargs = {}                                                            │ │
│ │     self = <pytorch_lightning.strategies.launchers.subprocess_script._S… │ │
│ │            object at 0x7f0a157a2a70>                                     │ │
│ │  trainer = <pytorch_lightning.trainer.trainer.Trainer object at          │ │
│ │            0x7f0a157a0dc0>                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:574 in _fit_impl                           │
│                                                                              │
│    571 │   │   │   model_provided=True,                                      │
│    572 │   │   │   model_connected=self.lightning_module is not None,        │
│    573 │   │   )                                                             │
│ ❱  574 │   │   self._run(model, ckpt_path=ckpt_path)                         │
│    575 │   │                                                                 │
│    576 │   │   assert self.state.stopped                                     │
│    577 │   │   self.training = False                                         │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         ckpt_path = None                                                 │ │
│ │        datamodule = <dataloader.WHUDataModule object at 0x7f0a15126560>  │ │
│ │             model = TeacherUNetModel(                                    │ │
│ │                       (model): Unet(                                     │ │
│ │                     │   (encoder): ResNetEncoder(                        │ │
│ │                     │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),     │ │
│ │                     stride=(2, 2), padding=(3, 3), bias=False)           │ │
│ │                     │     (bn1): BatchNorm2d(64, eps=1e-05,              │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │     (relu): ReLU(inplace=True)                     │ │
│ │                     │     (maxpool): MaxPool2d(kernel_size=3, stride=2,  │ │
│ │                     padding=1, dilation=1, ceil_mode=False)              │ │
│ │                     │     (layer1): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(64, 64, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer2): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(64, 128, kernel_size=(3,   │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), │ │
│ │                     stride=(2, 2), bias=False)                           │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(128, 128, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer3): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(128, 256, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(128, 256, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (5): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(256, 256, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │     (layer4): Sequential(                          │ │
│ │                     │   │   (0): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(256, 512, kernel_size=(3,  │ │
│ │                     3), stride=(2, 2), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (downsample): Sequential(                  │ │
│ │                     │   │   │   (0): Conv2d(256, 512, kernel_size=(1,    │ │
│ │                     1), stride=(2, 2), bias=False)                       │ │
│ │                     │   │   │   (1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): BasicBlock(                             │ │
│ │                     │   │     (conv1): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn1): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │     (relu): ReLU(inplace=True)                 │ │
│ │                     │   │     (conv2): Conv2d(512, 512, kernel_size=(3,  │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │     (bn2): BatchNorm2d(512, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (decoder): UnetDecoder(                          │ │
│ │                     │     (center): Identity()                           │ │
│ │                     │     (blocks): ModuleList(                          │ │
│ │                     │   │   (0): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(768, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(256, 256, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(256, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (1): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(384, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 128, kernel_size=(3,    │ │
│ │                     3), stride=(1, 1), padding=(1, 1), bias=False)       │ │
│ │                     │   │   │   (1): BatchNorm2d(128, eps=1e-05,         │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (2): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(64, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (3): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(32, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │   │   (4): DecoderBlock(                           │ │
│ │                     │   │     (conv1): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention1): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (conv2): Conv2dReLU(                       │ │
│ │                     │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),  │ │
│ │                     stride=(1, 1), padding=(1, 1), bias=False)           │ │
│ │                     │   │   │   (1): BatchNorm2d(16, eps=1e-05,          │ │
│ │                     momentum=0.1, affine=True, track_running_stats=True) │ │
│ │                     │   │   │   (2): ReLU(inplace=True)                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │     (attention2): Attention(                   │ │
│ │                     │   │   │   (attention): Identity()                  │ │
│ │                     │   │     )                                          │ │
│ │                     │   │   )                                            │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                     │   (segmentation_head): SegmentationHead(           │ │
│ │                     │     (0): Conv2d(16, 1, kernel_size=(3, 3),         │ │
│ │                     stride=(1, 1), padding=(1, 1))                       │ │
│ │                     │     (1): Identity()                                │ │
│ │                     │     (2): Activation(                               │ │
│ │                     │   │   (activation): Identity()                     │ │
│ │                     │     )                                              │ │
│ │                     │   )                                                │ │
│ │                       )                                                  │ │
│ │                       (loss): BCEWithLogitsLoss()                        │ │
│ │                       (train_f1): BinaryF1Score()                        │ │
│ │                       (train_iou): BinaryJaccardIndex()                  │ │
│ │                       (train_precision): BinaryPrecision()               │ │
│ │                       (train_recall): BinaryRecall()                     │ │
│ │                       (val_f1): BinaryF1Score()                          │ │
│ │                       (val_iou): BinaryJaccardIndex()                    │ │
│ │                       (val_precision): BinaryPrecision()                 │ │
│ │                       (val_recall): BinaryRecall()                       │ │
│ │                       (test_f1): BinaryF1Score()                         │ │
│ │                       (test_iou): BinaryJaccardIndex()                   │ │
│ │                       (test_precision): BinaryPrecision()                │ │
│ │                       (test_recall): BinaryRecall()                      │ │
│ │                     )                                                    │ │
│ │              self = <pytorch_lightning.trainer.trainer.Trainer object at │ │
│ │                     0x7f0a157a0dc0>                                      │ │
│ │ train_dataloaders = None                                                 │ │
│ │   val_dataloaders = None                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:981 in _run                                │
│                                                                              │
│    978 │   │   # ----------------------------                                │
│    979 │   │   # RUN THE TRAINER                                             │
│    980 │   │   # ----------------------------                                │
│ ❱  981 │   │   results = self._run_stage()                                   │
│    982 │   │                                                                 │
│    983 │   │   # ----------------------------                                │
│    984 │   │   # POST-Training CLEAN UP                                      │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │  ckpt_path = None                                                        │ │
│ │ max_epochs = 50                                                          │ │
│ │ min_epochs = 0                                                           │ │
│ │      model = TeacherUNetModel(                                           │ │
│ │                (model): Unet(                                            │ │
│ │              │   (encoder): ResNetEncoder(                               │ │
│ │              │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, │ │
│ │              2), padding=(3, 3), bias=False)                             │ │
│ │              │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │     (relu): ReLU(inplace=True)                            │ │
│ │              │     (maxpool): MaxPool2d(kernel_size=3, stride=2,         │ │
│ │              padding=1, dilation=1, ceil_mode=False)                     │ │
│ │              │     (layer1): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer2): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),      │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),        │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer3): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (5): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │     (layer4): Sequential(                                 │ │
│ │              │   │   (0): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),     │ │
│ │              stride=(2, 2), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (downsample): Sequential(                         │ │
│ │              │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),       │ │
│ │              stride=(2, 2), bias=False)                                  │ │
│ │              │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): BasicBlock(                                    │ │
│ │              │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │     (relu): ReLU(inplace=True)                        │ │
│ │              │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),     │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (decoder): UnetDecoder(                                 │ │
│ │              │     (center): Identity()                                  │ │
│ │              │     (blocks): ModuleList(                                 │ │
│ │              │   │   (0): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (1): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,  │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (2): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (3): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),        │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │   │   (4): DecoderBlock(                                  │ │
│ │              │   │     (conv1): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention1): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (conv2): Conv2dReLU(                              │ │
│ │              │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),         │ │
│ │              stride=(1, 1), padding=(1, 1), bias=False)                  │ │
│ │              │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,   │ │
│ │              affine=True, track_running_stats=True)                      │ │
│ │              │   │   │   (2): ReLU(inplace=True)                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │     (attention2): Attention(                          │ │
│ │              │   │   │   (attention): Identity()                         │ │
│ │              │   │     )                                                 │ │
│ │              │   │   )                                                   │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │              │   (segmentation_head): SegmentationHead(                  │ │
│ │              │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), │ │
│ │              padding=(1, 1))                                             │ │
│ │              │     (1): Identity()                                       │ │
│ │              │     (2): Activation(                                      │ │
│ │              │   │   (activation): Identity()                            │ │
│ │              │     )                                                     │ │
│ │              │   )                                                       │ │
│ │                )                                                         │ │
│ │                (loss): BCEWithLogitsLoss()                               │ │
│ │                (train_f1): BinaryF1Score()                               │ │
│ │                (train_iou): BinaryJaccardIndex()                         │ │
│ │                (train_precision): BinaryPrecision()                      │ │
│ │                (train_recall): BinaryRecall()                            │ │
│ │                (val_f1): BinaryF1Score()                                 │ │
│ │                (val_iou): BinaryJaccardIndex()                           │ │
│ │                (val_precision): BinaryPrecision()                        │ │
│ │                (val_recall): BinaryRecall()                              │ │
│ │                (test_f1): BinaryF1Score()                                │ │
│ │                (test_iou): BinaryJaccardIndex()                          │ │
│ │                (test_precision): BinaryPrecision()                       │ │
│ │                (test_recall): BinaryRecall()                             │ │
│ │              )                                                           │ │
│ │       self = <pytorch_lightning.trainer.trainer.Trainer object at        │ │
│ │              0x7f0a157a0dc0>                                             │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:1023 in _run_stage                         │
│                                                                              │
│   1020 │   │   │   return self.predict_loop.run()                            │
│   1021 │   │   if self.training:                                             │
│   1022 │   │   │   with isolate_rng():                                       │
│ ❱ 1023 │   │   │   │   self._run_sanity_check()                              │
│   1024 │   │   │   with torch.autograd.set_detect_anomaly(self._detect_anoma │
│   1025 │   │   │   │   self.fit_loop.run()                                   │
│   1026 │   │   │   return None                                               │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ self = <pytorch_lightning.trainer.trainer.Trainer object at              │ │
│ │        0x7f0a157a0dc0>                                                   │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/trainer.py:1052 in _run_sanity_check                  │
│                                                                              │
│   1049 │   │   │   call._call_callback_hooks(self, "on_sanity_check_start")  │
│   1050 │   │   │                                                             │
│   1051 │   │   │   # run eval step                                           │
│ ❱ 1052 │   │   │   val_loop.run()                                            │
│   1053 │   │   │                                                             │
│   1054 │   │   │   call._call_callback_hooks(self, "on_sanity_check_end")    │
│   1055                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                self = <pytorch_lightning.trainer.trainer.Trainer object  │ │
│ │                       at 0x7f0a157a0dc0>                                 │ │
│ │ should_sanity_check = True                                               │ │
│ │               stage = <RunningStage.TRAINING: 'train'>                   │ │
│ │            val_loop = <pytorch_lightning.loops.evaluation_loop._Evaluat… │ │
│ │                       object at 0x7f0a157a16c0>                          │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/utilities.py:178 in _decorator                          │
│                                                                              │
│   175 │   │   else:                                                          │
│   176 │   │   │   context_manager = torch.no_grad                            │
│   177 │   │   with context_manager():                                        │
│ ❱ 178 │   │   │   return loop_run(self, *args, **kwargs)                     │
│   179 │                                                                      │
│   180 │   return _decorator                                                  │
│   181                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │            args = ()                                                     │ │
│ │ context_manager = <class 'torch.autograd.grad_mode.no_grad'>             │ │
│ │          kwargs = {}                                                     │ │
│ │        loop_run = <function _EvaluationLoop.run at 0x7f0a31713e20>       │ │
│ │            self = <pytorch_lightning.loops.evaluation_loop._EvaluationL… │ │
│ │                   object at 0x7f0a157a16c0>                              │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/evaluation_loop.py:135 in run                           │
│                                                                              │
│   132 │   │   │   │   previous_dataloader_idx = dataloader_idx               │
│   133 │   │   │   │   self.batch_progress.is_last_batch = data_fetcher.done  │
│   134 │   │   │   │   # run step hooks                                       │
│ ❱ 135 │   │   │   │   self._evaluation_step(batch, batch_idx, dataloader_idx │
│   136 │   │   │   except StopIteration:                                      │
│   137 │   │   │   │   # this needs to wrap the `*_step` call too (not just ` │
│   138 │   │   │   │   break                                                  │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                   batch = [                                              │ │
│ │                           │   tensor([[[[ 2.3164,  2.3446,  2.3149,      │ │
│ │                           ..., -0.6058, -0.6181, -0.7150],               │ │
│ │                           │   │     [ 1.4268,  1.3023,  1.1477,  ...,    │ │
│ │                           -0.3876, -0.7470, -1.0972],                    │ │
│ │                           │   │     [ 0.0779, -0.0593,  0.0045,  ...,    │ │
│ │                           -0.7834, -1.3672, -1.4232],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.6139, -0.5378, -0.6376,  ...,    │ │
│ │                           0.7786,  0.8201,  0.9101],                     │ │
│ │                           │   │     [-0.5613, -0.4577, -0.6747,  ...,    │ │
│ │                           0.7601,  0.7934,  0.8617],                     │ │
│ │                           │   │     [-0.3507, -0.2922, -0.4185,  ...,    │ │
│ │                           0.7168,  0.8312,  0.9036]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 2.0406,  2.0645,  2.0510,  ...,    │ │
│ │                           -0.4332, -0.3903, -0.5082],                    │ │
│ │                           │   │     [ 1.1315,  1.0024,  0.8545,  ...,    │ │
│ │                           -0.1651, -0.5269, -0.9126],                    │ │
│ │                           │   │     [ 0.0182, -0.1264,  0.0231,  ...,    │ │
│ │                           -0.6886, -1.3571, -1.3879],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2281, -0.1932, -0.2900,  ...,    │ │
│ │                           0.4864,  0.5149,  0.6028],                     │ │
│ │                           │   │     [-0.1770, -0.0489, -0.2525,  ...,    │ │
│ │                           0.4758,  0.5133,  0.5956],                     │ │
│ │                           │   │     [ 0.0319,  0.1804,  0.0335,  ...,    │ │
│ │                           0.4438,  0.5766,  0.6924]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.8773,  1.9022,  1.8847,  ...,    │ │
│ │                           -0.4057, -0.4887, -0.5277],                    │ │
│ │                           │   │     [ 0.9649,  0.8121,  0.6603,  ...,    │ │
│ │                           -0.1638, -0.5726, -0.8895],                    │ │
│ │                           │   │     [ 0.0210, -0.0865,  0.0234,  ...,    │ │
│ │                           -0.5850, -1.2241, -1.2979],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.4361, -0.4343, -0.5230,  ...,    │ │
│ │                           0.4143,  0.4844,  0.5816],                     │ │
│ │                           │   │     [-0.2906, -0.2463, -0.5730,  ...,    │ │
│ │                           0.4011,  0.4917,  0.5691],                     │ │
│ │                           │   │     [ 0.0091,  0.0706, -0.2163,  ...,    │ │
│ │                           0.3680,  0.5424,  0.6669]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,    │ │
│ │                           -0.2612, -0.4125, -0.2770],                    │ │
│ │                           │   │     [ 0.6888,  0.5887,  0.5071,  ...,    │ │
│ │                           -0.1710, -0.2637, -0.5444],                    │ │
│ │                           │   │     [ 1.1148,  0.1169, -0.1676,  ...,    │ │
│ │                           0.1911,  0.3721, -0.2837],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.4486, -0.5441, -0.9948,  ...,    │ │
│ │                           1.4529,  1.5731,  1.6655],                     │ │
│ │                           │   │     [-0.8471, -0.8097, -0.5052,  ...,    │ │
│ │                           1.6699,  1.6633,  1.5620],                     │ │
│ │                           │   │     [-1.2547, -0.6262, -0.1167,  ...,    │ │
│ │                           2.0572,  1.8766,  1.8721]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 0.3655,  0.4483,  0.3462,  ...,    │ │
│ │                           0.0064, -0.0699,  0.0557],                     │ │
│ │                           │   │     [ 0.4605,  0.3635,  0.2722,  ...,    │ │
│ │                           0.0618,  0.0547, -0.1675],                     │ │
│ │                           │   │     [ 0.9666,  0.1626, -0.0085,  ...,    │ │
│ │                           0.3880,  0.6220,  0.0236],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2760, -0.2201, -0.7969,  ...,    │ │
│ │                           1.5642,  1.7006,  1.7636],                     │ │
│ │                           │   │     [-0.9533, -0.6040, -0.2027,  ...,    │ │
│ │                           1.7120,  1.7452,  1.6086],                     │ │
│ │                           │   │     [-1.4558, -0.4432,  0.2369,  ...,    │ │
│ │                           1.9949,  1.9005,  1.8320]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 0.2965,  0.3601,  0.3009,  ...,    │ │
│ │                           0.0602, -0.1504, -0.0534],                     │ │
│ │                           │   │     [ 0.4160,  0.2953,  0.2230,  ...,    │ │
│ │                           0.1778, -0.0084, -0.3465],                     │ │
│ │                           │   │     [ 0.9099,  0.0840, -0.1021,  ...,    │ │
│ │                           0.5869,  0.6836, -0.0941],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.3519, -0.4613, -0.9606,  ...,    │ │
│ │                           1.4837,  1.5997,  1.6536],                     │ │
│ │                           │   │     [-0.8312, -0.7609, -0.3011,  ...,    │ │
│ │                           1.6274,  1.6373,  1.4997],                     │ │
│ │                           │   │     [-1.3824, -0.5392,  0.2546,  ...,    │ │
│ │                           1.8659,  1.7704,  1.7204]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,    │ │
│ │                           0.5743,  0.6527,  0.1973],                     │ │
│ │                           │   │     [-0.1900,  0.1981,  0.3613,  ...,    │ │
│ │                           -0.4840, -0.7741, -0.6588],                    │ │
│ │                           │   │     [-0.4079, -0.5727, -0.7945,  ...,    │ │
│ │                           -0.9792, -0.8624, -0.8335],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5236, -1.5460, -1.5493,  ...,    │ │
│ │                           0.8791,  1.3495,  1.2763],                     │ │
│ │                           │   │     [-1.5478, -1.5571, -0.9722,  ...,    │ │
│ │                           1.0991,  1.2270,  1.1958],                     │ │
│ │                           │   │     [-1.5594, -1.5262, -1.3078,  ...,    │ │
│ │                           1.2170,  1.2479,  1.2777]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.2511,  2.0410,  2.2335,  ...,    │ │
│ │                           0.4876,  0.6290,  0.2545],                     │ │
│ │                           │   │     [-0.3203,  0.2990,  0.5133,  ...,    │ │
│ │                           -0.1165, -0.2367, -0.0257],                    │ │
│ │                           │   │     [-0.1477, -0.1331, -0.3114,  ...,    │ │
│ │                           -0.7581, -0.6202, -0.5923],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.8475, -1.8564, -1.9051,  ...,    │ │
│ │                           1.0213,  1.5171,  1.4460],                     │ │
│ │                           │   │     [-1.8560, -1.8576, -1.2073,  ...,    │ │
│ │                           1.4468,  1.5998,  1.5811],                     │ │
│ │                           │   │     [-1.9128, -1.8755, -1.5804,  ...,    │ │
│ │                           1.6565,  1.6719,  1.6993]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[ 1.3119,  1.9435,  2.1157,  ...,    │ │
│ │                           0.4802,  0.4811,  0.0363],                     │ │
│ │                           │   │     [-0.1179,  0.2318,  0.3654,  ...,    │ │
│ │                           -0.1602, -0.5587, -0.5162],                    │ │
│ │                           │   │     [-0.1421, -0.2981, -0.5722,  ...,    │ │
│ │                           -0.8887, -0.8376, -0.8337],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.7000, -1.7201, -1.7387,  ...,    │ │
│ │                           1.3972,  1.9169,  1.9397],                     │ │
│ │                           │   │     [-1.7279, -1.7529, -1.1157,  ...,    │ │
│ │                           2.0661,  2.2213,  2.2087],                     │ │
│ │                           │   │     [-1.7323, -1.6954, -1.4618,  ...,    │ │
│ │                           2.2354,  2.2530,  2.2691]]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   ...,                                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-1.0599, -1.0722, -0.8373,  ...,    │ │
│ │                           -0.8042, -0.7623, -0.7780],                    │ │
│ │                           │   │     [-1.0798, -0.9996, -1.0004,  ...,    │ │
│ │                           -0.8416, -0.7748, -0.8144],                    │ │
│ │                           │   │     [-0.8928, -0.8869, -0.8661,  ...,    │ │
│ │                           -0.7878, -0.9039, -0.9166],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.8657, -0.9139, -0.9354,  ...,    │ │
│ │                           -0.7860, -0.6917, -0.2532],                    │ │
│ │                           │   │     [-0.9836, -1.0682, -1.0412,  ...,    │ │
│ │                           -0.5871, -0.4002, -0.4672],                    │ │
│ │                           │   │     [-0.9863, -1.0090, -1.0853,  ...,    │ │
│ │                           -0.6160, -0.5219, -0.7189]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.6332, -0.7097, -0.4215,  ...,    │ │
│ │                           -0.1901, -0.1644, -0.2325],                    │ │
│ │                           │   │     [-0.6487, -0.6316, -0.5818,  ...,    │ │
│ │                           -0.2829, -0.2394, -0.3049],                    │ │
│ │                           │   │     [-0.3767, -0.4395, -0.4375,  ...,    │ │
│ │                           -0.2110, -0.4470, -0.5231],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.2565, -0.2205, -0.2220,  ...,    │ │
│ │                           -0.3818, -0.3438,  0.1731],                    │ │
│ │                           │   │     [-0.4657, -0.5518, -0.5182,  ...,    │ │
│ │                           -0.2438, -0.0176, -0.0727],                    │ │
│ │                           │   │     [-0.3987, -0.4983, -0.6036,  ...,    │ │
│ │                           -0.3505, -0.2082, -0.3332]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.0878, -1.1527, -0.9100,  ...,    │ │
│ │                           -0.7169, -0.7085, -0.7336],                    │ │
│ │                           │   │     [-1.1135, -1.0810, -1.0489,  ...,    │ │
│ │                           -0.7306, -0.6846, -0.7594],                    │ │
│ │                           │   │     [-0.9125, -0.9624, -0.9069,  ...,    │ │
│ │                           -0.6095, -0.7978, -0.8245],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.7285, -0.7857, -0.7854,  ...,    │ │
│ │                           -0.7182, -0.6215,  0.1228],                    │ │
│ │                           │   │     [-0.9004, -1.0222, -0.9365,  ...,    │ │
│ │                           -0.4408, -0.2605, -0.2418],                    │ │
│ │                           │   │     [-0.8313, -0.9434, -0.9788,  ...,    │ │
│ │                           -0.4678, -0.4024, -0.5858]]],                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-0.7077, -0.4473, -0.6266,  ...,    │ │
│ │                           -0.7038, -0.6567, -0.7818],                    │ │
│ │                           │   │     [-0.8280, -0.4161, -0.5953,  ...,    │ │
│ │                           -0.8468, -0.4521, -0.5808],                    │ │
│ │                           │   │     [-0.5753, -0.5170, -0.6090,  ...,    │ │
│ │                           -0.7919, -0.5200, -0.4384],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-0.1959, -0.6135, -0.5363,  ...,    │ │
│ │                           -1.3624, -0.8494, -0.1735],                    │ │
│ │                           │   │     [-0.4295, -0.6888, -0.4310,  ...,    │ │
│ │                           -0.3587, -0.2537, -0.3986],                    │ │
│ │                           │   │     [-0.5943, -0.6783, -0.7139,  ...,    │ │
│ │                           -0.3507, -0.4791, -0.6006]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.2072,  0.0127, -0.1702,  ...,    │ │
│ │                           -0.3419, -0.2687, -0.4003],                    │ │
│ │                           │   │     [-0.3858,  0.0282, -0.1687,  ...,    │ │
│ │                           -0.4790, -0.0354, -0.1698],                    │ │
│ │                           │   │     [-0.2005, -0.1149, -0.1699,  ...,    │ │
│ │                           -0.3153,  0.0203,  0.0299],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [ 0.1754, -0.2889, -0.1054,  ...,    │ │
│ │                           -1.4425, -0.7123,  0.3566],                    │ │
│ │                           │   │     [-0.1350, -0.4375, -0.0643,  ...,    │ │
│ │                           0.0931,  0.2030,  0.0399],                     │ │
│ │                           │   │     [-0.3228, -0.4490, -0.4441,  ...,    │ │
│ │                           0.1140, -0.0388, -0.1875]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-0.6597, -0.3586, -0.4449,  ...,    │ │
│ │                           -0.6856, -0.6522, -0.7503],                    │ │
│ │                           │   │     [-0.7248, -0.2678, -0.3945,  ...,    │ │
│ │                           -0.8226, -0.4105, -0.5004],                    │ │
│ │                           │   │     [-0.2626, -0.1671, -0.3766,  ...,    │ │
│ │                           -0.6941, -0.3854, -0.3569],                    │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [ 0.2934, -0.4135, -0.2755,  ...,    │ │
│ │                           -1.2591, -0.5653,  0.2921],                    │ │
│ │                           │   │     [-0.1146, -0.5248, -0.1897,  ...,    │ │
│ │                           0.0059,  0.1336, -0.1004],                     │ │
│ │                           │   │     [-0.4185, -0.6055, -0.5559,  ...,    │ │
│ │                           -0.0995, -0.2689, -0.3513]]],                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[-1.3826, -1.5758, -1.3897,  ...,    │ │
│ │                           1.1593,  1.1517,  1.0863],                     │ │
│ │                           │   │     [-1.4554, -1.4403, -1.1914,  ...,    │ │
│ │                           1.1762,  1.1228,  1.1525],                     │ │
│ │                           │   │     [-1.4418, -1.2993, -1.0208,  ...,    │ │
│ │                           1.3535,  1.1681,  1.1589],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5414, -0.6903, -0.7511,  ...,    │ │
│ │                           -0.5200, -0.5756, -0.5779],                    │ │
│ │                           │   │     [-1.5643, -0.7541, -0.6268,  ...,    │ │
│ │                           -0.5044, -0.6458, -0.6436],                    │ │
│ │                           │   │     [-1.4533, -0.6317, -0.1612,  ...,    │ │
│ │                           -0.3613, -0.7063, -0.7261]],                   │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.3448, -1.5791, -1.2935,  ...,    │ │
│ │                           0.5572,  0.5726,  0.5173],                     │ │
│ │                           │   │     [-1.4295, -1.4998, -1.0167,  ...,    │ │
│ │                           0.5924,  0.5592,  0.5988],                     │ │
│ │                           │   │     [-1.3550, -1.2938, -1.0301,  ...,    │ │
│ │                           0.7972,  0.6153,  0.6056],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.7982, -0.8752, -0.6012,  ...,    │ │
│ │                           -0.0912, -0.1196, -0.1621],                    │ │
│ │                           │   │     [-1.8009, -0.8427, -0.3782,  ...,    │ │
│ │                           -0.0841, -0.1920, -0.2276],                    │ │
│ │                           │   │     [-1.6954, -0.7387, -0.0568,  ...,    │ │
│ │                           0.0218, -0.2507, -0.3032]],                    │ │
│ │                           │   │                                          │ │
│ │                           │   │    [[-1.4091, -1.6641, -1.4289,  ...,    │ │
│ │                           0.2938,  0.2579,  0.1735],                     │ │
│ │                           │   │     [-1.4810, -1.5788, -1.2095,  ...,    │ │
│ │                           0.2887,  0.2026,  0.2187],                     │ │
│ │                           │   │     [-1.4501, -1.4066, -1.1120,  ...,    │ │
│ │                           0.4428,  0.2340,  0.2250],                     │ │
│ │                           │   │     ...,                                 │ │
│ │                           │   │     [-1.5457, -0.7003, -0.6430,  ...,    │ │
│ │                           -0.3908, -0.4467, -0.4766],                    │ │
│ │                           │   │     [-1.6041, -0.7394, -0.4135,  ...,    │ │
│ │                           -0.3832, -0.5244, -0.5442],                    │ │
│ │                           │   │     [-1.5440, -0.6222, -0.0975,  ...,    │ │
│ │                           -0.2572, -0.5930, -0.6154]]]]),                │ │
│ │                           │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,  │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.]]]],                                │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.]]]],                                │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   ...,                                   │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]],                                  │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │                                          │ │
│ │                           │   │   [[[[  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      [  0.,   0.,   0.,  ..., 255.,      │ │
│ │                           255., 255.],                                   │ │
│ │                           │   │      ...,                                │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.],                                     │ │
│ │                           │   │      [  0.,   0.,   0.,  ...,   0.,      │ │
│ │                           0.,   0.]]]]])                                 │ │
│ │                           ]                                              │ │
│ │               batch_idx = 0                                              │ │
│ │            data_fetcher = <pytorch_lightning.loops.fetchers._PrefetchDa… │ │
│ │                           object at 0x7f0a1331e0b0>                      │ │
│ │          dataloader_idx = 0                                              │ │
│ │         dataloader_iter = None                                           │ │
│ │ previous_dataloader_idx = 0                                              │ │
│ │                    self = <pytorch_lightning.loops.evaluation_loop._Eva… │ │
│ │                           object at 0x7f0a157a16c0>                      │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/loops/evaluation_loop.py:396 in _evaluation_step              │
│                                                                              │
│   393 │   │   │   if not using_dataloader_iter                               │
│   394 │   │   │   else (dataloader_iter,)                                    │
│   395 │   │   )                                                              │
│ ❱ 396 │   │   output = call._call_strategy_hook(trainer, hook_name, *step_ar │
│   397 │   │                                                                  │
│   398 │   │   self.batch_progress.increment_processed()                      │
│   399                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │                 batch = [                                                │ │
│ │                         │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,  │ │
│ │                         -0.6058, -0.6181, -0.7150],                      │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0'),                         │ │
│ │                         │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,    │ │
│ │                         0.,   0.],                                       │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')                        │ │
│ │                         ]                                                │ │
│ │             batch_idx = 0                                                │ │
│ │          data_fetcher = <pytorch_lightning.loops.fetchers._PrefetchData… │ │
│ │                         object at 0x7f0a1331e0b0>                        │ │
│ │        dataloader_idx = 0                                                │ │
│ │       dataloader_iter = None                                             │ │
│ │           hook_kwargs = OrderedDict([('batch', [tensor([[[[ 2.3164,      │ │
│ │                         2.3446,  2.3149,  ..., -0.6058, -0.6181,         │ │
│ │                         -0.7150],                                        │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0'), tensor([[[[[  0.,   0., │ │
│ │                         0.,  ...,   0.,   0.,   0.],                     │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')]), ('batch_idx', 0)])  │ │
│ │             hook_name = 'validation_step'                                │ │
│ │                  self = <pytorch_lightning.loops.evaluation_loop._Evalu… │ │
│ │                         object at 0x7f0a157a16c0>                        │ │
│ │             step_args = (                                                │ │
│ │                         │   [                                            │ │
│ │                         │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,    │ │
│ │                         ..., -0.6058, -0.6181, -0.7150],                 │ │
│ │                         │   │     [ 1.4268,  1.3023,  1.1477,  ...,      │ │
│ │                         -0.3876, -0.7470, -1.0972],                      │ │
│ │                         │   │     [ 0.0779, -0.0593,  0.0045,  ...,      │ │
│ │                         -0.7834, -1.3672, -1.4232],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.6139, -0.5378, -0.6376,  ...,      │ │
│ │                         0.7786,  0.8201,  0.9101],                       │ │
│ │                         │   │     [-0.5613, -0.4577, -0.6747,  ...,      │ │
│ │                         0.7601,  0.7934,  0.8617],                       │ │
│ │                         │   │     [-0.3507, -0.2922, -0.4185,  ...,      │ │
│ │                         0.7168,  0.8312,  0.9036]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 2.0406,  2.0645,  2.0510,  ...,      │ │
│ │                         -0.4332, -0.3903, -0.5082],                      │ │
│ │                         │   │     [ 1.1315,  1.0024,  0.8545,  ...,      │ │
│ │                         -0.1651, -0.5269, -0.9126],                      │ │
│ │                         │   │     [ 0.0182, -0.1264,  0.0231,  ...,      │ │
│ │                         -0.6886, -1.3571, -1.3879],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2281, -0.1932, -0.2900,  ...,      │ │
│ │                         0.4864,  0.5149,  0.6028],                       │ │
│ │                         │   │     [-0.1770, -0.0489, -0.2525,  ...,      │ │
│ │                         0.4758,  0.5133,  0.5956],                       │ │
│ │                         │   │     [ 0.0319,  0.1804,  0.0335,  ...,      │ │
│ │                         0.4438,  0.5766,  0.6924]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.8773,  1.9022,  1.8847,  ...,      │ │
│ │                         -0.4057, -0.4887, -0.5277],                      │ │
│ │                         │   │     [ 0.9649,  0.8121,  0.6603,  ...,      │ │
│ │                         -0.1638, -0.5726, -0.8895],                      │ │
│ │                         │   │     [ 0.0210, -0.0865,  0.0234,  ...,      │ │
│ │                         -0.5850, -1.2241, -1.2979],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4361, -0.4343, -0.5230,  ...,      │ │
│ │                         0.4143,  0.4844,  0.5816],                       │ │
│ │                         │   │     [-0.2906, -0.2463, -0.5730,  ...,      │ │
│ │                         0.4011,  0.4917,  0.5691],                       │ │
│ │                         │   │     [ 0.0091,  0.0706, -0.2163,  ...,      │ │
│ │                         0.3680,  0.5424,  0.6669]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 0.6236,  0.7028,  0.6188,  ...,      │ │
│ │                         -0.2612, -0.4125, -0.2770],                      │ │
│ │                         │   │     [ 0.6888,  0.5887,  0.5071,  ...,      │ │
│ │                         -0.1710, -0.2637, -0.5444],                      │ │
│ │                         │   │     [ 1.1148,  0.1169, -0.1676,  ...,      │ │
│ │                         0.1911,  0.3721, -0.2837],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.4486, -0.5441, -0.9948,  ...,      │ │
│ │                         1.4529,  1.5731,  1.6655],                       │ │
│ │                         │   │     [-0.8471, -0.8097, -0.5052,  ...,      │ │
│ │                         1.6699,  1.6633,  1.5620],                       │ │
│ │                         │   │     [-1.2547, -0.6262, -0.1167,  ...,      │ │
│ │                         2.0572,  1.8766,  1.8721]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.3655,  0.4483,  0.3462,  ...,      │ │
│ │                         0.0064, -0.0699,  0.0557],                       │ │
│ │                         │   │     [ 0.4605,  0.3635,  0.2722,  ...,      │ │
│ │                         0.0618,  0.0547, -0.1675],                       │ │
│ │                         │   │     [ 0.9666,  0.1626, -0.0085,  ...,      │ │
│ │                         0.3880,  0.6220,  0.0236],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2760, -0.2201, -0.7969,  ...,      │ │
│ │                         1.5642,  1.7006,  1.7636],                       │ │
│ │                         │   │     [-0.9533, -0.6040, -0.2027,  ...,      │ │
│ │                         1.7120,  1.7452,  1.6086],                       │ │
│ │                         │   │     [-1.4558, -0.4432,  0.2369,  ...,      │ │
│ │                         1.9949,  1.9005,  1.8320]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 0.2965,  0.3601,  0.3009,  ...,      │ │
│ │                         0.0602, -0.1504, -0.0534],                       │ │
│ │                         │   │     [ 0.4160,  0.2953,  0.2230,  ...,      │ │
│ │                         0.1778, -0.0084, -0.3465],                       │ │
│ │                         │   │     [ 0.9099,  0.0840, -0.1021,  ...,      │ │
│ │                         0.5869,  0.6836, -0.0941],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.3519, -0.4613, -0.9606,  ...,      │ │
│ │                         1.4837,  1.5997,  1.6536],                       │ │
│ │                         │   │     [-0.8312, -0.7609, -0.3011,  ...,      │ │
│ │                         1.6274,  1.6373,  1.4997],                       │ │
│ │                         │   │     [-1.3824, -0.5392,  0.2546,  ...,      │ │
│ │                         1.8659,  1.7704,  1.7204]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,      │ │
│ │                         0.5743,  0.6527,  0.1973],                       │ │
│ │                         │   │     [-0.1900,  0.1981,  0.3613,  ...,      │ │
│ │                         -0.4840, -0.7741, -0.6588],                      │ │
│ │                         │   │     [-0.4079, -0.5727, -0.7945,  ...,      │ │
│ │                         -0.9792, -0.8624, -0.8335],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5236, -1.5460, -1.5493,  ...,      │ │
│ │                         0.8791,  1.3495,  1.2763],                       │ │
│ │                         │   │     [-1.5478, -1.5571, -0.9722,  ...,      │ │
│ │                         1.0991,  1.2270,  1.1958],                       │ │
│ │                         │   │     [-1.5594, -1.5262, -1.3078,  ...,      │ │
│ │                         1.2170,  1.2479,  1.2777]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.2511,  2.0410,  2.2335,  ...,      │ │
│ │                         0.4876,  0.6290,  0.2545],                       │ │
│ │                         │   │     [-0.3203,  0.2990,  0.5133,  ...,      │ │
│ │                         -0.1165, -0.2367, -0.0257],                      │ │
│ │                         │   │     [-0.1477, -0.1331, -0.3114,  ...,      │ │
│ │                         -0.7581, -0.6202, -0.5923],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.8475, -1.8564, -1.9051,  ...,      │ │
│ │                         1.0213,  1.5171,  1.4460],                       │ │
│ │                         │   │     [-1.8560, -1.8576, -1.2073,  ...,      │ │
│ │                         1.4468,  1.5998,  1.5811],                       │ │
│ │                         │   │     [-1.9128, -1.8755, -1.5804,  ...,      │ │
│ │                         1.6565,  1.6719,  1.6993]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[ 1.3119,  1.9435,  2.1157,  ...,      │ │
│ │                         0.4802,  0.4811,  0.0363],                       │ │
│ │                         │   │     [-0.1179,  0.2318,  0.3654,  ...,      │ │
│ │                         -0.1602, -0.5587, -0.5162],                      │ │
│ │                         │   │     [-0.1421, -0.2981, -0.5722,  ...,      │ │
│ │                         -0.8887, -0.8376, -0.8337],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7000, -1.7201, -1.7387,  ...,      │ │
│ │                         1.3972,  1.9169,  1.9397],                       │ │
│ │                         │   │     [-1.7279, -1.7529, -1.1157,  ...,      │ │
│ │                         2.0661,  2.2213,  2.2087],                       │ │
│ │                         │   │     [-1.7323, -1.6954, -1.4618,  ...,      │ │
│ │                         2.2354,  2.2530,  2.2691]]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.0599, -1.0722, -0.8373,  ...,      │ │
│ │                         -0.8042, -0.7623, -0.7780],                      │ │
│ │                         │   │     [-1.0798, -0.9996, -1.0004,  ...,      │ │
│ │                         -0.8416, -0.7748, -0.8144],                      │ │
│ │                         │   │     [-0.8928, -0.8869, -0.8661,  ...,      │ │
│ │                         -0.7878, -0.9039, -0.9166],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.8657, -0.9139, -0.9354,  ...,      │ │
│ │                         -0.7860, -0.6917, -0.2532],                      │ │
│ │                         │   │     [-0.9836, -1.0682, -1.0412,  ...,      │ │
│ │                         -0.5871, -0.4002, -0.4672],                      │ │
│ │                         │   │     [-0.9863, -1.0090, -1.0853,  ...,      │ │
│ │                         -0.6160, -0.5219, -0.7189]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6332, -0.7097, -0.4215,  ...,      │ │
│ │                         -0.1901, -0.1644, -0.2325],                      │ │
│ │                         │   │     [-0.6487, -0.6316, -0.5818,  ...,      │ │
│ │                         -0.2829, -0.2394, -0.3049],                      │ │
│ │                         │   │     [-0.3767, -0.4395, -0.4375,  ...,      │ │
│ │                         -0.2110, -0.4470, -0.5231],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.2565, -0.2205, -0.2220,  ...,      │ │
│ │                         -0.3818, -0.3438,  0.1731],                      │ │
│ │                         │   │     [-0.4657, -0.5518, -0.5182,  ...,      │ │
│ │                         -0.2438, -0.0176, -0.0727],                      │ │
│ │                         │   │     [-0.3987, -0.4983, -0.6036,  ...,      │ │
│ │                         -0.3505, -0.2082, -0.3332]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.0878, -1.1527, -0.9100,  ...,      │ │
│ │                         -0.7169, -0.7085, -0.7336],                      │ │
│ │                         │   │     [-1.1135, -1.0810, -1.0489,  ...,      │ │
│ │                         -0.7306, -0.6846, -0.7594],                      │ │
│ │                         │   │     [-0.9125, -0.9624, -0.9069,  ...,      │ │
│ │                         -0.6095, -0.7978, -0.8245],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.7285, -0.7857, -0.7854,  ...,      │ │
│ │                         -0.7182, -0.6215,  0.1228],                      │ │
│ │                         │   │     [-0.9004, -1.0222, -0.9365,  ...,      │ │
│ │                         -0.4408, -0.2605, -0.2418],                      │ │
│ │                         │   │     [-0.8313, -0.9434, -0.9788,  ...,      │ │
│ │                         -0.4678, -0.4024, -0.5858]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-0.7077, -0.4473, -0.6266,  ...,      │ │
│ │                         -0.7038, -0.6567, -0.7818],                      │ │
│ │                         │   │     [-0.8280, -0.4161, -0.5953,  ...,      │ │
│ │                         -0.8468, -0.4521, -0.5808],                      │ │
│ │                         │   │     [-0.5753, -0.5170, -0.6090,  ...,      │ │
│ │                         -0.7919, -0.5200, -0.4384],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-0.1959, -0.6135, -0.5363,  ...,      │ │
│ │                         -1.3624, -0.8494, -0.1735],                      │ │
│ │                         │   │     [-0.4295, -0.6888, -0.4310,  ...,      │ │
│ │                         -0.3587, -0.2537, -0.3986],                      │ │
│ │                         │   │     [-0.5943, -0.6783, -0.7139,  ...,      │ │
│ │                         -0.3507, -0.4791, -0.6006]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.2072,  0.0127, -0.1702,  ...,      │ │
│ │                         -0.3419, -0.2687, -0.4003],                      │ │
│ │                         │   │     [-0.3858,  0.0282, -0.1687,  ...,      │ │
│ │                         -0.4790, -0.0354, -0.1698],                      │ │
│ │                         │   │     [-0.2005, -0.1149, -0.1699,  ...,      │ │
│ │                         -0.3153,  0.0203,  0.0299],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.1754, -0.2889, -0.1054,  ...,      │ │
│ │                         -1.4425, -0.7123,  0.3566],                      │ │
│ │                         │   │     [-0.1350, -0.4375, -0.0643,  ...,      │ │
│ │                         0.0931,  0.2030,  0.0399],                       │ │
│ │                         │   │     [-0.3228, -0.4490, -0.4441,  ...,      │ │
│ │                         0.1140, -0.0388, -0.1875]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-0.6597, -0.3586, -0.4449,  ...,      │ │
│ │                         -0.6856, -0.6522, -0.7503],                      │ │
│ │                         │   │     [-0.7248, -0.2678, -0.3945,  ...,      │ │
│ │                         -0.8226, -0.4105, -0.5004],                      │ │
│ │                         │   │     [-0.2626, -0.1671, -0.3766,  ...,      │ │
│ │                         -0.6941, -0.3854, -0.3569],                      │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [ 0.2934, -0.4135, -0.2755,  ...,      │ │
│ │                         -1.2591, -0.5653,  0.2921],                      │ │
│ │                         │   │     [-0.1146, -0.5248, -0.1897,  ...,      │ │
│ │                         0.0059,  0.1336, -0.1004],                       │ │
│ │                         │   │     [-0.4185, -0.6055, -0.5559,  ...,      │ │
│ │                         -0.0995, -0.2689, -0.3513]]],                    │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[-1.3826, -1.5758, -1.3897,  ...,      │ │
│ │                         1.1593,  1.1517,  1.0863],                       │ │
│ │                         │   │     [-1.4554, -1.4403, -1.1914,  ...,      │ │
│ │                         1.1762,  1.1228,  1.1525],                       │ │
│ │                         │   │     [-1.4418, -1.2993, -1.0208,  ...,      │ │
│ │                         1.3535,  1.1681,  1.1589],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5414, -0.6903, -0.7511,  ...,      │ │
│ │                         -0.5200, -0.5756, -0.5779],                      │ │
│ │                         │   │     [-1.5643, -0.7541, -0.6268,  ...,      │ │
│ │                         -0.5044, -0.6458, -0.6436],                      │ │
│ │                         │   │     [-1.4533, -0.6317, -0.1612,  ...,      │ │
│ │                         -0.3613, -0.7063, -0.7261]],                     │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.3448, -1.5791, -1.2935,  ...,      │ │
│ │                         0.5572,  0.5726,  0.5173],                       │ │
│ │                         │   │     [-1.4295, -1.4998, -1.0167,  ...,      │ │
│ │                         0.5924,  0.5592,  0.5988],                       │ │
│ │                         │   │     [-1.3550, -1.2938, -1.0301,  ...,      │ │
│ │                         0.7972,  0.6153,  0.6056],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.7982, -0.8752, -0.6012,  ...,      │ │
│ │                         -0.0912, -0.1196, -0.1621],                      │ │
│ │                         │   │     [-1.8009, -0.8427, -0.3782,  ...,      │ │
│ │                         -0.0841, -0.1920, -0.2276],                      │ │
│ │                         │   │     [-1.6954, -0.7387, -0.0568,  ...,      │ │
│ │                         0.0218, -0.2507, -0.3032]],                      │ │
│ │                         │   │                                            │ │
│ │                         │   │    [[-1.4091, -1.6641, -1.4289,  ...,      │ │
│ │                         0.2938,  0.2579,  0.1735],                       │ │
│ │                         │   │     [-1.4810, -1.5788, -1.2095,  ...,      │ │
│ │                         0.2887,  0.2026,  0.2187],                       │ │
│ │                         │   │     [-1.4501, -1.4066, -1.1120,  ...,      │ │
│ │                         0.4428,  0.2340,  0.2250],                       │ │
│ │                         │   │     ...,                                   │ │
│ │                         │   │     [-1.5457, -0.7003, -0.6430,  ...,      │ │
│ │                         -0.3908, -0.4467, -0.4766],                      │ │
│ │                         │   │     [-1.6041, -0.7394, -0.4135,  ...,      │ │
│ │                         -0.3832, -0.5244, -0.5442],                      │ │
│ │                         │   │     [-1.5440, -0.6222, -0.0975,  ...,      │ │
│ │                         -0.2572, -0.5930, -0.6154]]]],                   │ │
│ │                         │      device='cuda:0'),                         │ │
│ │                         │   │   tensor([[[[[  0.,   0.,   0.,  ...,      │ │
│ │                         0.,   0.,   0.],                                 │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.]]]],                                        │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   ...,                                     │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]],                                          │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │                                            │ │
│ │                         │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      [  0.,   0.,   0.,  ..., 255., 255.,  │ │
│ │                         255.],                                           │ │
│ │                         │   │      ...,                                  │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.],                                             │ │
│ │                         │   │      [  0.,   0.,   0.,  ...,   0.,   0.,  │ │
│ │                         0.]]]]], device='cuda:0')                        │ │
│ │                         │   ],                                           │ │
│ │                         │   0                                            │ │
│ │                         )                                                │ │
│ │               trainer = <pytorch_lightning.trainer.trainer.Trainer       │ │
│ │                         object at 0x7f0a157a0dc0>                        │ │
│ │ using_dataloader_iter = False                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/trainer/call.py:319 in _call_strategy_hook                    │
│                                                                              │
│   316 │   │   return None                                                    │
│   317 │                                                                      │
│   318 │   with trainer.profiler.profile(f"[Strategy]{trainer.strategy.__clas │
│ ❱ 319 │   │   output = fn(*args, **kwargs)                                   │
│   320 │                                                                      │
│   321 │   # restore current_fx when nested context                           │
│   322 │   pl_module._current_fx_name = prev_fx_name                          │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0'),                                  │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │           fn = <bound method Strategy.validation_step of                 │ │
│ │                <pytorch_lightning.strategies.ddp.DDPStrategy object at   │ │
│ │                0x7f0a157a03d0>>                                          │ │
│ │    hook_name = 'validation_step'                                         │ │
│ │       kwargs = {}                                                        │ │
│ │    pl_module = TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )                                                         │ │
│ │ prev_fx_name = None                                                      │ │
│ │      trainer = <pytorch_lightning.trainer.trainer.Trainer object at      │ │
│ │                0x7f0a157a0dc0>                                           │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:410 in validation_step                 │
│                                                                              │
│   407 │   │   assert self.model is not None                                  │
│   408 │   │   with self.precision_plugin.val_step_context():                 │
│   409 │   │   │   if self.model != self.lightning_module:                    │
│ ❱ 410 │   │   │   │   return self._forward_redirection(self.model, self.ligh │
│   411 │   │   │   return self.lightning_module.validation_step(*args, **kwar │
│   412 │                                                                      │
│   413 │   def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT:     │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0'),                                        │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = <pytorch_lightning.strategies.ddp.DDPStrategy object at         │ │
│ │          0x7f0a157a03d0>                                                 │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:640 in __call__                        │
│                                                                              │
│   637 │   │   # Patch the original_module's forward so we can redirect the a │
│   638 │   │   original_module.forward = wrapped_forward  # type: ignore[meth │
│   639 │   │                                                                  │
│ ❱ 640 │   │   wrapper_output = wrapper_module(*args, **kwargs)               │
│   641 │   │   self.on_after_outer_forward(wrapper_module, original_module)   │
│   642 │   │   return wrapper_output                                          │
│   643                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │             args = (                                                     │ │
│ │                    │   [                                                 │ │
│ │                    │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,   │ │
│ │                    -0.6058, -0.6181, -0.7150],                           │ │
│ │                    │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,  │ │
│ │                    -0.7470, -1.0972],                                    │ │
│ │                    │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,  │ │
│ │                    -1.3672, -1.4232],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  │ │
│ │                    0.8201,  0.9101],                                     │ │
│ │                    │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  │ │
│ │                    0.7934,  0.8617],                                     │ │
│ │                    │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  │ │
│ │                    0.8312,  0.9036]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,  │ │
│ │                    -0.3903, -0.5082],                                    │ │
│ │                    │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,  │ │
│ │                    -0.5269, -0.9126],                                    │ │
│ │                    │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,  │ │
│ │                    -1.3571, -1.3879],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  │ │
│ │                    0.5149,  0.6028],                                     │ │
│ │                    │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  │ │
│ │                    0.5133,  0.5956],                                     │ │
│ │                    │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  │ │
│ │                    0.5766,  0.6924]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,  │ │
│ │                    -0.4887, -0.5277],                                    │ │
│ │                    │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,  │ │
│ │                    -0.5726, -0.8895],                                    │ │
│ │                    │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,  │ │
│ │                    -1.2241, -1.2979],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  │ │
│ │                    0.4844,  0.5816],                                     │ │
│ │                    │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  │ │
│ │                    0.4917,  0.5691],                                     │ │
│ │                    │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  │ │
│ │                    0.5424,  0.6669]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,  │ │
│ │                    -0.4125, -0.2770],                                    │ │
│ │                    │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,  │ │
│ │                    -0.2637, -0.5444],                                    │ │
│ │                    │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  │ │
│ │                    0.3721, -0.2837],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  │ │
│ │                    1.5731,  1.6655],                                     │ │
│ │                    │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  │ │
│ │                    1.6633,  1.5620],                                     │ │
│ │                    │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  │ │
│ │                    1.8766,  1.8721]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,  │ │
│ │                    -0.0699,  0.0557],                                    │ │
│ │                    │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  │ │
│ │                    0.0547, -0.1675],                                     │ │
│ │                    │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  │ │
│ │                    0.6220,  0.0236],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  │ │
│ │                    1.7006,  1.7636],                                     │ │
│ │                    │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  │ │
│ │                    1.7452,  1.6086],                                     │ │
│ │                    │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  │ │
│ │                    1.9005,  1.8320]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,  │ │
│ │                    -0.1504, -0.0534],                                    │ │
│ │                    │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,  │ │
│ │                    -0.0084, -0.3465],                                    │ │
│ │                    │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  │ │
│ │                    0.6836, -0.0941],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  │ │
│ │                    1.5997,  1.6536],                                     │ │
│ │                    │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  │ │
│ │                    1.6373,  1.4997],                                     │ │
│ │                    │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  │ │
│ │                    1.7704,  1.7204]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  │ │
│ │                    0.6527,  0.1973],                                     │ │
│ │                    │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,  │ │
│ │                    -0.7741, -0.6588],                                    │ │
│ │                    │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,  │ │
│ │                    -0.8624, -0.8335],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  │ │
│ │                    1.3495,  1.2763],                                     │ │
│ │                    │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  │ │
│ │                    1.2270,  1.1958],                                     │ │
│ │                    │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  │ │
│ │                    1.2479,  1.2777]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  │ │
│ │                    0.6290,  0.2545],                                     │ │
│ │                    │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,  │ │
│ │                    -0.2367, -0.0257],                                    │ │
│ │                    │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,  │ │
│ │                    -0.6202, -0.5923],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  │ │
│ │                    1.5171,  1.4460],                                     │ │
│ │                    │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  │ │
│ │                    1.5998,  1.5811],                                     │ │
│ │                    │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  │ │
│ │                    1.6719,  1.6993]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  │ │
│ │                    0.4811,  0.0363],                                     │ │
│ │                    │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,  │ │
│ │                    -0.5587, -0.5162],                                    │ │
│ │                    │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,  │ │
│ │                    -0.8376, -0.8337],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  │ │
│ │                    1.9169,  1.9397],                                     │ │
│ │                    │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  │ │
│ │                    2.2213,  2.2087],                                     │ │
│ │                    │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  │ │
│ │                    2.2530,  2.2691]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,  │ │
│ │                    -0.7623, -0.7780],                                    │ │
│ │                    │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,  │ │
│ │                    -0.7748, -0.8144],                                    │ │
│ │                    │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,  │ │
│ │                    -0.9039, -0.9166],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,  │ │
│ │                    -0.6917, -0.2532],                                    │ │
│ │                    │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,  │ │
│ │                    -0.4002, -0.4672],                                    │ │
│ │                    │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,  │ │
│ │                    -0.5219, -0.7189]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,  │ │
│ │                    -0.1644, -0.2325],                                    │ │
│ │                    │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,  │ │
│ │                    -0.2394, -0.3049],                                    │ │
│ │                    │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,  │ │
│ │                    -0.4470, -0.5231],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,  │ │
│ │                    -0.3438,  0.1731],                                    │ │
│ │                    │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,  │ │
│ │                    -0.0176, -0.0727],                                    │ │
│ │                    │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,  │ │
│ │                    -0.2082, -0.3332]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,  │ │
│ │                    -0.7085, -0.7336],                                    │ │
│ │                    │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,  │ │
│ │                    -0.6846, -0.7594],                                    │ │
│ │                    │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,  │ │
│ │                    -0.7978, -0.8245],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,  │ │
│ │                    -0.6215,  0.1228],                                    │ │
│ │                    │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,  │ │
│ │                    -0.2605, -0.2418],                                    │ │
│ │                    │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,  │ │
│ │                    -0.4024, -0.5858]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,  │ │
│ │                    -0.6567, -0.7818],                                    │ │
│ │                    │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,  │ │
│ │                    -0.4521, -0.5808],                                    │ │
│ │                    │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,  │ │
│ │                    -0.5200, -0.4384],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,  │ │
│ │                    -0.8494, -0.1735],                                    │ │
│ │                    │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,  │ │
│ │                    -0.2537, -0.3986],                                    │ │
│ │                    │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,  │ │
│ │                    -0.4791, -0.6006]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,  │ │
│ │                    -0.2687, -0.4003],                                    │ │
│ │                    │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,  │ │
│ │                    -0.0354, -0.1698],                                    │ │
│ │                    │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  │ │
│ │                    0.0203,  0.0299],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,  │ │
│ │                    -0.7123,  0.3566],                                    │ │
│ │                    │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  │ │
│ │                    0.2030,  0.0399],                                     │ │
│ │                    │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,  │ │
│ │                    -0.0388, -0.1875]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,  │ │
│ │                    -0.6522, -0.7503],                                    │ │
│ │                    │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,  │ │
│ │                    -0.4105, -0.5004],                                    │ │
│ │                    │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,  │ │
│ │                    -0.3854, -0.3569],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,  │ │
│ │                    -0.5653,  0.2921],                                    │ │
│ │                    │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  │ │
│ │                    0.1336, -0.1004],                                     │ │
│ │                    │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,  │ │
│ │                    -0.2689, -0.3513]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  │ │
│ │                    1.1517,  1.0863],                                     │ │
│ │                    │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  │ │
│ │                    1.1228,  1.1525],                                     │ │
│ │                    │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  │ │
│ │                    1.1681,  1.1589],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,  │ │
│ │                    -0.5756, -0.5779],                                    │ │
│ │                    │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,  │ │
│ │                    -0.6458, -0.6436],                                    │ │
│ │                    │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,  │ │
│ │                    -0.7063, -0.7261]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  │ │
│ │                    0.5726,  0.5173],                                     │ │
│ │                    │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  │ │
│ │                    0.5592,  0.5988],                                     │ │
│ │                    │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  │ │
│ │                    0.6153,  0.6056],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,  │ │
│ │                    -0.1196, -0.1621],                                    │ │
│ │                    │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,  │ │
│ │                    -0.1920, -0.2276],                                    │ │
│ │                    │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,  │ │
│ │                    -0.2507, -0.3032]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  │ │
│ │                    0.2579,  0.1735],                                     │ │
│ │                    │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  │ │
│ │                    0.2026,  0.2187],                                     │ │
│ │                    │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  │ │
│ │                    0.2340,  0.2250],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,  │ │
│ │                    -0.4467, -0.4766],                                    │ │
│ │                    │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,  │ │
│ │                    -0.5244, -0.5442],                                    │ │
│ │                    │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,  │ │
│ │                    -0.5930, -0.6154]]]],                                 │ │
│ │                    │      device='cuda:0'),                              │ │
│ │                    │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,     │ │
│ │                    0.,   0.],                                            │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]]], device='cuda:0')                             │ │
│ │                    │   ],                                                │ │
│ │                    │   0                                                 │ │
│ │                    )                                                     │ │
│ │           kwargs = {}                                                    │ │
│ │      method_name = 'validation_step'                                     │ │
│ │ original_forward = <bound method TeacherUNetModel.forward of             │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │  original_module = TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )                                                     │ │
│ │             self = <pytorch_lightning.strategies.ddp._DDPForwardRedirec… │ │
│ │                    object at 0x7f0a157a06a0>                             │ │
│ │  wrapped_forward = <function                                             │ │
│ │                    _ForwardRedirection.__call__.<locals>.wrapped_forward │ │
│ │                    at 0x7f0a1338edd0>                                    │ │
│ │   wrapper_module = DistributedDataParallel(                              │ │
│ │                      (module): TeacherUNetModel(                         │ │
│ │                    │   (model): Unet(                                    │ │
│ │                    │     (encoder): ResNetEncoder(                       │ │
│ │                    │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),    │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   (relu): ReLU(inplace=True)                    │ │
│ │                    │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2, │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │   │   (layer1): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer2): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3,  │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(64, 128, kernel_size=(1,    │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer3): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(128, 256, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (5): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer4): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(256, 512, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (decoder): UnetDecoder(                         │ │
│ │                    │   │   (center): Identity()                          │ │
│ │                    │   │   (blocks): ModuleList(                         │ │
│ │                    │   │     (0): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(768, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(384, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(192, 64, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 32, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (segmentation_head): SegmentationHead(          │ │
│ │                    │   │   (0): Conv2d(16, 1, kernel_size=(3, 3),        │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │   │   (1): Identity()                               │ │
│ │                    │   │   (2): Activation(                              │ │
│ │                    │   │     (activation): Identity()                    │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (loss): BCEWithLogitsLoss()                       │ │
│ │                    │   (train_f1): BinaryF1Score()                       │ │
│ │                    │   (train_iou): BinaryJaccardIndex()                 │ │
│ │                    │   (train_precision): BinaryPrecision()              │ │
│ │                    │   (train_recall): BinaryRecall()                    │ │
│ │                    │   (val_f1): BinaryF1Score()                         │ │
│ │                    │   (val_iou): BinaryJaccardIndex()                   │ │
│ │                    │   (val_precision): BinaryPrecision()                │ │
│ │                    │   (val_recall): BinaryRecall()                      │ │
│ │                    │   (test_f1): BinaryF1Score()                        │ │
│ │                    │   (test_iou): BinaryJaccardIndex()                  │ │
│ │                    │   (test_precision): BinaryPrecision()               │ │
│ │                    │   (test_recall): BinaryRecall()                     │ │
│ │                      )                                                   │ │
│ │                    )                                                     │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0'),                                        │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0'),                                  │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method DistributedDataParallel.forward of          │ │
│ │                DistributedDataParallel(                                  │ │
│ │                  (module): TeacherUNetModel(                             │ │
│ │                │   (model): Unet(                                        │ │
│ │                │     (encoder): ResNetEncoder(                           │ │
│ │                │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),        │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,     │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   │   (layer1): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer2): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),  │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),    │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer3): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (5): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer4): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (decoder): UnetDecoder(                             │ │
│ │                │   │   (center): Identity()                              │ │
│ │                │   │   (blocks): ModuleList(                             │ │
│ │                │   │     (0): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (segmentation_head): SegmentationHead(              │ │
│ │                │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │   │   (1): Identity()                                   │ │
│ │                │   │   (2): Activation(                                  │ │
│ │                │   │     (activation): Identity()                        │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (loss): BCEWithLogitsLoss()                           │ │
│ │                │   (train_f1): BinaryF1Score()                           │ │
│ │                │   (train_iou): BinaryJaccardIndex()                     │ │
│ │                │   (train_precision): BinaryPrecision()                  │ │
│ │                │   (train_recall): BinaryRecall()                        │ │
│ │                │   (val_f1): BinaryF1Score()                             │ │
│ │                │   (val_iou): BinaryJaccardIndex()                       │ │
│ │                │   (val_precision): BinaryPrecision()                    │ │
│ │                │   (val_recall): BinaryRecall()                          │ │
│ │                │   (test_f1): BinaryF1Score()                            │ │
│ │                │   (test_iou): BinaryJaccardIndex()                      │ │
│ │                │   (test_precision): BinaryPrecision()                   │ │
│ │                │   (test_recall): BinaryRecall()                         │ │
│ │                  )                                                       │ │
│ │                )>                                                        │ │
│ │       kwargs = {}                                                        │ │
│ │         self = DistributedDataParallel(                                  │ │
│ │                  (module): TeacherUNetModel(                             │ │
│ │                │   (model): Unet(                                        │ │
│ │                │     (encoder): ResNetEncoder(                           │ │
│ │                │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),        │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,   │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   (relu): ReLU(inplace=True)                        │ │
│ │                │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,     │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │   │   (layer1): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer2): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),  │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),    │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer3): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (5): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (layer4): Sequential(                             │ │
│ │                │   │     (0): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3), │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (downsample): Sequential(                     │ │
│ │                │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),   │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │     (1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): BasicBlock(                                │ │
│ │                │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (relu): ReLU(inplace=True)                    │ │
│ │                │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3), │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (decoder): UnetDecoder(                             │ │
│ │                │   │   (center): Identity()                              │ │
│ │                │   │   (blocks): ModuleList(                             │ │
│ │                │   │     (0): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(256, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (1): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(128, eps=1e-05,            │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (2): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (3): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),    │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(32, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │     (4): DecoderBlock(                              │ │
│ │                │   │   │   (conv1): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention1): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (conv2): Conv2dReLU(                          │ │
│ │                │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │     (1): BatchNorm2d(16, eps=1e-05,             │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │     (2): ReLU(inplace=True)                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │   │   (attention2): Attention(                      │ │
│ │                │   │   │     (attention): Identity()                     │ │
│ │                │   │   │   )                                             │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (segmentation_head): SegmentationHead(              │ │
│ │                │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │   │   (1): Identity()                                   │ │
│ │                │   │   (2): Activation(                                  │ │
│ │                │   │     (activation): Identity()                        │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (loss): BCEWithLogitsLoss()                           │ │
│ │                │   (train_f1): BinaryF1Score()                           │ │
│ │                │   (train_iou): BinaryJaccardIndex()                     │ │
│ │                │   (train_precision): BinaryPrecision()                  │ │
│ │                │   (train_recall): BinaryRecall()                        │ │
│ │                │   (val_f1): BinaryF1Score()                             │ │
│ │                │   (val_iou): BinaryJaccardIndex()                       │ │
│ │                │   (val_precision): BinaryPrecision()                    │ │
│ │                │   (val_recall): BinaryRecall()                          │ │
│ │                │   (test_f1): BinaryF1Score()                            │ │
│ │                │   (test_iou): BinaryJaccardIndex()                      │ │
│ │                │   (test_precision): BinaryPrecision()                   │ │
│ │                │   (test_recall): BinaryRecall()                         │ │
│ │                  )                                                       │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/parallel/distributed.py:1523 in forward                                │
│                                                                              │
│   1520 │   │   │   output = (                                                │
│   1521 │   │   │   │   self.module.forward(*inputs, **kwargs)                │
│   1522 │   │   │   │   if self._delay_all_reduce_all_params                  │
│ ❱ 1523 │   │   │   │   else self._run_ddp_forward(*inputs, **kwargs)         │
│   1524 │   │   │   )                                                         │
│   1525 │   │   │   return self._post_forward(output)                         │
│   1526                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ inputs = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0'),                                        │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/parallel/distributed.py:1359 in _run_ddp_forward                       │
│                                                                              │
│   1356 │                                                                     │
│   1357 │   def _run_ddp_forward(self, *inputs, **kwargs):                    │
│   1358 │   │   with self._inside_ddp_forward():                              │
│ ❱ 1359 │   │   │   return self.module(*inputs, **kwargs)  # type: ignore[ind │
│   1360 │                                                                     │
│   1361 │   def _clear_grad_buffer(self):                                     │
│   1362 │   │   # Making param.grad points to the grad buffers before backwar │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │ inputs = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0'),                                        │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = DistributedDataParallel(                                        │ │
│ │            (module): TeacherUNetModel(                                   │ │
│ │          │   (model): Unet(                                              │ │
│ │          │     (encoder): ResNetEncoder(                                 │ │
│ │          │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,   │ │
│ │          2), padding=(3, 3), bias=False)                                 │ │
│ │          │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,         │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   (relu): ReLU(inplace=True)                              │ │
│ │          │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2,           │ │
│ │          padding=1, dilation=1, ceil_mode=False)                         │ │
│ │          │   │   (layer1): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer2): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3, 3),        │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(64, 128, kernel_size=(1, 1),          │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer3): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(128, 256, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (5): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (layer4): Sequential(                                   │ │
│ │          │   │     (0): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, 3),       │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (downsample): Sequential(                           │ │
│ │          │   │   │     (0): Conv2d(256, 512, kernel_size=(1, 1),         │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): BasicBlock(                                      │ │
│ │          │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (relu): ReLU(inplace=True)                          │ │
│ │          │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, 3),       │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (decoder): UnetDecoder(                                   │ │
│ │          │   │   (center): Identity()                                    │ │
│ │          │   │   (blocks): ModuleList(                                   │ │
│ │          │   │     (0): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(768, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (1): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(384, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,    │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (2): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(192, 64, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (3): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(128, 32, kernel_size=(3, 3),          │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (4): DecoderBlock(                                    │ │
│ │          │   │   │   (conv1): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention1): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (conv2): Conv2dReLU(                                │ │
│ │          │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,     │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │     (2): ReLU(inplace=True)                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │   │   (attention2): Attention(                            │ │
│ │          │   │   │     (attention): Identity()                           │ │
│ │          │   │   │   )                                                   │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (segmentation_head): SegmentationHead(                    │ │
│ │          │   │   (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),   │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │   │   (1): Identity()                                         │ │
│ │          │   │   (2): Activation(                                        │ │
│ │          │   │     (activation): Identity()                              │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (loss): BCEWithLogitsLoss()                                 │ │
│ │          │   (train_f1): BinaryF1Score()                                 │ │
│ │          │   (train_iou): BinaryJaccardIndex()                           │ │
│ │          │   (train_precision): BinaryPrecision()                        │ │
│ │          │   (train_recall): BinaryRecall()                              │ │
│ │          │   (val_f1): BinaryF1Score()                                   │ │
│ │          │   (val_iou): BinaryJaccardIndex()                             │ │
│ │          │   (val_precision): BinaryPrecision()                          │ │
│ │          │   (val_recall): BinaryRecall()                                │ │
│ │          │   (test_f1): BinaryF1Score()                                  │ │
│ │          │   (test_iou): BinaryJaccardIndex()                            │ │
│ │          │   (test_precision): BinaryPrecision()                         │ │
│ │          │   (test_recall): BinaryRecall()                               │ │
│ │            )                                                             │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   [                                                           │ │
│ │          │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,    │ │
│ │          -0.6181, -0.7150],                                              │ │
│ │          │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876, -0.7470,   │ │
│ │          -1.0972],                                                       │ │
│ │          │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834, -1.3672,   │ │
│ │          -1.4232],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  0.8201,   │ │
│ │          0.9101],                                                        │ │
│ │          │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  0.7934,   │ │
│ │          0.8617],                                                        │ │
│ │          │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  0.8312,   │ │
│ │          0.9036]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332, -0.3903,   │ │
│ │          -0.5082],                                                       │ │
│ │          │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651, -0.5269,   │ │
│ │          -0.9126],                                                       │ │
│ │          │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886, -1.3571,   │ │
│ │          -1.3879],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  0.5149,   │ │
│ │          0.6028],                                                        │ │
│ │          │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  0.5133,   │ │
│ │          0.5956],                                                        │ │
│ │          │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  0.5766,   │ │
│ │          0.6924]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057, -0.4887,   │ │
│ │          -0.5277],                                                       │ │
│ │          │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638, -0.5726,   │ │
│ │          -0.8895],                                                       │ │
│ │          │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850, -1.2241,   │ │
│ │          -1.2979],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  0.4844,   │ │
│ │          0.5816],                                                        │ │
│ │          │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  0.4917,   │ │
│ │          0.5691],                                                        │ │
│ │          │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  0.5424,   │ │
│ │          0.6669]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612, -0.4125,   │ │
│ │          -0.2770],                                                       │ │
│ │          │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710, -0.2637,   │ │
│ │          -0.5444],                                                       │ │
│ │          │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  0.3721,   │ │
│ │          -0.2837],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  1.5731,   │ │
│ │          1.6655],                                                        │ │
│ │          │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  1.6633,   │ │
│ │          1.5620],                                                        │ │
│ │          │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  1.8766,   │ │
│ │          1.8721]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064, -0.0699,   │ │
│ │          0.0557],                                                        │ │
│ │          │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  0.0547,   │ │
│ │          -0.1675],                                                       │ │
│ │          │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  0.6220,   │ │
│ │          0.0236],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  1.7006,   │ │
│ │          1.7636],                                                        │ │
│ │          │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  1.7452,   │ │
│ │          1.6086],                                                        │ │
│ │          │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  1.9005,   │ │
│ │          1.8320]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602, -0.1504,   │ │
│ │          -0.0534],                                                       │ │
│ │          │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778, -0.0084,   │ │
│ │          -0.3465],                                                       │ │
│ │          │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  0.6836,   │ │
│ │          -0.0941],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  1.5997,   │ │
│ │          1.6536],                                                        │ │
│ │          │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  1.6373,   │ │
│ │          1.4997],                                                        │ │
│ │          │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  1.7704,   │ │
│ │          1.7204]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  0.6527,   │ │
│ │          0.1973],                                                        │ │
│ │          │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840, -0.7741,   │ │
│ │          -0.6588],                                                       │ │
│ │          │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792, -0.8624,   │ │
│ │          -0.8335],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  1.3495,   │ │
│ │          1.2763],                                                        │ │
│ │          │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  1.2270,   │ │
│ │          1.1958],                                                        │ │
│ │          │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  1.2479,   │ │
│ │          1.2777]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  0.6290,   │ │
│ │          0.2545],                                                        │ │
│ │          │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165, -0.2367,   │ │
│ │          -0.0257],                                                       │ │
│ │          │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581, -0.6202,   │ │
│ │          -0.5923],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  1.5171,   │ │
│ │          1.4460],                                                        │ │
│ │          │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  1.5998,   │ │
│ │          1.5811],                                                        │ │
│ │          │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  1.6719,   │ │
│ │          1.6993]],                                                       │ │
│ │          │   │                                                           │ │
│ │          │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  0.4811,   │ │
│ │          0.0363],                                                        │ │
│ │          │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602, -0.5587,   │ │
│ │          -0.5162],                                                       │ │
│ │          │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887, -0.8376,   │ │
│ │          -0.8337],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  1.9169,   │ │
│ │          1.9397],                                                        │ │
│ │          │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  2.2213,   │ │
│ │          2.2087],                                                        │ │
│ │          │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  2.2530,   │ │
│ │          2.2691]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042, -0.7623,   │ │
│ │          -0.7780],                                                       │ │
│ │          │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416, -0.7748,   │ │
│ │          -0.8144],                                                       │ │
│ │          │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878, -0.9039,   │ │
│ │          -0.9166],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860, -0.6917,   │ │
│ │          -0.2532],                                                       │ │
│ │          │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871, -0.4002,   │ │
│ │          -0.4672],                                                       │ │
│ │          │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160, -0.5219,   │ │
│ │          -0.7189]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901, -0.1644,   │ │
│ │          -0.2325],                                                       │ │
│ │          │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829, -0.2394,   │ │
│ │          -0.3049],                                                       │ │
│ │          │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110, -0.4470,   │ │
│ │          -0.5231],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818, -0.3438,   │ │
│ │          0.1731],                                                        │ │
│ │          │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438, -0.0176,   │ │
│ │          -0.0727],                                                       │ │
│ │          │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505, -0.2082,   │ │
│ │          -0.3332]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169, -0.7085,   │ │
│ │          -0.7336],                                                       │ │
│ │          │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306, -0.6846,   │ │
│ │          -0.7594],                                                       │ │
│ │          │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095, -0.7978,   │ │
│ │          -0.8245],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182, -0.6215,   │ │
│ │          0.1228],                                                        │ │
│ │          │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408, -0.2605,   │ │
│ │          -0.2418],                                                       │ │
│ │          │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678, -0.4024,   │ │
│ │          -0.5858]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038, -0.6567,   │ │
│ │          -0.7818],                                                       │ │
│ │          │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468, -0.4521,   │ │
│ │          -0.5808],                                                       │ │
│ │          │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919, -0.5200,   │ │
│ │          -0.4384],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624, -0.8494,   │ │
│ │          -0.1735],                                                       │ │
│ │          │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587, -0.2537,   │ │
│ │          -0.3986],                                                       │ │
│ │          │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507, -0.4791,   │ │
│ │          -0.6006]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419, -0.2687,   │ │
│ │          -0.4003],                                                       │ │
│ │          │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790, -0.0354,   │ │
│ │          -0.1698],                                                       │ │
│ │          │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  0.0203,   │ │
│ │          0.0299],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425, -0.7123,   │ │
│ │          0.3566],                                                        │ │
│ │          │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  0.2030,   │ │
│ │          0.0399],                                                        │ │
│ │          │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140, -0.0388,   │ │
│ │          -0.1875]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856, -0.6522,   │ │
│ │          -0.7503],                                                       │ │
│ │          │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226, -0.4105,   │ │
│ │          -0.5004],                                                       │ │
│ │          │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941, -0.3854,   │ │
│ │          -0.3569],                                                       │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591, -0.5653,   │ │
│ │          0.2921],                                                        │ │
│ │          │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  0.1336,   │ │
│ │          -0.1004],                                                       │ │
│ │          │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995, -0.2689,   │ │
│ │          -0.3513]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  1.1517,   │ │
│ │          1.0863],                                                        │ │
│ │          │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  1.1228,   │ │
│ │          1.1525],                                                        │ │
│ │          │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  1.1681,   │ │
│ │          1.1589],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200, -0.5756,   │ │
│ │          -0.5779],                                                       │ │
│ │          │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044, -0.6458,   │ │
│ │          -0.6436],                                                       │ │
│ │          │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613, -0.7063,   │ │
│ │          -0.7261]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  0.5726,   │ │
│ │          0.5173],                                                        │ │
│ │          │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  0.5592,   │ │
│ │          0.5988],                                                        │ │
│ │          │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  0.6153,   │ │
│ │          0.6056],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912, -0.1196,   │ │
│ │          -0.1621],                                                       │ │
│ │          │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841, -0.1920,   │ │
│ │          -0.2276],                                                       │ │
│ │          │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218, -0.2507,   │ │
│ │          -0.3032]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  0.2579,   │ │
│ │          0.1735],                                                        │ │
│ │          │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  0.2026,   │ │
│ │          0.2187],                                                        │ │
│ │          │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  0.2340,   │ │
│ │          0.2250],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908, -0.4467,   │ │
│ │          -0.4766],                                                       │ │
│ │          │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832, -0.5244,   │ │
│ │          -0.5442],                                                       │ │
│ │          │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572, -0.5930,   │ │
│ │          -0.6154]]]],                                                    │ │
│ │          │      device='cuda:0'),                                        │ │
│ │          │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          │   ],                                                          │ │
│ │          │   0                                                           │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = TeacherUNetModel(                                               │ │
│ │            (model): Unet(                                                │ │
│ │          │   (encoder): ResNetEncoder(                                   │ │
│ │          │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), │ │
│ │          padding=(3, 3), bias=False)                                     │ │
│ │          │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,           │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │     (relu): ReLU(inplace=True)                                │ │
│ │          │     (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1,  │ │
│ │          dilation=1, ceil_mode=False)                                    │ │
│ │          │     (layer1): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer2): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),          │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, │ │
│ │          2), bias=False)                                                 │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer3): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (5): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │     (layer4): Sequential(                                     │ │
│ │          │   │   (0): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),         │ │
│ │          stride=(2, 2), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (downsample): Sequential(                             │ │
│ │          │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),           │ │
│ │          stride=(2, 2), bias=False)                                      │ │
│ │          │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): BasicBlock(                                        │ │
│ │          │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │     (relu): ReLU(inplace=True)                            │ │
│ │          │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),         │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (decoder): UnetDecoder(                                     │ │
│ │          │     (center): Identity()                                      │ │
│ │          │     (blocks): ModuleList(                                     │ │
│ │          │   │   (0): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (1): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),           │ │
│ │          stride=(1, 1), padding=(1, 1), bias=False)                      │ │
│ │          │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,      │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (2): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (3): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │   │   (4): DecoderBlock(                                      │ │
│ │          │   │     (conv1): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention1): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (conv2): Conv2dReLU(                                  │ │
│ │          │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1,  │ │
│ │          1), padding=(1, 1), bias=False)                                 │ │
│ │          │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,       │ │
│ │          affine=True, track_running_stats=True)                          │ │
│ │          │   │   │   (2): ReLU(inplace=True)                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │     (attention2): Attention(                              │ │
│ │          │   │   │   (attention): Identity()                             │ │
│ │          │   │     )                                                     │ │
│ │          │   │   )                                                       │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │          │   (segmentation_head): SegmentationHead(                      │ │
│ │          │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),     │ │
│ │          padding=(1, 1))                                                 │ │
│ │          │     (1): Identity()                                           │ │
│ │          │     (2): Activation(                                          │ │
│ │          │   │   (activation): Identity()                                │ │
│ │          │     )                                                         │ │
│ │          │   )                                                           │ │
│ │            )                                                             │ │
│ │            (loss): BCEWithLogitsLoss()                                   │ │
│ │            (train_f1): BinaryF1Score()                                   │ │
│ │            (train_iou): BinaryJaccardIndex()                             │ │
│ │            (train_precision): BinaryPrecision()                          │ │
│ │            (train_recall): BinaryRecall()                                │ │
│ │            (val_f1): BinaryF1Score()                                     │ │
│ │            (val_iou): BinaryJaccardIndex()                               │ │
│ │            (val_precision): BinaryPrecision()                            │ │
│ │            (val_recall): BinaryRecall()                                  │ │
│ │            (test_f1): BinaryF1Score()                                    │ │
│ │            (test_iou): BinaryJaccardIndex()                              │ │
│ │            (test_precision): BinaryPrecision()                           │ │
│ │            (test_recall): BinaryRecall()                                 │ │
│ │          )                                                               │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   [                                                     │ │
│ │                │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,       │ │
│ │                -0.6058, -0.6181, -0.7150],                               │ │
│ │                │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,      │ │
│ │                -0.7470, -1.0972],                                        │ │
│ │                │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,      │ │
│ │                -1.3672, -1.4232],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,      │ │
│ │                0.8201,  0.9101],                                         │ │
│ │                │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,      │ │
│ │                0.7934,  0.8617],                                         │ │
│ │                │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,      │ │
│ │                0.8312,  0.9036]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,      │ │
│ │                -0.3903, -0.5082],                                        │ │
│ │                │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,      │ │
│ │                -0.5269, -0.9126],                                        │ │
│ │                │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,      │ │
│ │                -1.3571, -1.3879],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,      │ │
│ │                0.5149,  0.6028],                                         │ │
│ │                │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,      │ │
│ │                0.5133,  0.5956],                                         │ │
│ │                │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,      │ │
│ │                0.5766,  0.6924]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,      │ │
│ │                -0.4887, -0.5277],                                        │ │
│ │                │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,      │ │
│ │                -0.5726, -0.8895],                                        │ │
│ │                │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,      │ │
│ │                -1.2241, -1.2979],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,      │ │
│ │                0.4844,  0.5816],                                         │ │
│ │                │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,      │ │
│ │                0.4917,  0.5691],                                         │ │
│ │                │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,      │ │
│ │                0.5424,  0.6669]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,      │ │
│ │                -0.4125, -0.2770],                                        │ │
│ │                │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,      │ │
│ │                -0.2637, -0.5444],                                        │ │
│ │                │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,      │ │
│ │                0.3721, -0.2837],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,      │ │
│ │                1.5731,  1.6655],                                         │ │
│ │                │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,      │ │
│ │                1.6633,  1.5620],                                         │ │
│ │                │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,      │ │
│ │                1.8766,  1.8721]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,      │ │
│ │                -0.0699,  0.0557],                                        │ │
│ │                │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,      │ │
│ │                0.0547, -0.1675],                                         │ │
│ │                │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,      │ │
│ │                0.6220,  0.0236],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,      │ │
│ │                1.7006,  1.7636],                                         │ │
│ │                │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,      │ │
│ │                1.7452,  1.6086],                                         │ │
│ │                │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,      │ │
│ │                1.9005,  1.8320]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,      │ │
│ │                -0.1504, -0.0534],                                        │ │
│ │                │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,      │ │
│ │                -0.0084, -0.3465],                                        │ │
│ │                │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,      │ │
│ │                0.6836, -0.0941],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,      │ │
│ │                1.5997,  1.6536],                                         │ │
│ │                │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,      │ │
│ │                1.6373,  1.4997],                                         │ │
│ │                │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,      │ │
│ │                1.7704,  1.7204]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,      │ │
│ │                0.6527,  0.1973],                                         │ │
│ │                │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,      │ │
│ │                -0.7741, -0.6588],                                        │ │
│ │                │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,      │ │
│ │                -0.8624, -0.8335],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,      │ │
│ │                1.3495,  1.2763],                                         │ │
│ │                │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,      │ │
│ │                1.2270,  1.1958],                                         │ │
│ │                │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,      │ │
│ │                1.2479,  1.2777]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,      │ │
│ │                0.6290,  0.2545],                                         │ │
│ │                │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,      │ │
│ │                -0.2367, -0.0257],                                        │ │
│ │                │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,      │ │
│ │                -0.6202, -0.5923],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,      │ │
│ │                1.5171,  1.4460],                                         │ │
│ │                │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,      │ │
│ │                1.5998,  1.5811],                                         │ │
│ │                │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,      │ │
│ │                1.6719,  1.6993]],                                        │ │
│ │                │   │                                                     │ │
│ │                │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,      │ │
│ │                0.4811,  0.0363],                                         │ │
│ │                │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,      │ │
│ │                -0.5587, -0.5162],                                        │ │
│ │                │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,      │ │
│ │                -0.8376, -0.8337],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,      │ │
│ │                1.9169,  1.9397],                                         │ │
│ │                │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,      │ │
│ │                2.2213,  2.2087],                                         │ │
│ │                │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,      │ │
│ │                2.2530,  2.2691]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,      │ │
│ │                -0.7623, -0.7780],                                        │ │
│ │                │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,      │ │
│ │                -0.7748, -0.8144],                                        │ │
│ │                │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,      │ │
│ │                -0.9039, -0.9166],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,      │ │
│ │                -0.6917, -0.2532],                                        │ │
│ │                │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,      │ │
│ │                -0.4002, -0.4672],                                        │ │
│ │                │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,      │ │
│ │                -0.5219, -0.7189]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,      │ │
│ │                -0.1644, -0.2325],                                        │ │
│ │                │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,      │ │
│ │                -0.2394, -0.3049],                                        │ │
│ │                │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,      │ │
│ │                -0.4470, -0.5231],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,      │ │
│ │                -0.3438,  0.1731],                                        │ │
│ │                │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,      │ │
│ │                -0.0176, -0.0727],                                        │ │
│ │                │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,      │ │
│ │                -0.2082, -0.3332]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,      │ │
│ │                -0.7085, -0.7336],                                        │ │
│ │                │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,      │ │
│ │                -0.6846, -0.7594],                                        │ │
│ │                │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,      │ │
│ │                -0.7978, -0.8245],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,      │ │
│ │                -0.6215,  0.1228],                                        │ │
│ │                │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,      │ │
│ │                -0.2605, -0.2418],                                        │ │
│ │                │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,      │ │
│ │                -0.4024, -0.5858]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,      │ │
│ │                -0.6567, -0.7818],                                        │ │
│ │                │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,      │ │
│ │                -0.4521, -0.5808],                                        │ │
│ │                │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,      │ │
│ │                -0.5200, -0.4384],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,      │ │
│ │                -0.8494, -0.1735],                                        │ │
│ │                │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,      │ │
│ │                -0.2537, -0.3986],                                        │ │
│ │                │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,      │ │
│ │                -0.4791, -0.6006]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,      │ │
│ │                -0.2687, -0.4003],                                        │ │
│ │                │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,      │ │
│ │                -0.0354, -0.1698],                                        │ │
│ │                │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,      │ │
│ │                0.0203,  0.0299],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,      │ │
│ │                -0.7123,  0.3566],                                        │ │
│ │                │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,      │ │
│ │                0.2030,  0.0399],                                         │ │
│ │                │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,      │ │
│ │                -0.0388, -0.1875]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,      │ │
│ │                -0.6522, -0.7503],                                        │ │
│ │                │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,      │ │
│ │                -0.4105, -0.5004],                                        │ │
│ │                │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,      │ │
│ │                -0.3854, -0.3569],                                        │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,      │ │
│ │                -0.5653,  0.2921],                                        │ │
│ │                │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,      │ │
│ │                0.1336, -0.1004],                                         │ │
│ │                │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,      │ │
│ │                -0.2689, -0.3513]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,      │ │
│ │                1.1517,  1.0863],                                         │ │
│ │                │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,      │ │
│ │                1.1228,  1.1525],                                         │ │
│ │                │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,      │ │
│ │                1.1681,  1.1589],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,      │ │
│ │                -0.5756, -0.5779],                                        │ │
│ │                │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,      │ │
│ │                -0.6458, -0.6436],                                        │ │
│ │                │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,      │ │
│ │                -0.7063, -0.7261]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,      │ │
│ │                0.5726,  0.5173],                                         │ │
│ │                │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,      │ │
│ │                0.5592,  0.5988],                                         │ │
│ │                │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,      │ │
│ │                0.6153,  0.6056],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,      │ │
│ │                -0.1196, -0.1621],                                        │ │
│ │                │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,      │ │
│ │                -0.1920, -0.2276],                                        │ │
│ │                │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,      │ │
│ │                -0.2507, -0.3032]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,      │ │
│ │                0.2579,  0.1735],                                         │ │
│ │                │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,      │ │
│ │                0.2026,  0.2187],                                         │ │
│ │                │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,      │ │
│ │                0.2340,  0.2250],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,      │ │
│ │                -0.4467, -0.4766],                                        │ │
│ │                │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,      │ │
│ │                -0.5244, -0.5442],                                        │ │
│ │                │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,      │ │
│ │                -0.5930, -0.6154]]]],                                     │ │
│ │                │      device='cuda:0'),                                  │ │
│ │                │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                │   ],                                                    │ │
│ │                │   0                                                     │ │
│ │                )                                                         │ │
│ │ forward_call = <function                                                 │ │
│ │                _ForwardRedirection.__call__.<locals>.wrapped_forward at  │ │
│ │                0x7f0a1338edd0>                                           │ │
│ │       kwargs = {}                                                        │ │
│ │         self = TeacherUNetModel(                                         │ │
│ │                  (model): Unet(                                          │ │
│ │                │   (encoder): ResNetEncoder(                             │ │
│ │                │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),          │ │
│ │                stride=(2, 2), padding=(3, 3), bias=False)                │ │
│ │                │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,     │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │     (relu): ReLU(inplace=True)                          │ │
│ │                │     (maxpool): MaxPool2d(kernel_size=3, stride=2,       │ │
│ │                padding=1, dilation=1, ceil_mode=False)                   │ │
│ │                │     (layer1): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer2): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),    │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),      │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer3): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (5): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │     (layer4): Sequential(                               │ │
│ │                │   │   (0): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),   │ │
│ │                stride=(2, 2), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (downsample): Sequential(                       │ │
│ │                │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),     │ │
│ │                stride=(2, 2), bias=False)                                │ │
│ │                │   │   │   (1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): BasicBlock(                                  │ │
│ │                │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn1): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │     (relu): ReLU(inplace=True)                      │ │
│ │                │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),   │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │     (bn2): BatchNorm2d(512, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (decoder): UnetDecoder(                               │ │
│ │                │     (center): Identity()                                │ │
│ │                │     (blocks): ModuleList(                               │ │
│ │                │   │   (0): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(256, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (1): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),     │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(128, eps=1e-05,              │ │
│ │                momentum=0.1, affine=True, track_running_stats=True)      │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (2): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (3): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),      │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │   │   (4): DecoderBlock(                                │ │
│ │                │   │     (conv1): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention1): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (conv2): Conv2dReLU(                            │ │
│ │                │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),       │ │
│ │                stride=(1, 1), padding=(1, 1), bias=False)                │ │
│ │                │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, │ │
│ │                affine=True, track_running_stats=True)                    │ │
│ │                │   │   │   (2): ReLU(inplace=True)                       │ │
│ │                │   │     )                                               │ │
│ │                │   │     (attention2): Attention(                        │ │
│ │                │   │   │   (attention): Identity()                       │ │
│ │                │   │     )                                               │ │
│ │                │   │   )                                                 │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                │   (segmentation_head): SegmentationHead(                │ │
│ │                │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1,   │ │
│ │                1), padding=(1, 1))                                       │ │
│ │                │     (1): Identity()                                     │ │
│ │                │     (2): Activation(                                    │ │
│ │                │   │   (activation): Identity()                          │ │
│ │                │     )                                                   │ │
│ │                │   )                                                     │ │
│ │                  )                                                       │ │
│ │                  (loss): BCEWithLogitsLoss()                             │ │
│ │                  (train_f1): BinaryF1Score()                             │ │
│ │                  (train_iou): BinaryJaccardIndex()                       │ │
│ │                  (train_precision): BinaryPrecision()                    │ │
│ │                  (train_recall): BinaryRecall()                          │ │
│ │                  (val_f1): BinaryF1Score()                               │ │
│ │                  (val_iou): BinaryJaccardIndex()                         │ │
│ │                  (val_precision): BinaryPrecision()                      │ │
│ │                  (val_recall): BinaryRecall()                            │ │
│ │                  (test_f1): BinaryF1Score()                              │ │
│ │                  (test_iou): BinaryJaccardIndex()                        │ │
│ │                  (test_precision): BinaryPrecision()                     │ │
│ │                  (test_recall): BinaryRecall()                           │ │
│ │                )                                                         │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/pyt │
│ orch_lightning/strategies/strategy.py:633 in wrapped_forward                 │
│                                                                              │
│   630 │   │   │   original_module.forward = original_forward  # type: ignore │
│   631 │   │   │   # Call the actual method e.g. `.training_step(...)`        │
│   632 │   │   │   method = getattr(original_module, method_name)             │
│ ❱ 633 │   │   │   out = method(*_args, **_kwargs)                            │
│   634 │   │   │   self.on_after_inner_forward(wrapper_module, original_modul │
│   635 │   │   │   return out                                                 │
│   636                                                                        │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │            _args = (                                                     │ │
│ │                    │   [                                                 │ │
│ │                    │   │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ...,   │ │
│ │                    -0.6058, -0.6181, -0.7150],                           │ │
│ │                    │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,  │ │
│ │                    -0.7470, -1.0972],                                    │ │
│ │                    │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,  │ │
│ │                    -1.3672, -1.4232],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,  │ │
│ │                    0.8201,  0.9101],                                     │ │
│ │                    │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,  │ │
│ │                    0.7934,  0.8617],                                     │ │
│ │                    │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,  │ │
│ │                    0.8312,  0.9036]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,  │ │
│ │                    -0.3903, -0.5082],                                    │ │
│ │                    │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,  │ │
│ │                    -0.5269, -0.9126],                                    │ │
│ │                    │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,  │ │
│ │                    -1.3571, -1.3879],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,  │ │
│ │                    0.5149,  0.6028],                                     │ │
│ │                    │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,  │ │
│ │                    0.5133,  0.5956],                                     │ │
│ │                    │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,  │ │
│ │                    0.5766,  0.6924]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,  │ │
│ │                    -0.4887, -0.5277],                                    │ │
│ │                    │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,  │ │
│ │                    -0.5726, -0.8895],                                    │ │
│ │                    │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,  │ │
│ │                    -1.2241, -1.2979],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,  │ │
│ │                    0.4844,  0.5816],                                     │ │
│ │                    │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,  │ │
│ │                    0.4917,  0.5691],                                     │ │
│ │                    │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,  │ │
│ │                    0.5424,  0.6669]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,  │ │
│ │                    -0.4125, -0.2770],                                    │ │
│ │                    │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,  │ │
│ │                    -0.2637, -0.5444],                                    │ │
│ │                    │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,  │ │
│ │                    0.3721, -0.2837],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,  │ │
│ │                    1.5731,  1.6655],                                     │ │
│ │                    │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,  │ │
│ │                    1.6633,  1.5620],                                     │ │
│ │                    │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,  │ │
│ │                    1.8766,  1.8721]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,  │ │
│ │                    -0.0699,  0.0557],                                    │ │
│ │                    │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,  │ │
│ │                    0.0547, -0.1675],                                     │ │
│ │                    │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,  │ │
│ │                    0.6220,  0.0236],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,  │ │
│ │                    1.7006,  1.7636],                                     │ │
│ │                    │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,  │ │
│ │                    1.7452,  1.6086],                                     │ │
│ │                    │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,  │ │
│ │                    1.9005,  1.8320]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,  │ │
│ │                    -0.1504, -0.0534],                                    │ │
│ │                    │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,  │ │
│ │                    -0.0084, -0.3465],                                    │ │
│ │                    │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,  │ │
│ │                    0.6836, -0.0941],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,  │ │
│ │                    1.5997,  1.6536],                                     │ │
│ │                    │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,  │ │
│ │                    1.6373,  1.4997],                                     │ │
│ │                    │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,  │ │
│ │                    1.7704,  1.7204]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,  │ │
│ │                    0.6527,  0.1973],                                     │ │
│ │                    │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,  │ │
│ │                    -0.7741, -0.6588],                                    │ │
│ │                    │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,  │ │
│ │                    -0.8624, -0.8335],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,  │ │
│ │                    1.3495,  1.2763],                                     │ │
│ │                    │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,  │ │
│ │                    1.2270,  1.1958],                                     │ │
│ │                    │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,  │ │
│ │                    1.2479,  1.2777]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,  │ │
│ │                    0.6290,  0.2545],                                     │ │
│ │                    │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,  │ │
│ │                    -0.2367, -0.0257],                                    │ │
│ │                    │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,  │ │
│ │                    -0.6202, -0.5923],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,  │ │
│ │                    1.5171,  1.4460],                                     │ │
│ │                    │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,  │ │
│ │                    1.5998,  1.5811],                                     │ │
│ │                    │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,  │ │
│ │                    1.6719,  1.6993]],                                    │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,  │ │
│ │                    0.4811,  0.0363],                                     │ │
│ │                    │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,  │ │
│ │                    -0.5587, -0.5162],                                    │ │
│ │                    │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,  │ │
│ │                    -0.8376, -0.8337],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,  │ │
│ │                    1.9169,  1.9397],                                     │ │
│ │                    │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,  │ │
│ │                    2.2213,  2.2087],                                     │ │
│ │                    │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,  │ │
│ │                    2.2530,  2.2691]]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,  │ │
│ │                    -0.7623, -0.7780],                                    │ │
│ │                    │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,  │ │
│ │                    -0.7748, -0.8144],                                    │ │
│ │                    │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,  │ │
│ │                    -0.9039, -0.9166],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,  │ │
│ │                    -0.6917, -0.2532],                                    │ │
│ │                    │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,  │ │
│ │                    -0.4002, -0.4672],                                    │ │
│ │                    │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,  │ │
│ │                    -0.5219, -0.7189]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,  │ │
│ │                    -0.1644, -0.2325],                                    │ │
│ │                    │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,  │ │
│ │                    -0.2394, -0.3049],                                    │ │
│ │                    │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,  │ │
│ │                    -0.4470, -0.5231],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,  │ │
│ │                    -0.3438,  0.1731],                                    │ │
│ │                    │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,  │ │
│ │                    -0.0176, -0.0727],                                    │ │
│ │                    │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,  │ │
│ │                    -0.2082, -0.3332]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,  │ │
│ │                    -0.7085, -0.7336],                                    │ │
│ │                    │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,  │ │
│ │                    -0.6846, -0.7594],                                    │ │
│ │                    │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,  │ │
│ │                    -0.7978, -0.8245],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,  │ │
│ │                    -0.6215,  0.1228],                                    │ │
│ │                    │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,  │ │
│ │                    -0.2605, -0.2418],                                    │ │
│ │                    │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,  │ │
│ │                    -0.4024, -0.5858]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,  │ │
│ │                    -0.6567, -0.7818],                                    │ │
│ │                    │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,  │ │
│ │                    -0.4521, -0.5808],                                    │ │
│ │                    │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,  │ │
│ │                    -0.5200, -0.4384],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,  │ │
│ │                    -0.8494, -0.1735],                                    │ │
│ │                    │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,  │ │
│ │                    -0.2537, -0.3986],                                    │ │
│ │                    │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,  │ │
│ │                    -0.4791, -0.6006]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,  │ │
│ │                    -0.2687, -0.4003],                                    │ │
│ │                    │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,  │ │
│ │                    -0.0354, -0.1698],                                    │ │
│ │                    │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,  │ │
│ │                    0.0203,  0.0299],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,  │ │
│ │                    -0.7123,  0.3566],                                    │ │
│ │                    │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,  │ │
│ │                    0.2030,  0.0399],                                     │ │
│ │                    │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,  │ │
│ │                    -0.0388, -0.1875]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,  │ │
│ │                    -0.6522, -0.7503],                                    │ │
│ │                    │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,  │ │
│ │                    -0.4105, -0.5004],                                    │ │
│ │                    │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,  │ │
│ │                    -0.3854, -0.3569],                                    │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,  │ │
│ │                    -0.5653,  0.2921],                                    │ │
│ │                    │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,  │ │
│ │                    0.1336, -0.1004],                                     │ │
│ │                    │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,  │ │
│ │                    -0.2689, -0.3513]]],                                  │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,  │ │
│ │                    1.1517,  1.0863],                                     │ │
│ │                    │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,  │ │
│ │                    1.1228,  1.1525],                                     │ │
│ │                    │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,  │ │
│ │                    1.1681,  1.1589],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,  │ │
│ │                    -0.5756, -0.5779],                                    │ │
│ │                    │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,  │ │
│ │                    -0.6458, -0.6436],                                    │ │
│ │                    │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,  │ │
│ │                    -0.7063, -0.7261]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,  │ │
│ │                    0.5726,  0.5173],                                     │ │
│ │                    │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,  │ │
│ │                    0.5592,  0.5988],                                     │ │
│ │                    │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,  │ │
│ │                    0.6153,  0.6056],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,  │ │
│ │                    -0.1196, -0.1621],                                    │ │
│ │                    │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,  │ │
│ │                    -0.1920, -0.2276],                                    │ │
│ │                    │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,  │ │
│ │                    -0.2507, -0.3032]],                                   │ │
│ │                    │   │                                                 │ │
│ │                    │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,  │ │
│ │                    0.2579,  0.1735],                                     │ │
│ │                    │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,  │ │
│ │                    0.2026,  0.2187],                                     │ │
│ │                    │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,  │ │
│ │                    0.2340,  0.2250],                                     │ │
│ │                    │   │     ...,                                        │ │
│ │                    │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,  │ │
│ │                    -0.4467, -0.4766],                                    │ │
│ │                    │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,  │ │
│ │                    -0.5244, -0.5442],                                    │ │
│ │                    │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,  │ │
│ │                    -0.5930, -0.6154]]]],                                 │ │
│ │                    │      device='cuda:0'),                              │ │
│ │                    │   │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,     │ │
│ │                    0.,   0.],                                            │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.]]]],                                             │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   ...,                                          │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]],                                               │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │                                                 │ │
│ │                    │   │   [[[[  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      [  0.,   0.,   0.,  ..., 255., 255.,       │ │
│ │                    255.],                                                │ │
│ │                    │   │      ...,                                       │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.],                                                  │ │
│ │                    │   │      [  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                    0.]]]]], device='cuda:0')                             │ │
│ │                    │   ],                                                │ │
│ │                    │   0                                                 │ │
│ │                    )                                                     │ │
│ │          _kwargs = {}                                                    │ │
│ │           method = <bound method TeacherUNetModel.validation_step of     │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │      method_name = 'validation_step'                                     │ │
│ │ original_forward = <bound method TeacherUNetModel.forward of             │ │
│ │                    TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )>                                                    │ │
│ │  original_module = TeacherUNetModel(                                     │ │
│ │                      (model): Unet(                                      │ │
│ │                    │   (encoder): ResNetEncoder(                         │ │
│ │                    │     (conv1): Conv2d(3, 64, kernel_size=(7, 7),      │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, │ │
│ │                    affine=True, track_running_stats=True)                │ │
│ │                    │     (relu): ReLU(inplace=True)                      │ │
│ │                    │     (maxpool): MaxPool2d(kernel_size=3, stride=2,   │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │     (layer1): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │     (bn2): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer2): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(64, 128, kernel_size=(3,    │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),  │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer3): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(128, 256, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (5): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (layer4): Sequential(                           │ │
│ │                    │   │   (0): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(256, 512, kernel_size=(3,   │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (downsample): Sequential(                   │ │
│ │                    │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1), │ │
│ │                    stride=(2, 2), bias=False)                            │ │
│ │                    │   │   │   (1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): BasicBlock(                              │ │
│ │                    │   │     (conv1): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn1): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     (relu): ReLU(inplace=True)                  │ │
│ │                    │   │     (conv2): Conv2d(512, 512, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │     (bn2): BatchNorm2d(512, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (decoder): UnetDecoder(                           │ │
│ │                    │     (center): Identity()                            │ │
│ │                    │     (blocks): ModuleList(                           │ │
│ │                    │   │   (0): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(256, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (1): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(128, eps=1e-05,          │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (2): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(64, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (3): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),  │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(32, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (4): DecoderBlock(                            │ │
│ │                    │   │     (conv1): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention1): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (conv2): Conv2dReLU(                        │ │
│ │                    │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),   │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │   (1): BatchNorm2d(16, eps=1e-05,           │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (2): ReLU(inplace=True)                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (attention2): Attention(                    │ │
│ │                    │   │   │   (attention): Identity()                   │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (segmentation_head): SegmentationHead(            │ │
│ │                    │     (0): Conv2d(16, 1, kernel_size=(3, 3),          │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │     (1): Identity()                                 │ │
│ │                    │     (2): Activation(                                │ │
│ │                    │   │   (activation): Identity()                      │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                      )                                                   │ │
│ │                      (loss): BCEWithLogitsLoss()                         │ │
│ │                      (train_f1): BinaryF1Score()                         │ │
│ │                      (train_iou): BinaryJaccardIndex()                   │ │
│ │                      (train_precision): BinaryPrecision()                │ │
│ │                      (train_recall): BinaryRecall()                      │ │
│ │                      (val_f1): BinaryF1Score()                           │ │
│ │                      (val_iou): BinaryJaccardIndex()                     │ │
│ │                      (val_precision): BinaryPrecision()                  │ │
│ │                      (val_recall): BinaryRecall()                        │ │
│ │                      (test_f1): BinaryF1Score()                          │ │
│ │                      (test_iou): BinaryJaccardIndex()                    │ │
│ │                      (test_precision): BinaryPrecision()                 │ │
│ │                      (test_recall): BinaryRecall()                       │ │
│ │                    )                                                     │ │
│ │             self = <pytorch_lightning.strategies.ddp._DDPForwardRedirec… │ │
│ │                    object at 0x7f0a157a06a0>                             │ │
│ │   wrapper_module = DistributedDataParallel(                              │ │
│ │                      (module): TeacherUNetModel(                         │ │
│ │                    │   (model): Unet(                                    │ │
│ │                    │     (encoder): ResNetEncoder(                       │ │
│ │                    │   │   (conv1): Conv2d(3, 64, kernel_size=(7, 7),    │ │
│ │                    stride=(2, 2), padding=(3, 3), bias=False)            │ │
│ │                    │   │   (bn1): BatchNorm2d(64, eps=1e-05,             │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   (relu): ReLU(inplace=True)                    │ │
│ │                    │   │   (maxpool): MaxPool2d(kernel_size=3, stride=2, │ │
│ │                    padding=1, dilation=1, ceil_mode=False)               │ │
│ │                    │   │   (layer1): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(64, 64, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer2): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(64, 128, kernel_size=(3,  │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(64, 128, kernel_size=(1,    │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(128, 128, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer3): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(128, 256, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(128, 256, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (5): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(256, 256, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │   │   (layer4): Sequential(                         │ │
│ │                    │   │     (0): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(256, 512, kernel_size=(3, │ │
│ │                    3), stride=(2, 2), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (downsample): Sequential(                 │ │
│ │                    │   │   │     (0): Conv2d(256, 512, kernel_size=(1,   │ │
│ │                    1), stride=(2, 2), bias=False)                        │ │
│ │                    │   │   │     (1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): BasicBlock(                            │ │
│ │                    │   │   │   (conv1): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn1): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │   (relu): ReLU(inplace=True)                │ │
│ │                    │   │   │   (conv2): Conv2d(512, 512, kernel_size=(3, │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │   (bn2): BatchNorm2d(512, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (decoder): UnetDecoder(                         │ │
│ │                    │   │   (center): Identity()                          │ │
│ │                    │   │   (blocks): ModuleList(                         │ │
│ │                    │   │     (0): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(768, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(256, 256, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(256, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (1): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(384, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 128, kernel_size=(3,   │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(128, eps=1e-05,        │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (2): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(192, 64, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(64, 64, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(64, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (3): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(128, 32, kernel_size=(3,    │ │
│ │                    3), stride=(1, 1), padding=(1, 1), bias=False)        │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 32, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(32, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │     (4): DecoderBlock(                          │ │
│ │                    │   │   │   (conv1): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(32, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention1): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (conv2): Conv2dReLU(                      │ │
│ │                    │   │   │     (0): Conv2d(16, 16, kernel_size=(3, 3), │ │
│ │                    stride=(1, 1), padding=(1, 1), bias=False)            │ │
│ │                    │   │   │     (1): BatchNorm2d(16, eps=1e-05,         │ │
│ │                    momentum=0.1, affine=True, track_running_stats=True)  │ │
│ │                    │   │   │     (2): ReLU(inplace=True)                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │   │   (attention2): Attention(                  │ │
│ │                    │   │   │     (attention): Identity()                 │ │
│ │                    │   │   │   )                                         │ │
│ │                    │   │     )                                           │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │     (segmentation_head): SegmentationHead(          │ │
│ │                    │   │   (0): Conv2d(16, 1, kernel_size=(3, 3),        │ │
│ │                    stride=(1, 1), padding=(1, 1))                        │ │
│ │                    │   │   (1): Identity()                               │ │
│ │                    │   │   (2): Activation(                              │ │
│ │                    │   │     (activation): Identity()                    │ │
│ │                    │   │   )                                             │ │
│ │                    │     )                                               │ │
│ │                    │   )                                                 │ │
│ │                    │   (loss): BCEWithLogitsLoss()                       │ │
│ │                    │   (train_f1): BinaryF1Score()                       │ │
│ │                    │   (train_iou): BinaryJaccardIndex()                 │ │
│ │                    │   (train_precision): BinaryPrecision()              │ │
│ │                    │   (train_recall): BinaryRecall()                    │ │
│ │                    │   (val_f1): BinaryF1Score()                         │ │
│ │                    │   (val_iou): BinaryJaccardIndex()                   │ │
│ │                    │   (val_precision): BinaryPrecision()                │ │
│ │                    │   (val_recall): BinaryRecall()                      │ │
│ │                    │   (test_f1): BinaryF1Score()                        │ │
│ │                    │   (test_iou): BinaryJaccardIndex()                  │ │
│ │                    │   (test_precision): BinaryPrecision()               │ │
│ │                    │   (test_recall): BinaryRecall()                     │ │
│ │                      )                                                   │ │
│ │                    )                                                     │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/projects/Noisy-Student/models/teacher_unet.py:68 in              │
│ validation_step                                                              │
│                                                                              │
│    65 │   │   outputs = self(images)                                         │
│    66 │   │                                                                  │
│    67 │   │   # Update the metrics                                           │
│ ❱  68 │   │   ce_loss = self.loss(outputs, labels)                           │
│    69 │   │                                                                  │
│    70 │   │   # Log metrics                                                  │
│    71 │   │   precision = self.val_precision(outputs, labels)                │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │     batch = [                                                            │ │
│ │             │   tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,     │ │
│ │             -0.6181, -0.7150],                                           │ │
│ │             │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,         │ │
│ │             -0.7470, -1.0972],                                           │ │
│ │             │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,         │ │
│ │             -1.3672, -1.4232],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,         │ │
│ │             0.8201,  0.9101],                                            │ │
│ │             │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,         │ │
│ │             0.7934,  0.8617],                                            │ │
│ │             │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,         │ │
│ │             0.8312,  0.9036]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,         │ │
│ │             -0.3903, -0.5082],                                           │ │
│ │             │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,         │ │
│ │             -0.5269, -0.9126],                                           │ │
│ │             │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,         │ │
│ │             -1.3571, -1.3879],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,         │ │
│ │             0.5149,  0.6028],                                            │ │
│ │             │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,         │ │
│ │             0.5133,  0.5956],                                            │ │
│ │             │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,         │ │
│ │             0.5766,  0.6924]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,         │ │
│ │             -0.4887, -0.5277],                                           │ │
│ │             │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,         │ │
│ │             -0.5726, -0.8895],                                           │ │
│ │             │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,         │ │
│ │             -1.2241, -1.2979],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,         │ │
│ │             0.4844,  0.5816],                                            │ │
│ │             │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,         │ │
│ │             0.4917,  0.5691],                                            │ │
│ │             │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,         │ │
│ │             0.5424,  0.6669]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,         │ │
│ │             -0.4125, -0.2770],                                           │ │
│ │             │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,         │ │
│ │             -0.2637, -0.5444],                                           │ │
│ │             │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,         │ │
│ │             0.3721, -0.2837],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,         │ │
│ │             1.5731,  1.6655],                                            │ │
│ │             │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,         │ │
│ │             1.6633,  1.5620],                                            │ │
│ │             │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,         │ │
│ │             1.8766,  1.8721]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,         │ │
│ │             -0.0699,  0.0557],                                           │ │
│ │             │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,         │ │
│ │             0.0547, -0.1675],                                            │ │
│ │             │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,         │ │
│ │             0.6220,  0.0236],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,         │ │
│ │             1.7006,  1.7636],                                            │ │
│ │             │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,         │ │
│ │             1.7452,  1.6086],                                            │ │
│ │             │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,         │ │
│ │             1.9005,  1.8320]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,         │ │
│ │             -0.1504, -0.0534],                                           │ │
│ │             │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,         │ │
│ │             -0.0084, -0.3465],                                           │ │
│ │             │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,         │ │
│ │             0.6836, -0.0941],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,         │ │
│ │             1.5997,  1.6536],                                            │ │
│ │             │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,         │ │
│ │             1.6373,  1.4997],                                            │ │
│ │             │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,         │ │
│ │             1.7704,  1.7204]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,         │ │
│ │             0.6527,  0.1973],                                            │ │
│ │             │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,         │ │
│ │             -0.7741, -0.6588],                                           │ │
│ │             │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,         │ │
│ │             -0.8624, -0.8335],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,         │ │
│ │             1.3495,  1.2763],                                            │ │
│ │             │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,         │ │
│ │             1.2270,  1.1958],                                            │ │
│ │             │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,         │ │
│ │             1.2479,  1.2777]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,         │ │
│ │             0.6290,  0.2545],                                            │ │
│ │             │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,         │ │
│ │             -0.2367, -0.0257],                                           │ │
│ │             │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,         │ │
│ │             -0.6202, -0.5923],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,         │ │
│ │             1.5171,  1.4460],                                            │ │
│ │             │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,         │ │
│ │             1.5998,  1.5811],                                            │ │
│ │             │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,         │ │
│ │             1.6719,  1.6993]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,         │ │
│ │             0.4811,  0.0363],                                            │ │
│ │             │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,         │ │
│ │             -0.5587, -0.5162],                                           │ │
│ │             │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,         │ │
│ │             -0.8376, -0.8337],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,         │ │
│ │             1.9169,  1.9397],                                            │ │
│ │             │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,         │ │
│ │             2.2213,  2.2087],                                            │ │
│ │             │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,         │ │
│ │             2.2530,  2.2691]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,         │ │
│ │             -0.7623, -0.7780],                                           │ │
│ │             │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,         │ │
│ │             -0.7748, -0.8144],                                           │ │
│ │             │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,         │ │
│ │             -0.9039, -0.9166],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,         │ │
│ │             -0.6917, -0.2532],                                           │ │
│ │             │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,         │ │
│ │             -0.4002, -0.4672],                                           │ │
│ │             │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,         │ │
│ │             -0.5219, -0.7189]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,         │ │
│ │             -0.1644, -0.2325],                                           │ │
│ │             │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,         │ │
│ │             -0.2394, -0.3049],                                           │ │
│ │             │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,         │ │
│ │             -0.4470, -0.5231],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,         │ │
│ │             -0.3438,  0.1731],                                           │ │
│ │             │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,         │ │
│ │             -0.0176, -0.0727],                                           │ │
│ │             │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,         │ │
│ │             -0.2082, -0.3332]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,         │ │
│ │             -0.7085, -0.7336],                                           │ │
│ │             │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,         │ │
│ │             -0.6846, -0.7594],                                           │ │
│ │             │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,         │ │
│ │             -0.7978, -0.8245],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,         │ │
│ │             -0.6215,  0.1228],                                           │ │
│ │             │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,         │ │
│ │             -0.2605, -0.2418],                                           │ │
│ │             │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,         │ │
│ │             -0.4024, -0.5858]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,         │ │
│ │             -0.6567, -0.7818],                                           │ │
│ │             │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,         │ │
│ │             -0.4521, -0.5808],                                           │ │
│ │             │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,         │ │
│ │             -0.5200, -0.4384],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,         │ │
│ │             -0.8494, -0.1735],                                           │ │
│ │             │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,         │ │
│ │             -0.2537, -0.3986],                                           │ │
│ │             │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,         │ │
│ │             -0.4791, -0.6006]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,         │ │
│ │             -0.2687, -0.4003],                                           │ │
│ │             │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,         │ │
│ │             -0.0354, -0.1698],                                           │ │
│ │             │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,         │ │
│ │             0.0203,  0.0299],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,         │ │
│ │             -0.7123,  0.3566],                                           │ │
│ │             │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,         │ │
│ │             0.2030,  0.0399],                                            │ │
│ │             │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,         │ │
│ │             -0.0388, -0.1875]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,         │ │
│ │             -0.6522, -0.7503],                                           │ │
│ │             │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,         │ │
│ │             -0.4105, -0.5004],                                           │ │
│ │             │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,         │ │
│ │             -0.3854, -0.3569],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,         │ │
│ │             -0.5653,  0.2921],                                           │ │
│ │             │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,         │ │
│ │             0.1336, -0.1004],                                            │ │
│ │             │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,         │ │
│ │             -0.2689, -0.3513]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,         │ │
│ │             1.1517,  1.0863],                                            │ │
│ │             │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,         │ │
│ │             1.1228,  1.1525],                                            │ │
│ │             │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,         │ │
│ │             1.1681,  1.1589],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,         │ │
│ │             -0.5756, -0.5779],                                           │ │
│ │             │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,         │ │
│ │             -0.6458, -0.6436],                                           │ │
│ │             │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,         │ │
│ │             -0.7063, -0.7261]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,         │ │
│ │             0.5726,  0.5173],                                            │ │
│ │             │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,         │ │
│ │             0.5592,  0.5988],                                            │ │
│ │             │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,         │ │
│ │             0.6153,  0.6056],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,         │ │
│ │             -0.1196, -0.1621],                                           │ │
│ │             │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,         │ │
│ │             -0.1920, -0.2276],                                           │ │
│ │             │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,         │ │
│ │             -0.2507, -0.3032]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,         │ │
│ │             0.2579,  0.1735],                                            │ │
│ │             │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,         │ │
│ │             0.2026,  0.2187],                                            │ │
│ │             │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,         │ │
│ │             0.2340,  0.2250],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,         │ │
│ │             -0.4467, -0.4766],                                           │ │
│ │             │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,         │ │
│ │             -0.5244, -0.5442],                                           │ │
│ │             │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,         │ │
│ │             -0.5930, -0.6154]]]],                                        │ │
│ │             │      device='cuda:0'),                                     │ │
│ │             │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],   │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],   │ │
│ │             device='cuda:0')                                             │ │
│ │             ]                                                            │ │
│ │ batch_idx = 0                                                            │ │
│ │    images = tensor([[[[ 2.3164,  2.3446,  2.3149,  ..., -0.6058,         │ │
│ │             -0.6181, -0.7150],                                           │ │
│ │             │   │     [ 1.4268,  1.3023,  1.1477,  ..., -0.3876,         │ │
│ │             -0.7470, -1.0972],                                           │ │
│ │             │   │     [ 0.0779, -0.0593,  0.0045,  ..., -0.7834,         │ │
│ │             -1.3672, -1.4232],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.6139, -0.5378, -0.6376,  ...,  0.7786,         │ │
│ │             0.8201,  0.9101],                                            │ │
│ │             │   │     [-0.5613, -0.4577, -0.6747,  ...,  0.7601,         │ │
│ │             0.7934,  0.8617],                                            │ │
│ │             │   │     [-0.3507, -0.2922, -0.4185,  ...,  0.7168,         │ │
│ │             0.8312,  0.9036]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 2.0406,  2.0645,  2.0510,  ..., -0.4332,         │ │
│ │             -0.3903, -0.5082],                                           │ │
│ │             │   │     [ 1.1315,  1.0024,  0.8545,  ..., -0.1651,         │ │
│ │             -0.5269, -0.9126],                                           │ │
│ │             │   │     [ 0.0182, -0.1264,  0.0231,  ..., -0.6886,         │ │
│ │             -1.3571, -1.3879],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2281, -0.1932, -0.2900,  ...,  0.4864,         │ │
│ │             0.5149,  0.6028],                                            │ │
│ │             │   │     [-0.1770, -0.0489, -0.2525,  ...,  0.4758,         │ │
│ │             0.5133,  0.5956],                                            │ │
│ │             │   │     [ 0.0319,  0.1804,  0.0335,  ...,  0.4438,         │ │
│ │             0.5766,  0.6924]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.8773,  1.9022,  1.8847,  ..., -0.4057,         │ │
│ │             -0.4887, -0.5277],                                           │ │
│ │             │   │     [ 0.9649,  0.8121,  0.6603,  ..., -0.1638,         │ │
│ │             -0.5726, -0.8895],                                           │ │
│ │             │   │     [ 0.0210, -0.0865,  0.0234,  ..., -0.5850,         │ │
│ │             -1.2241, -1.2979],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4361, -0.4343, -0.5230,  ...,  0.4143,         │ │
│ │             0.4844,  0.5816],                                            │ │
│ │             │   │     [-0.2906, -0.2463, -0.5730,  ...,  0.4011,         │ │
│ │             0.4917,  0.5691],                                            │ │
│ │             │   │     [ 0.0091,  0.0706, -0.2163,  ...,  0.3680,         │ │
│ │             0.5424,  0.6669]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.6236,  0.7028,  0.6188,  ..., -0.2612,         │ │
│ │             -0.4125, -0.2770],                                           │ │
│ │             │   │     [ 0.6888,  0.5887,  0.5071,  ..., -0.1710,         │ │
│ │             -0.2637, -0.5444],                                           │ │
│ │             │   │     [ 1.1148,  0.1169, -0.1676,  ...,  0.1911,         │ │
│ │             0.3721, -0.2837],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.4486, -0.5441, -0.9948,  ...,  1.4529,         │ │
│ │             1.5731,  1.6655],                                            │ │
│ │             │   │     [-0.8471, -0.8097, -0.5052,  ...,  1.6699,         │ │
│ │             1.6633,  1.5620],                                            │ │
│ │             │   │     [-1.2547, -0.6262, -0.1167,  ...,  2.0572,         │ │
│ │             1.8766,  1.8721]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.3655,  0.4483,  0.3462,  ...,  0.0064,         │ │
│ │             -0.0699,  0.0557],                                           │ │
│ │             │   │     [ 0.4605,  0.3635,  0.2722,  ...,  0.0618,         │ │
│ │             0.0547, -0.1675],                                            │ │
│ │             │   │     [ 0.9666,  0.1626, -0.0085,  ...,  0.3880,         │ │
│ │             0.6220,  0.0236],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2760, -0.2201, -0.7969,  ...,  1.5642,         │ │
│ │             1.7006,  1.7636],                                            │ │
│ │             │   │     [-0.9533, -0.6040, -0.2027,  ...,  1.7120,         │ │
│ │             1.7452,  1.6086],                                            │ │
│ │             │   │     [-1.4558, -0.4432,  0.2369,  ...,  1.9949,         │ │
│ │             1.9005,  1.8320]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 0.2965,  0.3601,  0.3009,  ...,  0.0602,         │ │
│ │             -0.1504, -0.0534],                                           │ │
│ │             │   │     [ 0.4160,  0.2953,  0.2230,  ...,  0.1778,         │ │
│ │             -0.0084, -0.3465],                                           │ │
│ │             │   │     [ 0.9099,  0.0840, -0.1021,  ...,  0.5869,         │ │
│ │             0.6836, -0.0941],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3519, -0.4613, -0.9606,  ...,  1.4837,         │ │
│ │             1.5997,  1.6536],                                            │ │
│ │             │   │     [-0.8312, -0.7609, -0.3011,  ...,  1.6274,         │ │
│ │             1.6373,  1.4997],                                            │ │
│ │             │   │     [-1.3824, -0.5392,  0.2546,  ...,  1.8659,         │ │
│ │             1.7704,  1.7204]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 1.2738,  2.0317,  2.3064,  ...,  0.5743,         │ │
│ │             0.6527,  0.1973],                                            │ │
│ │             │   │     [-0.1900,  0.1981,  0.3613,  ..., -0.4840,         │ │
│ │             -0.7741, -0.6588],                                           │ │
│ │             │   │     [-0.4079, -0.5727, -0.7945,  ..., -0.9792,         │ │
│ │             -0.8624, -0.8335],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5236, -1.5460, -1.5493,  ...,  0.8791,         │ │
│ │             1.3495,  1.2763],                                            │ │
│ │             │   │     [-1.5478, -1.5571, -0.9722,  ...,  1.0991,         │ │
│ │             1.2270,  1.1958],                                            │ │
│ │             │   │     [-1.5594, -1.5262, -1.3078,  ...,  1.2170,         │ │
│ │             1.2479,  1.2777]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.2511,  2.0410,  2.2335,  ...,  0.4876,         │ │
│ │             0.6290,  0.2545],                                            │ │
│ │             │   │     [-0.3203,  0.2990,  0.5133,  ..., -0.1165,         │ │
│ │             -0.2367, -0.0257],                                           │ │
│ │             │   │     [-0.1477, -0.1331, -0.3114,  ..., -0.7581,         │ │
│ │             -0.6202, -0.5923],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.8475, -1.8564, -1.9051,  ...,  1.0213,         │ │
│ │             1.5171,  1.4460],                                            │ │
│ │             │   │     [-1.8560, -1.8576, -1.2073,  ...,  1.4468,         │ │
│ │             1.5998,  1.5811],                                            │ │
│ │             │   │     [-1.9128, -1.8755, -1.5804,  ...,  1.6565,         │ │
│ │             1.6719,  1.6993]],                                           │ │
│ │             │   │                                                        │ │
│ │             │   │    [[ 1.3119,  1.9435,  2.1157,  ...,  0.4802,         │ │
│ │             0.4811,  0.0363],                                            │ │
│ │             │   │     [-0.1179,  0.2318,  0.3654,  ..., -0.1602,         │ │
│ │             -0.5587, -0.5162],                                           │ │
│ │             │   │     [-0.1421, -0.2981, -0.5722,  ..., -0.8887,         │ │
│ │             -0.8376, -0.8337],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7000, -1.7201, -1.7387,  ...,  1.3972,         │ │
│ │             1.9169,  1.9397],                                            │ │
│ │             │   │     [-1.7279, -1.7529, -1.1157,  ...,  2.0661,         │ │
│ │             2.2213,  2.2087],                                            │ │
│ │             │   │     [-1.7323, -1.6954, -1.4618,  ...,  2.2354,         │ │
│ │             2.2530,  2.2691]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.0599, -1.0722, -0.8373,  ..., -0.8042,         │ │
│ │             -0.7623, -0.7780],                                           │ │
│ │             │   │     [-1.0798, -0.9996, -1.0004,  ..., -0.8416,         │ │
│ │             -0.7748, -0.8144],                                           │ │
│ │             │   │     [-0.8928, -0.8869, -0.8661,  ..., -0.7878,         │ │
│ │             -0.9039, -0.9166],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.8657, -0.9139, -0.9354,  ..., -0.7860,         │ │
│ │             -0.6917, -0.2532],                                           │ │
│ │             │   │     [-0.9836, -1.0682, -1.0412,  ..., -0.5871,         │ │
│ │             -0.4002, -0.4672],                                           │ │
│ │             │   │     [-0.9863, -1.0090, -1.0853,  ..., -0.6160,         │ │
│ │             -0.5219, -0.7189]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6332, -0.7097, -0.4215,  ..., -0.1901,         │ │
│ │             -0.1644, -0.2325],                                           │ │
│ │             │   │     [-0.6487, -0.6316, -0.5818,  ..., -0.2829,         │ │
│ │             -0.2394, -0.3049],                                           │ │
│ │             │   │     [-0.3767, -0.4395, -0.4375,  ..., -0.2110,         │ │
│ │             -0.4470, -0.5231],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2565, -0.2205, -0.2220,  ..., -0.3818,         │ │
│ │             -0.3438,  0.1731],                                           │ │
│ │             │   │     [-0.4657, -0.5518, -0.5182,  ..., -0.2438,         │ │
│ │             -0.0176, -0.0727],                                           │ │
│ │             │   │     [-0.3987, -0.4983, -0.6036,  ..., -0.3505,         │ │
│ │             -0.2082, -0.3332]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.0878, -1.1527, -0.9100,  ..., -0.7169,         │ │
│ │             -0.7085, -0.7336],                                           │ │
│ │             │   │     [-1.1135, -1.0810, -1.0489,  ..., -0.7306,         │ │
│ │             -0.6846, -0.7594],                                           │ │
│ │             │   │     [-0.9125, -0.9624, -0.9069,  ..., -0.6095,         │ │
│ │             -0.7978, -0.8245],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.7285, -0.7857, -0.7854,  ..., -0.7182,         │ │
│ │             -0.6215,  0.1228],                                           │ │
│ │             │   │     [-0.9004, -1.0222, -0.9365,  ..., -0.4408,         │ │
│ │             -0.2605, -0.2418],                                           │ │
│ │             │   │     [-0.8313, -0.9434, -0.9788,  ..., -0.4678,         │ │
│ │             -0.4024, -0.5858]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.7077, -0.4473, -0.6266,  ..., -0.7038,         │ │
│ │             -0.6567, -0.7818],                                           │ │
│ │             │   │     [-0.8280, -0.4161, -0.5953,  ..., -0.8468,         │ │
│ │             -0.4521, -0.5808],                                           │ │
│ │             │   │     [-0.5753, -0.5170, -0.6090,  ..., -0.7919,         │ │
│ │             -0.5200, -0.4384],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.1959, -0.6135, -0.5363,  ..., -1.3624,         │ │
│ │             -0.8494, -0.1735],                                           │ │
│ │             │   │     [-0.4295, -0.6888, -0.4310,  ..., -0.3587,         │ │
│ │             -0.2537, -0.3986],                                           │ │
│ │             │   │     [-0.5943, -0.6783, -0.7139,  ..., -0.3507,         │ │
│ │             -0.4791, -0.6006]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.2072,  0.0127, -0.1702,  ..., -0.3419,         │ │
│ │             -0.2687, -0.4003],                                           │ │
│ │             │   │     [-0.3858,  0.0282, -0.1687,  ..., -0.4790,         │ │
│ │             -0.0354, -0.1698],                                           │ │
│ │             │   │     [-0.2005, -0.1149, -0.1699,  ..., -0.3153,         │ │
│ │             0.0203,  0.0299],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.1754, -0.2889, -0.1054,  ..., -1.4425,         │ │
│ │             -0.7123,  0.3566],                                           │ │
│ │             │   │     [-0.1350, -0.4375, -0.0643,  ...,  0.0931,         │ │
│ │             0.2030,  0.0399],                                            │ │
│ │             │   │     [-0.3228, -0.4490, -0.4441,  ...,  0.1140,         │ │
│ │             -0.0388, -0.1875]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-0.6597, -0.3586, -0.4449,  ..., -0.6856,         │ │
│ │             -0.6522, -0.7503],                                           │ │
│ │             │   │     [-0.7248, -0.2678, -0.3945,  ..., -0.8226,         │ │
│ │             -0.4105, -0.5004],                                           │ │
│ │             │   │     [-0.2626, -0.1671, -0.3766,  ..., -0.6941,         │ │
│ │             -0.3854, -0.3569],                                           │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [ 0.2934, -0.4135, -0.2755,  ..., -1.2591,         │ │
│ │             -0.5653,  0.2921],                                           │ │
│ │             │   │     [-0.1146, -0.5248, -0.1897,  ...,  0.0059,         │ │
│ │             0.1336, -0.1004],                                            │ │
│ │             │   │     [-0.4185, -0.6055, -0.5559,  ..., -0.0995,         │ │
│ │             -0.2689, -0.3513]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-1.3826, -1.5758, -1.3897,  ...,  1.1593,         │ │
│ │             1.1517,  1.0863],                                            │ │
│ │             │   │     [-1.4554, -1.4403, -1.1914,  ...,  1.1762,         │ │
│ │             1.1228,  1.1525],                                            │ │
│ │             │   │     [-1.4418, -1.2993, -1.0208,  ...,  1.3535,         │ │
│ │             1.1681,  1.1589],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5414, -0.6903, -0.7511,  ..., -0.5200,         │ │
│ │             -0.5756, -0.5779],                                           │ │
│ │             │   │     [-1.5643, -0.7541, -0.6268,  ..., -0.5044,         │ │
│ │             -0.6458, -0.6436],                                           │ │
│ │             │   │     [-1.4533, -0.6317, -0.1612,  ..., -0.3613,         │ │
│ │             -0.7063, -0.7261]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.3448, -1.5791, -1.2935,  ...,  0.5572,         │ │
│ │             0.5726,  0.5173],                                            │ │
│ │             │   │     [-1.4295, -1.4998, -1.0167,  ...,  0.5924,         │ │
│ │             0.5592,  0.5988],                                            │ │
│ │             │   │     [-1.3550, -1.2938, -1.0301,  ...,  0.7972,         │ │
│ │             0.6153,  0.6056],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.7982, -0.8752, -0.6012,  ..., -0.0912,         │ │
│ │             -0.1196, -0.1621],                                           │ │
│ │             │   │     [-1.8009, -0.8427, -0.3782,  ..., -0.0841,         │ │
│ │             -0.1920, -0.2276],                                           │ │
│ │             │   │     [-1.6954, -0.7387, -0.0568,  ...,  0.0218,         │ │
│ │             -0.2507, -0.3032]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │    [[-1.4091, -1.6641, -1.4289,  ...,  0.2938,         │ │
│ │             0.2579,  0.1735],                                            │ │
│ │             │   │     [-1.4810, -1.5788, -1.2095,  ...,  0.2887,         │ │
│ │             0.2026,  0.2187],                                            │ │
│ │             │   │     [-1.4501, -1.4066, -1.1120,  ...,  0.4428,         │ │
│ │             0.2340,  0.2250],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-1.5457, -0.7003, -0.6430,  ..., -0.3908,         │ │
│ │             -0.4467, -0.4766],                                           │ │
│ │             │   │     [-1.6041, -0.7394, -0.4135,  ..., -0.3832,         │ │
│ │             -0.5244, -0.5442],                                           │ │
│ │             │   │     [-1.5440, -0.6222, -0.0975,  ..., -0.2572,         │ │
│ │             -0.5930, -0.6154]]]],                                        │ │
│ │             │      device='cuda:0')                                      │ │
│ │    labels = tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],    │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],       │ │
│ │             │   │      ...,                                              │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],       │ │
│ │             │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],   │ │
│ │             device='cuda:0')                                             │ │
│ │   outputs = tensor([[[[-0.0279,  0.0116, -0.0197,  ..., -0.0803,         │ │
│ │             -0.0152, -0.0020],                                           │ │
│ │             │   │     [-0.0659,  0.1263,  0.1180,  ...,  0.0021,         │ │
│ │             0.1010,  0.1056],                                            │ │
│ │             │   │     [ 0.1149,  0.1550,  0.3108,  ...,  0.0916,         │ │
│ │             0.1504,  0.2377],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3740, -0.1196, -0.1798,  ..., -0.1198,         │ │
│ │             -0.1116,  0.1718],                                           │ │
│ │             │   │     [-0.2927, -0.1691,  0.0233,  ..., -0.0781,         │ │
│ │             0.0413,  0.1412],                                            │ │
│ │             │   │     [-0.0300,  0.0842,  0.1364,  ..., -0.0254,         │ │
│ │             -0.0889,  0.0761]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.1294, -0.0253,  0.0245,  ..., -0.0753,         │ │
│ │             0.0539,  0.1015],                                            │ │
│ │             │   │     [-0.1243, -0.0791,  0.1270,  ...,  0.1829,         │ │
│ │             0.2532,  0.1139],                                            │ │
│ │             │   │     [-0.1294,  0.0254,  0.1617,  ...,  0.3633,         │ │
│ │             0.2478,  0.2445],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3372, -0.3716, -0.3953,  ..., -0.0201,         │ │
│ │             -0.1327,  0.1012],                                           │ │
│ │             │   │     [-0.1477, -0.3081, -0.0349,  ..., -0.1764,         │ │
│ │             -0.0923, -0.0737],                                           │ │
│ │             │   │     [ 0.0566,  0.1150,  0.1567,  ..., -0.0323,         │ │
│ │             -0.1155,  0.0596]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.0634,  0.0865, -0.0599,  ..., -0.0974,         │ │
│ │             -0.0269,  0.0041],                                           │ │
│ │             │   │     [ 0.0970,  0.1237,  0.1902,  ...,  0.0899,         │ │
│ │             0.0369,  0.0660],                                            │ │
│ │             │   │     [ 0.0046,  0.0969,  0.0421,  ...,  0.1782,         │ │
│ │             0.2664,  0.1254],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2817, -0.3960, -0.3130,  ...,  0.1370,         │ │
│ │             0.1470, -0.0364],                                            │ │
│ │             │   │     [-0.2585, -0.3835, -0.2625,  ..., -0.1390,         │ │
│ │             -0.1609, -0.0415],                                           │ │
│ │             │   │     [-0.1159, -0.0264,  0.0231,  ..., -0.0155,         │ │
│ │             -0.0535, -0.0242]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   ...,                                                 │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.0082,  0.0677,  0.0889,  ..., -0.0126,         │ │
│ │             0.1331,  0.0773],                                            │ │
│ │             │   │     [-0.0154,  0.1910,  0.2317,  ..., -0.0175,         │ │
│ │             0.0737,  0.0904],                                            │ │
│ │             │   │     [ 0.0045,  0.0079,  0.0782,  ...,  0.0871,         │ │
│ │             0.2146,  0.1610],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2072, -0.4070, -0.2063,  ...,  0.2056,         │ │
│ │             0.2026,  0.1909],                                            │ │
│ │             │   │     [-0.1892, -0.3584, -0.1125,  ...,  0.2360,         │ │
│ │             0.2014,  0.1350],                                            │ │
│ │             │   │     [-0.0207,  0.0061,  0.1028,  ...,  0.0423,         │ │
│ │             0.0614,  0.1290]]],                                          │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[ 0.0014, -0.0277, -0.0316,  ...,  0.0136,         │ │
│ │             -0.0720, -0.0031],                                           │ │
│ │             │   │     [ 0.0594,  0.2211,  0.3027,  ...,  0.0545,         │ │
│ │             -0.0148,  0.1456],                                           │ │
│ │             │   │     [ 0.0020,  0.1174,  0.1288,  ...,  0.2161,         │ │
│ │             0.2646,  0.2428],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.2764, -0.1858, -0.1377,  ..., -0.0336,         │ │
│ │             -0.0698,  0.0914],                                           │ │
│ │             │   │     [-0.2128, -0.2139, -0.0213,  ..., -0.1216,         │ │
│ │             0.0495,  0.0784],                                            │ │
│ │             │   │     [-0.0201, -0.0068,  0.0654,  ..., -0.0707,         │ │
│ │             -0.0082,  0.0613]]],                                         │ │
│ │             │   │                                                        │ │
│ │             │   │                                                        │ │
│ │             │   │   [[[-0.0410, -0.1239, -0.0381,  ..., -0.0250,         │ │
│ │             0.0571,  0.0465],                                            │ │
│ │             │   │     [ 0.0892,  0.1350,  0.2820,  ..., -0.0524,         │ │
│ │             0.0540,  0.1465],                                            │ │
│ │             │   │     [ 0.0535,  0.1686,  0.1600,  ...,  0.0972,         │ │
│ │             0.3105,  0.1892],                                            │ │
│ │             │   │     ...,                                               │ │
│ │             │   │     [-0.3572, -0.4065, -0.5254,  ...,  0.0081,         │ │
│ │             0.1448,  0.0538],                                            │ │
│ │             │   │     [-0.3552, -0.5039, -0.3284,  ...,  0.2098,         │ │
│ │             0.3291,  0.0665],                                            │ │
│ │             │   │     [-0.0542,  0.0217,  0.1528,  ...,  0.0293,         │ │
│ │             0.0638,  0.0684]]]],                                         │ │
│ │             │      device='cuda:0', dtype=torch.float16)                 │ │
│ │      self = TeacherUNetModel(                                            │ │
│ │               (model): Unet(                                             │ │
│ │             │   (encoder): ResNetEncoder(                                │ │
│ │             │     (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2,  │ │
│ │             2), padding=(3, 3), bias=False)                              │ │
│ │             │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,        │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │     (relu): ReLU(inplace=True)                             │ │
│ │             │     (maxpool): MaxPool2d(kernel_size=3, stride=2,          │ │
│ │             padding=1, dilation=1, ceil_mode=False)                      │ │
│ │             │     (layer1): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(64, 64, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer2): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(64, 128, kernel_size=(3, 3),       │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(64, 128, kernel_size=(1, 1),         │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(128, 128, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer3): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(128, 256, kernel_size=(3, 3),      │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(128, 256, kernel_size=(1, 1),        │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (4): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (5): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(256, 256, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │     (layer4): Sequential(                                  │ │
│ │             │   │   (0): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(256, 512, kernel_size=(3, 3),      │ │
│ │             stride=(2, 2), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (downsample): Sequential(                          │ │
│ │             │   │   │   (0): Conv2d(256, 512, kernel_size=(1, 1),        │ │
│ │             stride=(2, 2), bias=False)                                   │ │
│ │             │   │   │   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): BasicBlock(                                     │ │
│ │             │   │     (conv1): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │     (relu): ReLU(inplace=True)                         │ │
│ │             │   │     (conv2): Conv2d(512, 512, kernel_size=(3, 3),      │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │             │   (decoder): UnetDecoder(                                  │ │
│ │             │     (center): Identity()                                   │ │
│ │             │     (blocks): ModuleList(                                  │ │
│ │             │   │   (0): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(768, 256, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(256, 256, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (1): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(384, 128, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(128, 128, kernel_size=(3, 3),        │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1,   │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (2): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(192, 64, kernel_size=(3, 3),         │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(64, 64, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(64, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (3): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(128, 32, kernel_size=(3, 3),         │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(32, 32, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │   │   (4): DecoderBlock(                                   │ │
│ │             │   │     (conv1): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(32, 16, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention1): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (conv2): Conv2dReLU(                               │ │
│ │             │   │   │   (0): Conv2d(16, 16, kernel_size=(3, 3),          │ │
│ │             stride=(1, 1), padding=(1, 1), bias=False)                   │ │
│ │             │   │   │   (1): BatchNorm2d(16, eps=1e-05, momentum=0.1,    │ │
│ │             affine=True, track_running_stats=True)                       │ │
│ │             │   │   │   (2): ReLU(inplace=True)                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │     (attention2): Attention(                           │ │
│ │             │   │   │   (attention): Identity()                          │ │
│ │             │   │     )                                                  │ │
│ │             │   │   )                                                    │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │             │   (segmentation_head): SegmentationHead(                   │ │
│ │             │     (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1),  │ │
│ │             padding=(1, 1))                                              │ │
│ │             │     (1): Identity()                                        │ │
│ │             │     (2): Activation(                                       │ │
│ │             │   │   (activation): Identity()                             │ │
│ │             │     )                                                      │ │
│ │             │   )                                                        │ │
│ │               )                                                          │ │
│ │               (loss): BCEWithLogitsLoss()                                │ │
│ │               (train_f1): BinaryF1Score()                                │ │
│ │               (train_iou): BinaryJaccardIndex()                          │ │
│ │               (train_precision): BinaryPrecision()                       │ │
│ │               (train_recall): BinaryRecall()                             │ │
│ │               (val_f1): BinaryF1Score()                                  │ │
│ │               (val_iou): BinaryJaccardIndex()                            │ │
│ │               (val_precision): BinaryPrecision()                         │ │
│ │               (val_recall): BinaryRecall()                               │ │
│ │               (test_f1): BinaryF1Score()                                 │ │
│ │               (test_iou): BinaryJaccardIndex()                           │ │
│ │               (test_precision): BinaryPrecision()                        │ │
│ │               (test_recall): BinaryRecall()                              │ │
│ │             )                                                            │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1511 in _wrapped_call_impl                           │
│                                                                              │
│   1508 │   │   if self._compiled_call_impl is not None:                      │
│   1509 │   │   │   return self._compiled_call_impl(*args, **kwargs)  # type: │
│   1510 │   │   else:                                                         │
│ ❱ 1511 │   │   │   return self._call_impl(*args, **kwargs)                   │
│   1512 │                                                                     │
│   1513 │   def _call_impl(self, *args, **kwargs):                            │
│   1514 │   │   forward_call = (self._slow_forward if torch._C._get_tracing_s │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │   args = (                                                               │ │
│ │          │   tensor([[[[-0.0279,  0.0116, -0.0197,  ..., -0.0803,        │ │
│ │          -0.0152, -0.0020],                                              │ │
│ │          │   │     [-0.0659,  0.1263,  0.1180,  ...,  0.0021,  0.1010,   │ │
│ │          0.1056],                                                        │ │
│ │          │   │     [ 0.1149,  0.1550,  0.3108,  ...,  0.0916,  0.1504,   │ │
│ │          0.2377],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3740, -0.1196, -0.1798,  ..., -0.1198, -0.1116,   │ │
│ │          0.1718],                                                        │ │
│ │          │   │     [-0.2927, -0.1691,  0.0233,  ..., -0.0781,  0.0413,   │ │
│ │          0.1412],                                                        │ │
│ │          │   │     [-0.0300,  0.0842,  0.1364,  ..., -0.0254, -0.0889,   │ │
│ │          0.0761]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.1294, -0.0253,  0.0245,  ..., -0.0753,  0.0539,   │ │
│ │          0.1015],                                                        │ │
│ │          │   │     [-0.1243, -0.0791,  0.1270,  ...,  0.1829,  0.2532,   │ │
│ │          0.1139],                                                        │ │
│ │          │   │     [-0.1294,  0.0254,  0.1617,  ...,  0.3633,  0.2478,   │ │
│ │          0.2445],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3372, -0.3716, -0.3953,  ..., -0.0201, -0.1327,   │ │
│ │          0.1012],                                                        │ │
│ │          │   │     [-0.1477, -0.3081, -0.0349,  ..., -0.1764, -0.0923,   │ │
│ │          -0.0737],                                                       │ │
│ │          │   │     [ 0.0566,  0.1150,  0.1567,  ..., -0.0323, -0.1155,   │ │
│ │          0.0596]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.0634,  0.0865, -0.0599,  ..., -0.0974, -0.0269,   │ │
│ │          0.0041],                                                        │ │
│ │          │   │     [ 0.0970,  0.1237,  0.1902,  ...,  0.0899,  0.0369,   │ │
│ │          0.0660],                                                        │ │
│ │          │   │     [ 0.0046,  0.0969,  0.0421,  ...,  0.1782,  0.2664,   │ │
│ │          0.1254],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2817, -0.3960, -0.3130,  ...,  0.1370,  0.1470,   │ │
│ │          -0.0364],                                                       │ │
│ │          │   │     [-0.2585, -0.3835, -0.2625,  ..., -0.1390, -0.1609,   │ │
│ │          -0.0415],                                                       │ │
│ │          │   │     [-0.1159, -0.0264,  0.0231,  ..., -0.0155, -0.0535,   │ │
│ │          -0.0242]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.0082,  0.0677,  0.0889,  ..., -0.0126,  0.1331,   │ │
│ │          0.0773],                                                        │ │
│ │          │   │     [-0.0154,  0.1910,  0.2317,  ..., -0.0175,  0.0737,   │ │
│ │          0.0904],                                                        │ │
│ │          │   │     [ 0.0045,  0.0079,  0.0782,  ...,  0.0871,  0.2146,   │ │
│ │          0.1610],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2072, -0.4070, -0.2063,  ...,  0.2056,  0.2026,   │ │
│ │          0.1909],                                                        │ │
│ │          │   │     [-0.1892, -0.3584, -0.1125,  ...,  0.2360,  0.2014,   │ │
│ │          0.1350],                                                        │ │
│ │          │   │     [-0.0207,  0.0061,  0.1028,  ...,  0.0423,  0.0614,   │ │
│ │          0.1290]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.0014, -0.0277, -0.0316,  ...,  0.0136, -0.0720,   │ │
│ │          -0.0031],                                                       │ │
│ │          │   │     [ 0.0594,  0.2211,  0.3027,  ...,  0.0545, -0.0148,   │ │
│ │          0.1456],                                                        │ │
│ │          │   │     [ 0.0020,  0.1174,  0.1288,  ...,  0.2161,  0.2646,   │ │
│ │          0.2428],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2764, -0.1858, -0.1377,  ..., -0.0336, -0.0698,   │ │
│ │          0.0914],                                                        │ │
│ │          │   │     [-0.2128, -0.2139, -0.0213,  ..., -0.1216,  0.0495,   │ │
│ │          0.0784],                                                        │ │
│ │          │   │     [-0.0201, -0.0068,  0.0654,  ..., -0.0707, -0.0082,   │ │
│ │          0.0613]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.0410, -0.1239, -0.0381,  ..., -0.0250,  0.0571,   │ │
│ │          0.0465],                                                        │ │
│ │          │   │     [ 0.0892,  0.1350,  0.2820,  ..., -0.0524,  0.0540,   │ │
│ │          0.1465],                                                        │ │
│ │          │   │     [ 0.0535,  0.1686,  0.1600,  ...,  0.0972,  0.3105,   │ │
│ │          0.1892],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3572, -0.4065, -0.5254,  ...,  0.0081,  0.1448,   │ │
│ │          0.0538],                                                        │ │
│ │          │   │     [-0.3552, -0.5039, -0.3284,  ...,  0.2098,  0.3291,   │ │
│ │          0.0665],                                                        │ │
│ │          │   │     [-0.0542,  0.0217,  0.1528,  ...,  0.0293,  0.0638,   │ │
│ │          0.0684]]]],                                                     │ │
│ │          │      device='cuda:0', dtype=torch.float16),                   │ │
│ │          │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],      │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ │          )                                                               │ │
│ │ kwargs = {}                                                              │ │
│ │   self = BCEWithLogitsLoss()                                             │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/module.py:1520 in _call_impl                                   │
│                                                                              │
│   1517 │   │   if not (self._backward_hooks or self._backward_pre_hooks or s │
│   1518 │   │   │   │   or _global_backward_pre_hooks or _global_backward_hoo │
│   1519 │   │   │   │   or _global_forward_hooks or _global_forward_pre_hooks │
│ ❱ 1520 │   │   │   return forward_call(*args, **kwargs)                      │
│   1521 │   │                                                                 │
│   1522 │   │   try:                                                          │
│   1523 │   │   │   result = None                                             │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │         args = (                                                         │ │
│ │                │   tensor([[[[-0.0279,  0.0116, -0.0197,  ..., -0.0803,  │ │
│ │                -0.0152, -0.0020],                                        │ │
│ │                │   │     [-0.0659,  0.1263,  0.1180,  ...,  0.0021,      │ │
│ │                0.1010,  0.1056],                                         │ │
│ │                │   │     [ 0.1149,  0.1550,  0.3108,  ...,  0.0916,      │ │
│ │                0.1504,  0.2377],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3740, -0.1196, -0.1798,  ..., -0.1198,      │ │
│ │                -0.1116,  0.1718],                                        │ │
│ │                │   │     [-0.2927, -0.1691,  0.0233,  ..., -0.0781,      │ │
│ │                0.0413,  0.1412],                                         │ │
│ │                │   │     [-0.0300,  0.0842,  0.1364,  ..., -0.0254,      │ │
│ │                -0.0889,  0.0761]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.1294, -0.0253,  0.0245,  ..., -0.0753,      │ │
│ │                0.0539,  0.1015],                                         │ │
│ │                │   │     [-0.1243, -0.0791,  0.1270,  ...,  0.1829,      │ │
│ │                0.2532,  0.1139],                                         │ │
│ │                │   │     [-0.1294,  0.0254,  0.1617,  ...,  0.3633,      │ │
│ │                0.2478,  0.2445],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3372, -0.3716, -0.3953,  ..., -0.0201,      │ │
│ │                -0.1327,  0.1012],                                        │ │
│ │                │   │     [-0.1477, -0.3081, -0.0349,  ..., -0.1764,      │ │
│ │                -0.0923, -0.0737],                                        │ │
│ │                │   │     [ 0.0566,  0.1150,  0.1567,  ..., -0.0323,      │ │
│ │                -0.1155,  0.0596]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.0634,  0.0865, -0.0599,  ..., -0.0974,      │ │
│ │                -0.0269,  0.0041],                                        │ │
│ │                │   │     [ 0.0970,  0.1237,  0.1902,  ...,  0.0899,      │ │
│ │                0.0369,  0.0660],                                         │ │
│ │                │   │     [ 0.0046,  0.0969,  0.0421,  ...,  0.1782,      │ │
│ │                0.2664,  0.1254],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2817, -0.3960, -0.3130,  ...,  0.1370,      │ │
│ │                0.1470, -0.0364],                                         │ │
│ │                │   │     [-0.2585, -0.3835, -0.2625,  ..., -0.1390,      │ │
│ │                -0.1609, -0.0415],                                        │ │
│ │                │   │     [-0.1159, -0.0264,  0.0231,  ..., -0.0155,      │ │
│ │                -0.0535, -0.0242]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.0082,  0.0677,  0.0889,  ..., -0.0126,      │ │
│ │                0.1331,  0.0773],                                         │ │
│ │                │   │     [-0.0154,  0.1910,  0.2317,  ..., -0.0175,      │ │
│ │                0.0737,  0.0904],                                         │ │
│ │                │   │     [ 0.0045,  0.0079,  0.0782,  ...,  0.0871,      │ │
│ │                0.2146,  0.1610],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2072, -0.4070, -0.2063,  ...,  0.2056,      │ │
│ │                0.2026,  0.1909],                                         │ │
│ │                │   │     [-0.1892, -0.3584, -0.1125,  ...,  0.2360,      │ │
│ │                0.2014,  0.1350],                                         │ │
│ │                │   │     [-0.0207,  0.0061,  0.1028,  ...,  0.0423,      │ │
│ │                0.0614,  0.1290]]],                                       │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[ 0.0014, -0.0277, -0.0316,  ...,  0.0136,      │ │
│ │                -0.0720, -0.0031],                                        │ │
│ │                │   │     [ 0.0594,  0.2211,  0.3027,  ...,  0.0545,      │ │
│ │                -0.0148,  0.1456],                                        │ │
│ │                │   │     [ 0.0020,  0.1174,  0.1288,  ...,  0.2161,      │ │
│ │                0.2646,  0.2428],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.2764, -0.1858, -0.1377,  ..., -0.0336,      │ │
│ │                -0.0698,  0.0914],                                        │ │
│ │                │   │     [-0.2128, -0.2139, -0.0213,  ..., -0.1216,      │ │
│ │                0.0495,  0.0784],                                         │ │
│ │                │   │     [-0.0201, -0.0068,  0.0654,  ..., -0.0707,      │ │
│ │                -0.0082,  0.0613]]],                                      │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[-0.0410, -0.1239, -0.0381,  ..., -0.0250,      │ │
│ │                0.0571,  0.0465],                                         │ │
│ │                │   │     [ 0.0892,  0.1350,  0.2820,  ..., -0.0524,      │ │
│ │                0.0540,  0.1465],                                         │ │
│ │                │   │     [ 0.0535,  0.1686,  0.1600,  ...,  0.0972,      │ │
│ │                0.3105,  0.1892],                                         │ │
│ │                │   │     ...,                                            │ │
│ │                │   │     [-0.3572, -0.4065, -0.5254,  ...,  0.0081,      │ │
│ │                0.1448,  0.0538],                                         │ │
│ │                │   │     [-0.3552, -0.5039, -0.3284,  ...,  0.2098,      │ │
│ │                0.3291,  0.0665],                                         │ │
│ │                │   │     [-0.0542,  0.0217,  0.1528,  ...,  0.0293,      │ │
│ │                0.0638,  0.0684]]]],                                      │ │
│ │                │      device='cuda:0', dtype=torch.float16),             │ │
│ │                │   tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,       │ │
│ │                0.],                                                      │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   ...,                                              │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]], │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │                                                     │ │
│ │                │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],    │ │
│ │                │   │      ...,                                           │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],    │ │
│ │                │   │      [  0.,   0.,   0.,  ...,   0.,   0.,           │ │
│ │                0.]]]]], device='cuda:0')                                 │ │
│ │                )                                                         │ │
│ │ forward_call = <bound method BCEWithLogitsLoss.forward of                │ │
│ │                BCEWithLogitsLoss()>                                      │ │
│ │       kwargs = {}                                                        │ │
│ │         self = BCEWithLogitsLoss()                                       │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/modules/loss.py:725 in forward                                         │
│                                                                              │
│    722 │   │   self.pos_weight: Optional[Tensor]                             │
│    723 │                                                                     │
│    724 │   def forward(self, input: Tensor, target: Tensor) -> Tensor:       │
│ ❱  725 │   │   return F.binary_cross_entropy_with_logits(input, target,      │
│    726 │   │   │   │   │   │   │   │   │   │   │   │     self.weight,        │
│    727 │   │   │   │   │   │   │   │   │   │   │   │     pos_weight=self.pos │
│    728 │   │   │   │   │   │   │   │   │   │   │   │     reduction=self.redu │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │  input = tensor([[[[-0.0279,  0.0116, -0.0197,  ..., -0.0803, -0.0152,   │ │
│ │          -0.0020],                                                       │ │
│ │          │   │     [-0.0659,  0.1263,  0.1180,  ...,  0.0021,  0.1010,   │ │
│ │          0.1056],                                                        │ │
│ │          │   │     [ 0.1149,  0.1550,  0.3108,  ...,  0.0916,  0.1504,   │ │
│ │          0.2377],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3740, -0.1196, -0.1798,  ..., -0.1198, -0.1116,   │ │
│ │          0.1718],                                                        │ │
│ │          │   │     [-0.2927, -0.1691,  0.0233,  ..., -0.0781,  0.0413,   │ │
│ │          0.1412],                                                        │ │
│ │          │   │     [-0.0300,  0.0842,  0.1364,  ..., -0.0254, -0.0889,   │ │
│ │          0.0761]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.1294, -0.0253,  0.0245,  ..., -0.0753,  0.0539,   │ │
│ │          0.1015],                                                        │ │
│ │          │   │     [-0.1243, -0.0791,  0.1270,  ...,  0.1829,  0.2532,   │ │
│ │          0.1139],                                                        │ │
│ │          │   │     [-0.1294,  0.0254,  0.1617,  ...,  0.3633,  0.2478,   │ │
│ │          0.2445],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3372, -0.3716, -0.3953,  ..., -0.0201, -0.1327,   │ │
│ │          0.1012],                                                        │ │
│ │          │   │     [-0.1477, -0.3081, -0.0349,  ..., -0.1764, -0.0923,   │ │
│ │          -0.0737],                                                       │ │
│ │          │   │     [ 0.0566,  0.1150,  0.1567,  ..., -0.0323, -0.1155,   │ │
│ │          0.0596]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.0634,  0.0865, -0.0599,  ..., -0.0974, -0.0269,   │ │
│ │          0.0041],                                                        │ │
│ │          │   │     [ 0.0970,  0.1237,  0.1902,  ...,  0.0899,  0.0369,   │ │
│ │          0.0660],                                                        │ │
│ │          │   │     [ 0.0046,  0.0969,  0.0421,  ...,  0.1782,  0.2664,   │ │
│ │          0.1254],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2817, -0.3960, -0.3130,  ...,  0.1370,  0.1470,   │ │
│ │          -0.0364],                                                       │ │
│ │          │   │     [-0.2585, -0.3835, -0.2625,  ..., -0.1390, -0.1609,   │ │
│ │          -0.0415],                                                       │ │
│ │          │   │     [-0.1159, -0.0264,  0.0231,  ..., -0.0155, -0.0535,   │ │
│ │          -0.0242]]],                                                     │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.0082,  0.0677,  0.0889,  ..., -0.0126,  0.1331,   │ │
│ │          0.0773],                                                        │ │
│ │          │   │     [-0.0154,  0.1910,  0.2317,  ..., -0.0175,  0.0737,   │ │
│ │          0.0904],                                                        │ │
│ │          │   │     [ 0.0045,  0.0079,  0.0782,  ...,  0.0871,  0.2146,   │ │
│ │          0.1610],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2072, -0.4070, -0.2063,  ...,  0.2056,  0.2026,   │ │
│ │          0.1909],                                                        │ │
│ │          │   │     [-0.1892, -0.3584, -0.1125,  ...,  0.2360,  0.2014,   │ │
│ │          0.1350],                                                        │ │
│ │          │   │     [-0.0207,  0.0061,  0.1028,  ...,  0.0423,  0.0614,   │ │
│ │          0.1290]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[ 0.0014, -0.0277, -0.0316,  ...,  0.0136, -0.0720,   │ │
│ │          -0.0031],                                                       │ │
│ │          │   │     [ 0.0594,  0.2211,  0.3027,  ...,  0.0545, -0.0148,   │ │
│ │          0.1456],                                                        │ │
│ │          │   │     [ 0.0020,  0.1174,  0.1288,  ...,  0.2161,  0.2646,   │ │
│ │          0.2428],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.2764, -0.1858, -0.1377,  ..., -0.0336, -0.0698,   │ │
│ │          0.0914],                                                        │ │
│ │          │   │     [-0.2128, -0.2139, -0.0213,  ..., -0.1216,  0.0495,   │ │
│ │          0.0784],                                                        │ │
│ │          │   │     [-0.0201, -0.0068,  0.0654,  ..., -0.0707, -0.0082,   │ │
│ │          0.0613]]],                                                      │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[-0.0410, -0.1239, -0.0381,  ..., -0.0250,  0.0571,   │ │
│ │          0.0465],                                                        │ │
│ │          │   │     [ 0.0892,  0.1350,  0.2820,  ..., -0.0524,  0.0540,   │ │
│ │          0.1465],                                                        │ │
│ │          │   │     [ 0.0535,  0.1686,  0.1600,  ...,  0.0972,  0.3105,   │ │
│ │          0.1892],                                                        │ │
│ │          │   │     ...,                                                  │ │
│ │          │   │     [-0.3572, -0.4065, -0.5254,  ...,  0.0081,  0.1448,   │ │
│ │          0.0538],                                                        │ │
│ │          │   │     [-0.3552, -0.5039, -0.3284,  ...,  0.2098,  0.3291,   │ │
│ │          0.0665],                                                        │ │
│ │          │   │     [-0.0542,  0.0217,  0.1528,  ...,  0.0293,  0.0638,   │ │
│ │          0.0684]]]],                                                     │ │
│ │          │      device='cuda:0', dtype=torch.float16)                    │ │
│ │   self = BCEWithLogitsLoss()                                             │ │
│ │ target = tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   ...,                                                    │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]],       │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │                                                           │ │
│ │          │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],          │ │
│ │          │   │      ...,                                                 │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],          │ │
│ │          │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]]],      │ │
│ │          device='cuda:0')                                                │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
│                                                                              │
│ /home/tidop/Documentos/miniconda3/envs/deep/lib/python3.10/site-packages/tor │
│ ch/nn/functional.py:3197 in binary_cross_entropy_with_logits                 │
│                                                                              │
│   3194 │   │   reduction_enum = _Reduction.get_enum(reduction)               │
│   3195 │                                                                     │
│   3196 │   if not (target.size() == input.size()):                           │
│ ❱ 3197 │   │   raise ValueError(f"Target size ({target.size()}) must be the  │
│   3198 │                                                                     │
│   3199 │   return torch.binary_cross_entropy_with_logits(input, target, weig │
│   3200                                                                       │
│                                                                              │
│ ╭───────────────────────────────── locals ─────────────────────────────────╮ │
│ │          input = tensor([[[[-0.0279,  0.0116, -0.0197,  ..., -0.0803,    │ │
│ │                  -0.0152, -0.0020],                                      │ │
│ │                  │   │     [-0.0659,  0.1263,  0.1180,  ...,  0.0021,    │ │
│ │                  0.1010,  0.1056],                                       │ │
│ │                  │   │     [ 0.1149,  0.1550,  0.3108,  ...,  0.0916,    │ │
│ │                  0.1504,  0.2377],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.3740, -0.1196, -0.1798,  ..., -0.1198,    │ │
│ │                  -0.1116,  0.1718],                                      │ │
│ │                  │   │     [-0.2927, -0.1691,  0.0233,  ..., -0.0781,    │ │
│ │                  0.0413,  0.1412],                                       │ │
│ │                  │   │     [-0.0300,  0.0842,  0.1364,  ..., -0.0254,    │ │
│ │                  -0.0889,  0.0761]]],                                    │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[ 0.1294, -0.0253,  0.0245,  ..., -0.0753,    │ │
│ │                  0.0539,  0.1015],                                       │ │
│ │                  │   │     [-0.1243, -0.0791,  0.1270,  ...,  0.1829,    │ │
│ │                  0.2532,  0.1139],                                       │ │
│ │                  │   │     [-0.1294,  0.0254,  0.1617,  ...,  0.3633,    │ │
│ │                  0.2478,  0.2445],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.3372, -0.3716, -0.3953,  ..., -0.0201,    │ │
│ │                  -0.1327,  0.1012],                                      │ │
│ │                  │   │     [-0.1477, -0.3081, -0.0349,  ..., -0.1764,    │ │
│ │                  -0.0923, -0.0737],                                      │ │
│ │                  │   │     [ 0.0566,  0.1150,  0.1567,  ..., -0.0323,    │ │
│ │                  -0.1155,  0.0596]]],                                    │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[ 0.0634,  0.0865, -0.0599,  ..., -0.0974,    │ │
│ │                  -0.0269,  0.0041],                                      │ │
│ │                  │   │     [ 0.0970,  0.1237,  0.1902,  ...,  0.0899,    │ │
│ │                  0.0369,  0.0660],                                       │ │
│ │                  │   │     [ 0.0046,  0.0969,  0.0421,  ...,  0.1782,    │ │
│ │                  0.2664,  0.1254],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.2817, -0.3960, -0.3130,  ...,  0.1370,    │ │
│ │                  0.1470, -0.0364],                                       │ │
│ │                  │   │     [-0.2585, -0.3835, -0.2625,  ..., -0.1390,    │ │
│ │                  -0.1609, -0.0415],                                      │ │
│ │                  │   │     [-0.1159, -0.0264,  0.0231,  ..., -0.0155,    │ │
│ │                  -0.0535, -0.0242]]],                                    │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   ...,                                            │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[-0.0082,  0.0677,  0.0889,  ..., -0.0126,    │ │
│ │                  0.1331,  0.0773],                                       │ │
│ │                  │   │     [-0.0154,  0.1910,  0.2317,  ..., -0.0175,    │ │
│ │                  0.0737,  0.0904],                                       │ │
│ │                  │   │     [ 0.0045,  0.0079,  0.0782,  ...,  0.0871,    │ │
│ │                  0.2146,  0.1610],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.2072, -0.4070, -0.2063,  ...,  0.2056,    │ │
│ │                  0.2026,  0.1909],                                       │ │
│ │                  │   │     [-0.1892, -0.3584, -0.1125,  ...,  0.2360,    │ │
│ │                  0.2014,  0.1350],                                       │ │
│ │                  │   │     [-0.0207,  0.0061,  0.1028,  ...,  0.0423,    │ │
│ │                  0.0614,  0.1290]]],                                     │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[ 0.0014, -0.0277, -0.0316,  ...,  0.0136,    │ │
│ │                  -0.0720, -0.0031],                                      │ │
│ │                  │   │     [ 0.0594,  0.2211,  0.3027,  ...,  0.0545,    │ │
│ │                  -0.0148,  0.1456],                                      │ │
│ │                  │   │     [ 0.0020,  0.1174,  0.1288,  ...,  0.2161,    │ │
│ │                  0.2646,  0.2428],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.2764, -0.1858, -0.1377,  ..., -0.0336,    │ │
│ │                  -0.0698,  0.0914],                                      │ │
│ │                  │   │     [-0.2128, -0.2139, -0.0213,  ..., -0.1216,    │ │
│ │                  0.0495,  0.0784],                                       │ │
│ │                  │   │     [-0.0201, -0.0068,  0.0654,  ..., -0.0707,    │ │
│ │                  -0.0082,  0.0613]]],                                    │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[-0.0410, -0.1239, -0.0381,  ..., -0.0250,    │ │
│ │                  0.0571,  0.0465],                                       │ │
│ │                  │   │     [ 0.0892,  0.1350,  0.2820,  ..., -0.0524,    │ │
│ │                  0.0540,  0.1465],                                       │ │
│ │                  │   │     [ 0.0535,  0.1686,  0.1600,  ...,  0.0972,    │ │
│ │                  0.3105,  0.1892],                                       │ │
│ │                  │   │     ...,                                          │ │
│ │                  │   │     [-0.3572, -0.4065, -0.5254,  ...,  0.0081,    │ │
│ │                  0.1448,  0.0538],                                       │ │
│ │                  │   │     [-0.3552, -0.5039, -0.3284,  ...,  0.2098,    │ │
│ │                  0.3291,  0.0665],                                       │ │
│ │                  │   │     [-0.0542,  0.0217,  0.1528,  ...,  0.0293,    │ │
│ │                  0.0638,  0.0684]]]],                                    │ │
│ │                  │      device='cuda:0', dtype=torch.float16)            │ │
│ │     pos_weight = None                                                    │ │
│ │         reduce = None                                                    │ │
│ │      reduction = 'mean'                                                  │ │
│ │ reduction_enum = 1                                                       │ │
│ │   size_average = None                                                    │ │
│ │         target = tensor([[[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,         │ │
│ │                  0.]]]],                                                 │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255.,         │ │
│ │                  255.]]]],                                               │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255.,         │ │
│ │                  255.]]]],                                               │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   ...,                                            │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,         │ │
│ │                  0.]]]],                                                 │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,         │ │
│ │                  0.]]]],                                                 │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │                                                   │ │
│ │                  │   │   [[[[  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ..., 255., 255., 255.],  │ │
│ │                  │   │      ...,                                         │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,   0.],  │ │
│ │                  │   │      [  0.,   0.,   0.,  ...,   0.,   0.,         │ │
│ │                  0.]]]]], device='cuda:0')                               │ │
│ │         weight = None                                                    │ │
│ ╰──────────────────────────────────────────────────────────────────────────╯ │
╰──────────────────────────────────────────────────────────────────────────────╯
ValueError: Target size (torch.Size([16, 1, 1, 256, 256])) must be the same as
input size (torch.Size([16, 1, 256, 256]))
